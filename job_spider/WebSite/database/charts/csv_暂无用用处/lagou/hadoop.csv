"fromsite", "positionType", "positionName", "salary", "education", "city", "workYear", "jobDes", "company", "companySize", "financeStage", "industryField", "rate"
"拉勾", "Hadoop", "Hadoop/spark大数据开发工程师", "15000-30000", "本科", "杭州", "1-3年", "职位描述岗位职责：负责处理各种不同维度的金融数据，构建模型应用于互联网金融业务场景下的风控、推荐和人群画像等领域。任职要求：1.本科或以上学历，计算机、数学相关专业毕业2.精通JAVA和Python编程语言，了解Linux/Unix平台3.有较好的逻辑分析和数据分析能力，解决问题能力强4.了解数据挖掘、机器学习、并行计算相关理论5.有风控、推荐、人群画像等领域模型构建和调优工作经验者优先6.有spark、hadoop平台上的大数据处理工作经验者优先7.有大型互联网企业工作经验者优先", "杭州魔蝎数据科技有限公司", "15-50人", "初创型(天使轮)", "金融,数据服务", "4.2"
"拉勾", "Hadoop", "Hadoop工程师", "13000-25000", "本科", "上海", "3-5年", "职位描述岗位职责：1.基于海量数据的数据仓库建设、数据应用开发；2.分布式平台应用开发（Hadoop/Hive/Hbase）；3.开发数据统计系统，各类统计程序报表 ；4.支撑各业务线数据需求。任职要求：1.具有丰富的数据仓库开发经验，有2年以上互联网或移动互联网并基于Hadoop/Storm/HIVE/Hbase等应用开发经验，对分布式计算、数据仓库理论有深刻理解 ；2.熟练掌握linux常规命令与工具 ；3.对Hadoop、Hive、Storm等源码有研究优先 ；4.精通JAVA、MapReduce、Python，有并发应用或者分布式应用软件开发经验优先 ；5.精通shell编程，sql编程、awk脚本语言等；6.良好的系统分析、架构设计能力；7.对数据敏感、对新技术敏感，有数据挖掘技能者优先 ；8.了解无线端技术、有ios/android下开发经验者优先；9.对商业和业务逻辑敏感，具备良好的分析、组织、沟通能力和团队精神。", "上海高欣计算机系统有限公司", "150-500人", "成长型(A轮)", "移动互联网,电子商务", "3.9"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "上海", "1-3年", "职位描述工作职责：1、基于hive和spark构建数据仓库2、负责业务数据的清洗、建模、统计与可视化，全方位支撑线上产品和线下业务迭代扩张；3、构建数据的监测与分析体系，帮助业务人员快速、及时发现问题并找到原因；职位要求：1、熟练掌握SQL，理解 Hive/Mysql/Sqlserver 基本原理和调优策略；2、具备优秀的业务理解能力，具有数据建模经验，有大型数据的建模经验优先；3、熟悉Mongodb，Redis等非关系型数据库和内存数据库优先；4、具有数据清洗的经验，熟悉常用的数据清洗方法5、了解数据仓库开发流程，有数据仓库(DW)/商业智能(BI)/数据统计 相关工作经验者优先。", "上海秦苍信息科技有限公司", "150-500人", "成熟型(C轮)", "金融", "3.9"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "南京", "1-3年", "职位描述1、理解HADOOP体系架构，熟悉HDFS、MapReduce原理2、有一定Hive、Hbase、Spark、Storm等开发经验3、熟悉Linux操作系统及shell等脚本编程4、最好有一定Java开发基础", "深圳市网新新思软件有限公司", "500-2000人", "上市公司", "移动互联网,企业服务", "3.5"
"拉勾", "Hadoop", "资深大数据开发工程师-Hadoop", "15000-25000", "本科", "北京", "3-5年", "职位描述1.负责网易传媒大数据相关项目的核心开发；2.负责网易传媒大数据应用项目的详细设计及实现；3,负责网易传媒大数据项目中的技术难点攻关；要求1.本科及以上学历，计算机等相关专业毕业；2.熟练使用java语言，三年以上J2EE开发工作经验，熟悉Jvm运行机制及内存管理者；3.熟悉linux环境和命令；4.对hadoop、hive、hbase、MapReduce、spark、等大数据相关技术有所了解者优先考虑；5.热衷于产品研发和技术发展、具有强烈的责任意识和开放的心态；6.具有较强的沟通能力、逻辑思维能力以及良好的团队合作精神；7.有数据可视化系统项目经验优先考虑；", "网之易信息技术（北京）有限公司", "2000人以上", "上市公司", "数据服务,文化娱乐", "4.3"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "杭州", "1-3年", "职位描述        职位描述工作内容：1、了解需求，参与架构设计，能将用户的需求形成需求规格说明书；2、 负责指定功能模块的设计、开发与测试；3、负责Hadoop开发、测试和生产环境的搭建，维护hadoop集群并进行必要的troubleshooting，保障系统正常运行；4、负责核心代码编写，对质量直接负责，帮助Hadoop开发团队；5、分解详细的开发任务，能配合其他项目制定开发计划、开发文档、开发流程图。任职要求：1、计算机相关专业，本科及以上学历；2、5年以上开发经验2年以上Hadoop架构经验；3、精通Hadoop架构设计，Hadoop集群的搭建、部署、开发和维护；4、熟悉分布式算法设计，熟悉数据挖掘和机器学习等技术，对海量数据的分析处理、挖掘和分布式存储有丰富经验；5、精通Hadoop各个模块功能及配置，对HDFS、HBASE、MR和Spark有深入了解；7、熟悉linux环境和命令，熟悉shell脚本；8、会mysql，oracle者优先，有集群数据库开发使用经验者优先，有互联网金融、P2P、电子商务等行业背景者优先。", "杭州爱上租科技有限公司", "500-2000人", "成长型(A轮)", "移动互联网,O2O", "4.2"
"拉勾", "Hadoop", "hadoop运维工程师", "5000-9000", "本科", "成都", "1-3年", "职位描述岗位职责：1、负责搭建hadoop集群，并维护与管理；2、负责hadoop平台上的数据存储，数据维护和优化；3、负责保障大数据平台的高效运转、稳定、安全；4、建立Hadoop集群管理规范、维护，包括版本管理和变更记录等；5、撰写专业规范的技术文档，研究行业前沿技术。编写平台产品功能清单，编写产品使用手册及其他相关文档。任职要求：1.年龄25-40岁，大学本科及以上学历，计算机相关专业；2.具有2年以上系统集成项目规划和建设经验，至少设计或参与设计3个以上系统集成项目；3.熟悉多台Linux 服务器自动安装调试，具有大型应用平台运维经验，有过运维自动化项目经验者优先；4.熟悉系统集成所涉及的各种软硬件设备厂商、主流产品及关键技术，如：CISCO、H3C、华为、IBM、HP、EMC、微软、ORACLE、LINUX、VMware等；5.熟练掌握bash（sed/awk 等）和（Php/Python/Perl）中的一种；6.具有较强的人际沟通能力和文档编写能力，良好的语言表达能力和自学能力；7.具备独立分析问题和解决问题的能力，身体健康，适应环境能力强；8.具有等同于CCIE、HCNA、CCNA、linux、oracle相关认证优先；9.有hadoop集群运维经验优先。", "成都卡莱博尔信息技术股份有限公司", "50-150人", "成熟型(C轮)", "企业服务,数据服务", "4.2"
"拉勾", "Hadoop", "Hadoop/spark大数据开发工程师", "15000-30000", "本科", "杭州", "1-3年", "职位描述岗位职责：负责处理各种不同维度的金融数据，构建模型应用于互联网金融业务场景下的风控、推荐和人群画像等领域。任职要求：1.本科或以上学历，计算机、数学相关专业毕业2.精通JAVA和Python编程语言，了解Linux/Unix平台3.有较好的逻辑分析和数据分析能力，解决问题能力强4.了解数据挖掘、机器学习、并行计算相关理论5.有风控、推荐、人群画像等领域模型构建和调优工作经验者优先6.有spark、hadoop平台上的大数据处理工作经验者优先7.有大型互联网企业工作经验者优先", "杭州信邦科技有限公司", "50-150人", "初创型(天使轮)", "数据服务,移动互联网", "4.1"
"拉勾", "Hadoop", "Hadoop大数据开发", "20000-40000", "本科", "北京", "3-5年", "职位描述工作职责：1.负责hadoop平台上的数据处理；2.使用spark、mapreduce进行数据处理职位要求：1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce2.对数据结构、算法有深刻理解3.精通Java、Python4.熟悉linux开发环境5.熟悉hadoop、hbase、spark的源码的优先6.对新技术充满激情，认真负责、有良好的沟通和学习能力7.计算机或数学相关专业本科及以上学历", "车好多旧机动车经纪(北京)有限公司", "2000人以上", "成长型(A轮)", "O2O", "4.1"
"拉勾", "Hadoop", "高级hadoop工程师", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位描述：1. 实现基于Spark框架的开发；2. 对接kafka或flume，使用Spark Streaming和Spark SQL进行实时数据处理岗位要求：1. 熟悉Hadoop相关生态系统和Spark相关技术，至少有1年以上Spark开发经验；2. 熟悉Scala，或Python，Java语言，有丰富的分布式编程经验；3. 熟悉Spark Streaming和Spark SQL。熟悉Spark Mllib优先考虑；4. 较强的分析、动手解决技术问题能力。", "北京蜜莱坞网络科技有限公司", "500-2000人", "成长型(B轮)", "移动互联网,文化娱乐", "4.2"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "上海", "5-10年", "职位描述职位描述：岗位职责：1.负责电信级运营商流量分析云计算平台的基础架构的维护，监控，优化和升级等日常工作；2.负责处理数据平台Hadoop/Hive/Hbase/Storm/Spark等疑难问题的研究和解决；3.深入研究社区的各类大数据技术和产品，能够引入并实施；4.根据业务需求开发各类工具；5.帮助团队提供大数据分析相关能力；职位要求：1. 5年以上工作经验，2年以上大数据工作经验；2.在可扩展、高性能，高并发，高稳定性系统设计，开发和调优方面有实际经验；3.JAVA技术知识扎实，熟悉IO，多线程，集合类等基础框架，熟悉缓存，消息，搜索等机制；4.对Hadoop/Spark/Storm生态有丰富的经验；5.有良好的系统分析能力、故障诊断能力者优先；6.有大型分布式系统架构的实际经验。", "常熟市易迁网络科技有限公司", "15-50人", "初创型(天使轮)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop/ 大数据工程师", "18000-30000", "不限", "北京", "5-10年", "职位描述职位描述：物联网项目，将发动机中的数据提取整合到微软Azure平台上进行存储以及相应的分析计算。职位要求：1. 5年以上Java开发经验，有大数据经验或者微软Azure工作经验；2. 熟悉软件生命周期流程，熟悉Agile环境（有Scrum或者Kanban经验优先）；3.3年以上SQL Server经验；4.有Linux/Unix经验（RHEL经验优先）。", "北京塔塔信息咨询有限公司", "2000人以上", "上市公司", "金融", "-"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "上海", "3-5年", "职位描述职责：· 按照规范及设计文档完成编码工作，并对代码质量负责；· 编写及维护技术开发相关文档；· 能够对自己开发的代码设计并编写单元测试及功能测试代码；· 学习和研究新技术以满足产品的需求；· 为产品改进、优化、效率提升设计开发产品内部工具。要求：· 计算机相关专业本科及以上；· 软件基础理论知识扎实，具有良好的数据结构、算法功底；· 熟悉Hadoop等分布式开发，了解Hadoop相关各种开源项目，如：Hive、Hbase等，并有实际应用，熟悉Storm、Spark者优先；· 熟练应用Spring、Java Cache等开源框架；· 熟悉MySQL等关系型数据库，熟悉NoSQL数据库者优先；· 对新技术敏感，有一定独立分析，技术研究能力；· 熟练使用Linux环境下开发者优先；· 熟悉至少一种版本控制工具，如：SVN，熟悉分布式版本控制工具Mercurial或Git者优先；· 有个人开源项目或参与开源项目者优先；· 有代码洁癖和自发组织Code Review的开发者优先；· 提供本人半年内写过的代码，不限开发语言；工作态度：· 具备良好的人际交往、语言表达和沟通能力；· 具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神；· 愿意接受挑战性的工作，能够高效及时完成工作；", "上海丹焱信息科技有限公司", "15-50人", "初创型(未融资)", "移动互联网,企业服务", "4.3"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "北京", "3-5年", "职位描述工作职责：负责调度系统的开发，优化，提升数据处理的稳定性和效率负责元数据系统的开发，优化，提升数据质量。负责数据仓库的主题开发任职资格：1、有一定的研究、实验的能力，优秀的分析问题和解决问题的能力2、理解自然语言处理、机器学习、网页搜索，推荐系统，用户数据分析和建模的基本概念和常用方法，有相关领域的实际项目研发或者实习经历者优先。3、熟悉C++, Java或Python，熟悉Linux或类Unix系统开发,有较强的编程能力。能独立实现线上算法模块者优先。4、对大数据处理平台和工具有一定经验者优先,包括：Hadoop, Hive, Pig, Spark等5、学历要求：统招本科", "天津讯铭科技发展股份有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,电子商务", "-"
"拉勾", "Hadoop", "Hadoop/spark开发", "15000-30000", "本科", "北京", "3-5年", "职位描述 岗位职责: 负责基于Spark的并行计算平台的开发与优化工作。  任职资格： 1、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD编程； 2、熟悉Spark源码者优先； 3、熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先； 4、有深厚的操作系统，数据结构和算法基础； 5、熟练掌握Java或Scala语言； 6、2年以上软件开发经验, 熟悉mongodb数据库者优先； 7、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。", "北京盛世全景科技股份有限公司", "15-50人", "上市公司", "数据服务,金融", "3.5"
"拉勾", "Hadoop", "Hadoop开发工程师", "25000-35000", "本科", "北京", "3-5年", "职位描述工作职责：1.负责hadoop平台上的数据处理；2.使用spark、mapreduce进行数据处理职位要求：1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce2.对数据结构、算法有深刻理解3.精通Java、Python4.熟悉linux开发环境5.熟悉hadoop、hbase、spark的源码的优先6.对新技术充满激情，认真负责、有良好的沟通和学习能力7.计算机或数学相关专业本科及以上学历", "车好多旧机动车经纪(北京)有限公司", "2000人以上", "成长型(A轮)", "O2O", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "15000-25000", "本科", "上海", "3-5年", "职位描述工作内容负责安全日志分析系统研发，大数据分析架构搭建;spark大数据分析中job业务逻辑开发岗位要求对Hadoop2中的MR、hdfs、yarn技术内幕有深入的理解；有Hadoop集群搭建和管理经验；对spark技术内幕有了解；有java开发经验；有Elasticsearch或Lucene开发经验加分；有scala语言开发经验；了解spark技术内幕，对spark job生命周期有深入理解；能review spark代码来进行bug修复。", "上海云盾信息技术有限公司", "50-150人", "成长型(A轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop（python）", "13000-20000", "本科", "上海", "3-5年", "职位描述1、精通Python；2、熟悉MVC架构，精通Django或者其他Python Web开发框架者优先；3、具备数据库设计能力，精通掌握MySql/MongoDB者优先；4、熟悉Linux操作系统，熟悉Apache/Tomcat/Nigix等WebServer的部署和应用；5、有大型网络数据挖掘，在高并发，高稳定性方面有经验者优先；6、具备良好的编码习惯及开发文档书写习惯；7、具有优秀的团队合作和沟通协作能力，善于学习，乐于分享，能承受较大工作压力；8、了解或熟悉HTML、CSS、Javascript等前端技术优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "企业服务,金融", "3.8"
"拉勾", "Hadoop", "大数据开发工程师（Hadoop）", "15000-30000", "本科", "深圳", "3-5年", "职位描述任职要求：1. 精通至少一种开发语言，包括但不限于：Java，Scala，Ruby，Go等；2. 精通至少一种开源技术框架，包括但不限于：Hadoop，Spark，Kylin，Prestro等；3. 深刻理解敏捷开发模式；4. 热衷技术，较强的快速学习能力；5. 3年以上应用开发经验，2年以上大数据项目开发经验；项目经验：1. 实践过至少2个大数据开发项目，开发周期不少于半年；2. 有流处理系统和离线分析系统建设经验；3. 精通至少一个行业的平台建设，包括但不限于：电信行业，金融，互联网等；电信行业经验为佳；", "深圳索信达数据技术股份有限公司", "150-500人", "上市公司", "数据服务", "4.8"
"拉勾", "Hadoop", "Hadoop", "18000-30000", "大专", "深圳", "5-10年", "职位描述1.大数据相关工作3年以上；2.Java、Python中至少一门语言的5年以上的开发经验；3.熟悉运用MapReduce、HDFS、Hive、Hbase、Sqoop、storm、kafka、mongoDB、redis、elasticSearch中至少4种组件，并基于这4种以上组件的开发经验；4.熟练使用关系型数据库；5.大数据组件性能、存储优化经验丰富；6.3年以上shell编程", "武汉佰钧成技术有限责任公司", "2000人以上", "成熟型(不需要融资)", "移动互联网,分类信息", "3.4"
"拉勾", "Hadoop", "Hadoop", "1000-2000", "本科", "成都", "应届毕业生", "职位描述Familiar with RDBMS like Oracle, Mysql, or NoSQL DB like HBase, Mangodb.Familiar with Hadoop (HDFS, MapReduce), know about Hive, Pig, Spark etc.Has interest in Big Data, preferred to have related experiences.Bachelor degree, can communicate in English.Major in computer and science and related. 本职位针对2017年毕业生", "新电信息科技（成都）有限公司", "500-2000人", "成熟型(不需要融资)", "企业服务", "4.0"
"拉勾", "Hadoop", "Hadoop大数据", "6000-12000", "本科", "成都", "1-3年", "职位描述岗位职责：1、从事公司集群分布式计算（日志处理、数据统计分析）相关的开发工作；2、负责hadoop计算平台的版本升级、系统优化、故障处理、集群监控等工作；3、负责实时计算框架的开发、版本升级、系统优化、故障处理、集群监控等工作。任职资格：1、本科以上学历，2年以上工作经验；2、1年以上Hadoop开发经验3、熟悉Java语言优先4、拥有实际的Hadoop的项目经验", "成都快乐家网络技术有限公司", "50-150人", "成长型(A轮)", "电子商务", "3.8"
"拉勾", "Hadoop", "hadoop开发工程师", "8000-12000", "本科", "上海", "1-3年", "职位描述职位描述:1、hadoop相关底层应用研发工作；2、海量数据分析挖掘。岗位要求:1、熟悉Spark,streaming,了解mllib。2、熟悉scala编程，熟悉AKKA等框架。3、熟悉JAVA，熟悉JQUERY。4、熟悉LINUX系统，简单运维工作。SHELL脚本编写。5、熟悉离线分析HADOOP。6、熟悉HDFS、MAPREDUCE、YARN、HBASE(面向列数据库)、REDIS(基于内存数据库)。", "上海思创华信信息技术有限公司", "500-2000人", "成熟型(不需要融资)", "其他", "3.4"
"拉勾", "Hadoop", "Hadoop工程师", "15000-30000", "本科", "北京", "3-5年", "职位描述岗位职责:-利用大规模机器学习算法挖掘数据之间的联系，探索数据挖掘技术在实际场景中的产品应用-构建大规模推荐引擎，并致力于提供极致的推荐效果-结合传统行业，立足百度大数据，研发创新型产品-对百度已有的大规模数据处理系统已经优化和改善任职资格:-扎实自然语言处理/机器学习/数据挖掘理论和技术基础, 有2年以上的相关经验-熟悉当前推荐算法/机器学习/数据挖掘领域热点和前沿技术-精通C++或Java或Python等程序设计语言-有大规模用户数据或互联网内容数据处理经验者优先-有推荐系统相关工作经验者优先-有创新精神、喜欢挑战者优先", "百度移信网络技术（北京）有限公司", "2000人以上", "上市公司", "移动互联网", "4.2"
"拉勾", "Hadoop", "Hadoop/大数据研发工程师", "15000-20000", "本科", "上海", "3-5年", "职位描述岗位职责：1、负责大数据分析平台服务端的架构设计及性能优化；2、负责基于大数据技术开源框架的选型和开发；3、负责数据挖掘和建模相关核心算法的代码实现；4、负责和大数据平台业务系统模块集成；5、负责相关技术文档编写工作。岗位要求：1、本科（含）以上计算机、数学等理工科专业；2、熟悉大规模数据挖掘、机器学习，并具备1年以上的实际工作经验 ；3、熟悉Shell、Perl、Python中的至少一种，同时熟悉其它语言，如C/C++/java语言者优先；4、熟悉数据库原理，对SQL及NoSQL至少各了解一种主流数据库；5、良好的逻辑思维能力，能够从海量数据中发现有价值的规律 ；6、熟悉数据挖掘算法，具备数据分析建模经验优先考虑；7、具备Hadoop、Spark、Redis、Storm等开发及部署经验优先考虑；8、有银行业大数据平台工作经验优先考虑；9、熟悉分布式系统及并行计算原理的优先考虑。", "上海天正智能数据服务有限公司", "500-2000人", "成熟型(不需要融资)", "金融", "4.2"
"拉勾", "Hadoop", "Hadoop架构师", "15000-30000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责大数据产品线的架构设计  2、理解系统的业务需求，制定系统的整体技术框架、业务框架和系统架构；  3、负责给产品开发、实施、运维团队提供技术保障；  4、负责对系统的重用、扩展、安全、性能、伸缩性、简洁等做系统级的把握；  5、对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题。职位要求：1、本科以上学历，计算机相关专业，拥有5年以上工作经验，3年以上大数据工作经验；  2、对各种大数据框架（Hadoop、Storm、Spark、Kafka、Flume等）有深入理解，了解各个技术的优缺点；  3、熟悉Java、Scala或C++中的至少一门语言，有优良的Trouble Shooting能力；  4、对技术由衷热爱，对新技术、新方向有敏感的前瞻性；  5、有扎实的表达能力，对业务模型、技术模型进行分析、评估；  6、对大数据技术有钻研热情，乐于分享；  7、在开源社群活跃并有积极贡献者优先；  8、有大数据产品架构经验者优先。  ", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "spark/Hadoop开发", "15000-30000", "本科", "北京", "1-3年", "职位描述大数据平台软件工程师岗位职责:负责基于Spark的并行计算平台的开发与优化工作。任职资格：1、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD编程；2、熟悉Spark源码者优先；3、熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先；4、有深厚的操作系统，数据结构和算法基础；5、熟练掌握Java或Scala语言；6、2年以上软件开发经验, 熟悉mongodb数据库者优先；7、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。", "北京盛世全景科技有限公司", "15-50人", "初创型(天使轮)", "金融,数据服务", "3.0"
"拉勾", "Hadoop", "Hadoop高级工程师", "20000-25000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责数据后台的开发、维护，支撑数据平台的业务需求工作；2、根据需求完成相关数据处理模块的开发；3、负责对产品、市场团队技术支持；4、负责基于Hadoop的并行计算平台的开发与优化工作；5、与部门进行跨地域跨文化的沟通和合作，共同开发维护数据产品。工作要求：1. 熟悉并行计算或者分布式计算，熟悉Hadoop框架,熟练掌握RDD编程；2. 熟悉Hadoop源码者优先；3. 熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先；4. 有深厚的操作系统，数据结构和算法基础；5. 熟练掌握Java语言；3年以上软件开发经验,熟悉mongodb数据库者优先；6. 做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。加分项:1、对HDFS，Yarn，Hbase，Hive相关组件的性能优化和补丁跟踪等有实际经验2、以上Hadoop及大数据生态圈产品实践经验，Kafka/HBase/Presto/YARN等走心福利：1.目前业内最高薪酬：薪酬依据能力而定，不封顶不设限，我们保证您的生活和家庭需要！2.股权激励利益共沾：我们希望若干年后的您不再为生活奔波，专注于您最愿意做的专业工作。3.关注您的专业成长：提供专业培训机会，充满大牛的团队；结合专家的帮助和指导，通过持续在特定领域实践，是您专业提升最好最快的方法。4.我们了解工程师文化：这是支纯粹的工程师团队，拒绝技术官僚，我们知道您需要的，你懂的！", "北京创业公社信息科技服务有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop", "10000-17000", "本科", "深圳", "3-5年", "职位描述1.熟悉常用的报表工具：Cognos，Tableau，Pentaho等2.熟悉ETL工具：Datastage，Kettle, Informatica Powercenter等3.精通使用Oracle，MySQL，Greenplum等关系型数据库，熟悉SQL编写，存储过程编写以及海量数据的SQL查询优化4.最好熟悉Hadoop Hive的数据处理开发。5.良好的逻辑思维和沟通表达，工作积极负责", "深圳雁联计算有限公司", "500-2000人", "初创型(未融资)", "金融", "4.7"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责Hadoop集群的开发、调优、监控等工作，负责集群容量规划、扩容及集群性能优化，并持续跟踪了解开源Hadoop/Spark新特性；2、负责Hadoop集群的升级和运维工作，保证其稳定和高可用；3、根据研发经理的安排完成项目/模块的研发及维护工作；4、指导研发工程师，协助其解决相关技术难题。任职要求：1、计算机、软件工程相关专业，有Hadoop/Spark相关经验优先考虑；2、1-3年及以上的Hadoop/Spark平台设计和开发经验；3、精通MapReduce和Hive开发以及HDFS，HBase和Cassandra体系架构，并有相当优化经验；4、熟悉一种以上的常用关系型数据库，如MySQL、PostgreSQL、Oracle、SQL Server等，对数据库的基本理论和内部实现机制有比较深刻的理解，对于SQL优化有一定的实践经验；5、熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；6、良好的系统分析、架构设计能力，熟悉分析/设计的方法论，并有丰富的实践经验，学习能力强，拥有优秀的逻辑思维能力，工作认真负责，沟通能力良好。", "北京易车互联信息技术有限公司", "2000人以上", "上市公司", "移动互联网,电子商务", "4.1"
"拉勾", "Hadoop", "资深Hadoop运维工程师", "20000-35000", "本科", "北京", "3-5年", "职位描述工作职责：负责hadoop生态圈的运维保障；负责Hadoop/Hbase/Spark/Presto/Druid等系统的架构审核、业务监控、持续交付、应急响应、容量规划等；为每天处理TB级别数据的大数据平台的稳定、高效运行负责；深入理解数据平台架构，发现并解决重大故障及性能瓶颈；根据需求，修改源码，添加功能；工作要求：大学本科及以上学历，计算机或者相关专业；熟悉hadoop、hbase、hive、spark、presto的原理，有3年以上的Hadoop集群部署、开发和维护管理经验；深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，精通java语言；优秀的学习能力，分析和解决问题的能力和强烈的进取心；诚恳、踏实，对技术和工作充满热情；具备良好的沟通能力和团队合作精神；熟悉分布式系统设计范型，有大规模系统设计和工程实现的了解者优先；有阅读过hadoop等的源码者并持续跟踪Hadoop社区发展方向优先。", "车好多旧机动车经纪(北京)有限公司", "2000人以上", "成长型(A轮)", "O2O", "4.1"
"拉勾", "Hadoop", "Hadoop大数据（金融项目-陆家嘴）", "10000-18000", "本科", "上海", "3-5年", "职位描述岗位职责：1、负责搭建hadoop集群，并维护与管理；2、负责hadoop平台上的数据存储，数据维护和优化；3、负责进行Hadoop、Hive、Hbase项目开发；4、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题;5、根据项目设计文档，完成项目模块的设计与开发；任职要求：1、本科以上（含本科）计算机、数学等相关专业；2、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；3、熟悉java开发(精通优先考虑)；4、熟悉SQL语言；5、熟悉linux开发环境；6、熟悉shell、perl、python中的一种；7、有hadoop集群部署和开发经验者优先；8、熟悉hadoop、hive、impala、kafka、flume等，对hive、impala开发有实际经验者优先；9、有银行业工作经验，熟悉银行业务者优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "企业服务,金融", "3.8"
"拉勾", "Hadoop", "Hadoop", "8000-16000", "本科", "北京", "不限", "职位描述工作描述：1、参与大数据相关系统的需求调研和需求分析，撰写相关技术文档；2、项目概要设计、详细设计、开发计划等的编制并实施；3、具有良好沟通能力，能与客户进行需求方面的交流；4、搭建大数据相关系统开发环境，完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具程序代码的实现；5、完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维工作，完成上述工具的故障排除、修复工作；岗位要求:1、全国统招全日制高校计算机软件及相关专业一本学历及以上；2、具备软件设计、编码开发测试、文档编写的能力；3、熟悉主流Linux操作系统，精通shell;4、了解Hadoop、Hive、Hbase、Storm、Spark等技术中的两种以上进行大数据应用开发；5、了解Linux系统运维，了解Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维；6、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；7、责任心强，工作踏实，团队协作精神，能适应严格项目管理；8、具备良好的沟通能力；9、具备电信行业、互联网行业工作经验者优先考虑；10、能够接受出差。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "25000-50000", "硕士", "上海", "5-10年", "职位描述Software Engineer （Hadoop）Job Description:Support and enhance open source distributed computing platform technology. Contribute to the open source community on Hadoop related projects.Leadand participate to the design and implementation of analytics infrastructure toalign with the vision of eBay Platform Infrastructure.Provide technical consultancy to engineers on Hadoop MapReduce and Spark development.Job Requirements:Proven successful track record of 3+ years of software engineering design anddevelopment experience with strong background of open source technology.Strong development skills in Java and Scala with strong sense of performance, scalability,concurrency and extensibility.Excellent background on computer science fundamentals, data structures, and algorithms.Experience in bigdata processing is a plus.", "北京翰嘉睿华科技有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,电子商务", "-"
"拉勾", "Hadoop", "Hadoop大数据开发工程师", "10000-20000", "大专", "北京", "1-3年", "职位描述岗位要求：1、有1－3年大数据或数据仓库项目经验，了解数据仓库相关理论知识；2、熟练掌握Hadoop及Map-Reduce应用开发，精通HBase、Hive、Pig、Storm等大数据开发工具者优先；3、精通SQL开发，精通Mysql、Oracle等关系型数据库中的一种；4、熟悉java开发；5、熟悉Linux系统，具备shell、perl等脚本开发能力岗位职责：负责电信业务的大数据开发工作", "上海新致软件股份有限公司", "2000人以上", "成熟型(C轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "8000-15000", "本科", "杭州", "1-3年", "职位描述岗位职责：•搭建和部署hadoop集群；•利用大数据平台实现对数据的分析和处理；•负责大数据平台的性能参数调整和优化；•良好的数据敏感度，能从海量数据提炼核心结果；•负责大数据平台的开发（目前涉及组件spark、hbase、es、kylin、tableau）；•使用Hadoop进行MapReduce或Storm等开发；•根据业务需求，编制各类分析图表、撰写项目分析文档和分析报告；•进行技术设计和项目实施。任职要求：•2年以上java工作经验，具备独立完成系统开发、维护能力；•良好的java基础，深入了解java核心API，反射、IO、多线程等；•深入了解Hadoop平台，Yarn资源管理，熟悉HDFS系统，MapReduce编程模式；•熟悉oracle/mysql等数据库的操作；•熟悉spark、hbase、es、kafka组件的优先；•强烈的责任心和团队合作能力，性格开朗，善于沟通；•工作积极主动，认真细致，良好的学习能力，逻辑思维能力并且敢于创新和接；受挑战。", "杭州腾果网络科技有限公司", "150-500人", "初创型(未融资)", "移动互联网,广告营销", "-"
"拉勾", "Hadoop", "大数据研发工程师JAVA/Hadoop/SQL", "13000-26000", "大专", "上海", "1-3年", "职位描述1.互联网及传统IT公司领域3年以上研发经验；2.计算机及相关专业本科以上学历，具有良好的数学、统计学、计算机相关知识；3.深厚的Java/C++功底；4.参与过分布式高性能服务的设计开发，有大规模分布式系统的实践经验者优先；5.熟练掌握linux下多线程及网络编程；6.熟悉hadoop以及mapreduce编程模型；7.具备编写、优化复杂SQL的能力；熟悉MySQL数据库，熟练使用Shell、Python、Perl、Tcl等脚本语言之一对数据敏感，具备良好的逻辑思维能力、组织沟通能力、具有团队精神以及优秀的问题解决能力你将负责：1.在领导下完成大数据平台建设；2.负责大数据ETL的具体实现与性能优化，构建Data Warehouses；3.负责与业务端对接的API开发；4.负责平台中数据质量的治理与管控；5.负责与内外部数据源沟通，梳理业务所需数据，并制定数据加载策略。能给你的世界500强技术团队+技术驱动+创新活泼型人才。（说的就是我们现在这群程序员）自我成长并分享公司的成长果实。（越来越大的办公室，越来越多的团队建设，当然还有期权）", "上海最闻信息科技有限公司", "15-50人", "初创型(未融资)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "高级hadoop运维工程师", "15000-25000", "不限", "北京", "1-3年", "职位描述岗位职责1、负责hadoop、hbase、hive、spark，flume，kafka、hue等大数据平台的规划、部署、监控和系统优化等工作2、负责Hadoop平台的用户管理、权限分配、资源分配3、处理大数据平台各类异常和故障，确保系统平台的稳定运行4、研究业界前沿的大数据运维技术，负责各种运维工具和系统的设计开发任职要求 1、具备至少2年以上hadoop及相关组件的运维经验 3、掌握Hadoop、Hbase、Kafka、Hive、Spark、hue（资源管理，可以管理hdfs,hive,spark）等组件的工作原理 4、熟练掌握至少一种脚本语言（shell、Python、perl）； 5、熟悉java，能够编写java运维工具或调试脚本。6、熟悉mapreduce算法，能够编写和提交分布式计算任务； 6、在大数据分析方面据有一定的工作经验； 7、对分布式开源项目有技术兴趣，能跟踪Hadoop开源社区的发展方向，不断改进和优化集群； 8、具备高度的责任心，较强的故障分析及排除能力9、具备良好的团队合作精神，工作认真、细心、虚心好学、沟通能力好。", "影时光网络技术（北京）有限公司", "500-2000人", "成熟型(C轮)", "移动互联网,文化娱乐", "3.8"
"拉勾", "Hadoop", "Hadoop数据开发", "13000-22000", "本科", "北京", "不限", "职位描述岗位职责：负责京东大数据部的数据仓库搭建和维护任职要求：1、有一定数据仓库经验2、熟练掌握shell和python3、能单独处理并核查问题4、有Hadoop和hive开发经验优先5、对数据敏感，良好的团队精神", "京东商城-技术研发体系-大数据部", "2000人以上", "上市公司", "电子商务", "4.5"
"拉勾", "Hadoop", "hadoop/linux开发工程师（实习生）", "2000-4000", "本科", "南京", "应届毕业生", "职位描述岗位职责;1. 承担部分大数据平台运维工作和运维插件开发；2. 参与异构数据系统和大数据平台的集成、融合；3. 参与大数据平台技术调研和难点攻克；4. 研究并跟进大数据领域新技术并分享；5. 负责大数据产品系统开发和测试；6.参与数据平台各系统的性能分析与系统优化，不断提高系统运行效率。任职要求:1、计算机或相关专业本科以上学历，大三，大四，研二，研三在南京上学的学生，有至少半年以上的实习时间，每周至少保持4天工作时间，工作地点为南京分公司；2、有扎实的计算机理论基础，对数据结构及算法有较强的功底，有编程学习基础或相关项目实施经验或有自学经验；3、对大数据，hadoop，linux，java有浓厚的兴趣，对技术有追求并有较强的学习能力；4、性格积极乐观，诚信，有较强的语言表达能力；5、英语要求良好，能读懂大量英文文档；6.会spark，hbase和linux运维等的优先考虑。", "上海玖道信息科技股份有限公司", "150-500人", "上市公司", "移动互联网,O2O", "4.3"
"拉勾", "Hadoop", "Hadoop大数据工程师", "15000-20000", "本科", "成都", "3-5年", "职位描述1. 负责数据分析算法及模型的实现及调优；2. 负责数据产品相关的数据分析，数据挖掘，以及产品算法设计和实现.3. 负责相关的数学模型建立，以及反复迭代模型输出和实现；4. 协助项目开发人员实现产品从模型、算法到系统的转变；4. 负责公司需要的其他算法相关工作。岗位要求：1. 具备扎实的数学基础和统计学基础，包括高等代数，离散数学以及微积分、统计方法，时间序列分析等；2. 熟悉数据分析挖掘常用算法（分类，聚类，预测，回归等）原理及其实现方式；3. 熟练使用SAS/SPSS/R/Excel等工具，能应用统计软件对各类数据进行分析建模，并绘制成统计报告；4. 熟练掌握 Matlab，能进行仿真分析与设计，熟悉聚类分析、关联分析、回归分析等数理统计和挖掘算法；4. 熟悉主流数据库，熟悉python/perl/ruby等脚本语言优先；5. 具备良好沟通能力，学习能力，抗压能力，和团队协作精神；6. 热爱数据分析和数据挖掘工作，对数据敏感,有强烈的学习和提高欲望。", "成都优易数据有限公司", "50-150人", "成长型(不需要融资)", "数据服务,移动互联网", "-"
"拉勾", "Hadoop", "Hadoop", "13000-18000", "大专", "深圳", "3-5年", "职位描述岗位要求：1. 3-5 年左右 Java编程经验，2年以上 Hadoop 相关工作经验，熟练掌握Hdfs、 MapReduce、Hbase 、Hive的设计和开发技能；有实际大数据项目的成功经验。2. 熟练掌握Storm、Spark streaming等大数据实时处理框架的一种，具备实时处理框架的设计和开发能力；3. 熟悉Lucene、Solr、Elasticsearch等搜索引擎框架中的一种；4. 熟悉Linux开发环境；熟练掌握Python、Shell、Perl中的一种；5. 良好的团队精神及沟通表达能力；6. 有较好的沟通理解和表达能力，工作踏实，热衷于技术研究。", "深圳市泰久信息系统有限公司", "500-2000人", "成熟型(C轮)", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Hadoop", "12000-18000", "本科", "北京", "1-3年", "职位描述岗位描述:1.基于互联网/电子商务海量数据，分析用户特征，开发基于认证风险控制模型。2.通过数据分析，发现互联网保险机会点，与保险产品经理共同制定保险产品政策与规则。3.对各保险产品运营、风险进行监控分析，完成分析报告、报表，通过数据帮助运营人员共同制定保险产品运营策略。岗位要求:1. 熟悉Hadoop或其他分布式数据开发技术，熟练掌握数据库技术；2、精通海量数据仓库（百T及以上）的系统设计和开发，精通数据建模、ETL过程、元数据管理等数据仓库主要环节；3、精通SQL,PL/SQL，精通Mysql数据库；4、熟练使用Hadoop或其他分布式平台的一种，能使用Java、Python或其他语言编写MapReduce进行大数据处理；5、掌握报表工具BIEE、BO、cognos；6、从事过数据安全、数据质量管理工作者优先；", "北京青年众人网络安全技术有限公司", "50-150人", "上市公司", "移动互联网,金融", "4.6"
"拉勾", "Hadoop", "Hadoop/spark\u200b大数据工程师", "10000-20000", "本科", "深圳", "3-5年", "职位描述岗位职责：1、负责海量信息分析处理，系统设计；2、负责根据业务场景，项目需求抽取、分析处理。任职要求：1、计算机及相关专业本科以上学历，两年以上大数据相关工作经验；2、熟悉Hadoop/spark等开源系统, 有相关系统设计经验；熟悉scala或java语言编程；3、擅长基于Spark/Spark streaming/impala环境的大数据分析处理；4、良好的团队合作能力，勤奋好学。5、有互联网金融行业大数据分析处理经验优先考虑。", "小花互联网金融服务（深圳）有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,金融", "4.4"
"拉勾", "Hadoop", "hadoop/storm高级数据开发工程师", "20000-30000", "本科", "北京", "3-5年", "职位描述hadoop/storm高级数据开发工程师工作内容： 1.基于hadoop/storm计算框架，实现个性化推荐离线/实时计算模型。2.为已成型的推荐产品做持续地迭代优化。职位要求：1、本科及以上学历，计算机相关专业；2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。3、熟悉Hadoop/Storm/HIVE/Hbase等分布式开源项目及其工作原理，并有实际开发经验。4、熟悉常用脚本语言shell,python等。5、有互联网或移动互联网公司背景优先。", "京东商城", "2000人以上", "上市公司", "电子商务", "4.2"
"拉勾", "Hadoop", "Hadoop", "8000-16000", "本科", "上海", "不限", "职位描述工作描述：1、参与大数据相关系统的需求调研和需求分析，撰写相关技术文档；2、项目概要设计、详细设计、开发计划等的编制并实施；3、具有良好沟通能力，能与客户进行需求方面的交流；4、搭建大数据相关系统开发环境，完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具程序代码的实现；5、完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维工作，完成上述工具的故障排除、修复工作；岗位要求:1、全国统招全日制高校计算机软件及相关专业一本学历及以上；2、具备软件设计、编码开发测试、文档编写的能力；3、熟悉主流Linux操作系统，精通shell;4、了解Hadoop、Hive、Hbase、Storm、Spark等技术中的两种以上进行大数据应用开发；5、了解Linux系统运维，了解Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维；6、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；7、责任心强，工作踏实，团队协作精神，能适应严格项目管理；8、具备良好的沟通能力；9、具备电信行业、互联网行业工作经验者优先考虑；10、能够接受出差。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "hadoop开发工程师（实习生）", "2000-4000", "本科", "上海", "应届毕业生", "职位描述岗位职责：1.负责大数据平台的运维以及测试2.负责或配合开发前端或相关接口对大数据进行分析负责大数据平台的售前沟通任职要求：1.了解大数据的概念，对hadoop生态圈有一定的了解2.有mapreduce,hbase,hive,kylin,spark，phonix，sqoop中至少一种的学习或者使用经验3.良好的沟通能力和反应能力4.良好的文档书写功底5.良好的学习能力", "上海玖道信息科技股份有限公司", "150-500人", "上市公司", "移动互联网,O2O", "4.3"
"拉勾", "Hadoop", "hadoop/storm数据开发工程师", "15000-25000", "本科", "北京", "1-3年", "职位描述hadoop/storm数据开发工程师工作内容： 1.基于hadoop/storm计算框架，实现个性化推荐离线/实时计算模型。2.为已成型的推荐产品做持续地迭代优化。职位要求：1、本科及以上学历，计算机相关专业；2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。3、熟悉Hadoop/Storm/HIVE/Hbase等分布式开源项目及其工作原理，并有实际开发经验。4、熟悉常用脚本语言shell,python等。5、有互联网或移动互联网公司背景优先。", "京东商城", "2000人以上", "上市公司", "电子商务", "4.2"
"拉勾", "Hadoop", "Hadoop云计算运营经理", "15000-20000", "本科", "广州", "不限", "职位描述岗位职责:职位描述：工作职责：1、管理Hadoop集群运行，稳定提供平台服务。2、对于Hadoop、Hbase、HIVE日常故障能提供应急修复手段。3、能结合实际业务场景提供相关工具简化运营过程。职位要求：1、熟悉流行云计算框架的应用模式及开发：hadoop、zookeeper、hbase、hive；2、较强动手能力，有实际hadoop应用设计和开发经验优先（有两年hadoop实际项目开发经验。 ）；3、掌握java语言，精通JDK的使用(IO,NIO,容器,反射机制、异常)；理解jvm原理：类加载、垃圾回收、内存管理；4、了解常用开源框架原理及使用（struts、spring、hibernate、log4j、jdbc）；5、了解Linux管理和使用及SHELL使用；6、有良好的沟通表达能力，善于团队合作。", "广东亿迅科技有限公司", "2000人以上", "成熟型(不需要融资)", "其他", "3.5"
"拉勾", "Hadoop", "高级hadoop工程师", "25000-50000", "本科", "北京", "5-10年", "职位描述岗位职责：1、负责公司大数据平台运维、优化、改造，如hadoop, spark、hbase等。2、负责公司的大数据处理框架的研发设计工作。3、根据业务需要为数据仓库的实现提供支持。4、具备责任心和良好的团队协作精神。任职要求：1、5年以上开发经验，熟练运用Java、Scala、C++、Python语言中的一种。2、熟练掌握Hadoop、Hive、Hbase、spark等分布式框架原理，有相关的调优、运维、开发经验。3、需要有Hadoop / Spark平台相关运维经验2年以上，hadoop/Spark开发3年以上。4、熟练掌握linux常规命令与工具，Python，shell，至少1种脚本语言熟练。5、有elasticsearch相关开发使用经验。6、对高并发处理、调优等有经验更佳，对于系统性能瓶颈能够进行优化分析。7、有数据仓库设计、开发相关经验。6、具有较强的学习能力、逻辑分析能力、问题排查能力、沟通能力、自我驱动动力、自我管理能力。", "拉卡拉支付有限公司", "2000人以上", "初创型(未融资)", "金融", "3.5"
"拉勾", "Hadoop", "集团总部-大数据中心-Hadoop高级工程师(日志处理方向)", "20000-25000", "本科", "北京", "不限", "职位描述岗位职责:1.负责搜狐大数据平台的开发、维护工作；2.负责搜狐各业务线日志采集、清洗、整合等工作；3.负责大数据平台数据分析、用户行为分析等相关工作。任职资格:1.本科及以上学历，计算机相关专业； 2.有1－3年大数据或数据仓库项目经验，了解数据仓库相关理论知识； 3.熟练掌握Hadoop及Map-Reduce应用开发，精通HBase、Hive、Pig、Storm等大数据开发工具者优先；4.精通SQL开发，精通Mysql、Oracle等关系型数据库中的一种；5.精通java开发；6.拥有memcache、redis、ehcache等cache开发经验，理解其原理和工作模式；7.熟悉Linux系统，具备shell、perl等脚本开发能力；8.熟悉nginx、resin者优先；9.学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。", "搜狐媒体", "2000人以上", "上市公司", "移动互联网,广告营销", "4.3"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "深圳", "3-5年", "职位描述岗位职责：1、搭建和维护大数据相关集群架构和项目；2、协助运营团队分析和统计各类线上数据；3、负责大数据平台和应用产品相关业务开发工作，完成各类数据业务抽象和模型化；4、负责基于日志数据的用户行为/用户画像分析；任职要求：1、本科（含）以上学历；2、熟悉linux，至少熟悉掌握一门编程语言，java或者python更佳；3、二年以上的大数据相关开发经验，有深厚的算法基础，优秀者可不受此条件限制；4、熟悉掌握hadoop/hive/hbase/spark/flume-ng/storm等大数据主流工具和技术；5、熟悉分布式系统中常用技术，如消息中间件kafka，缓存数据库redis，关系型数据库mysql等；6、熟悉网络爬虫和搜索技术；7、逻辑思维清晰，能清楚的表达个人想法和理解需求，具备强烈的责任心和团队合作能力。", "深圳市川海长丰网络科技有限公司", "15-50人", "初创型(未融资)", "移动互联网", "-"
"拉勾", "Hadoop", "Hadoop", "13000-20000", "本科", "北京", "3-5年", "职位描述岗位职责：1、根据结合需求，负责数据收集、建模，构建可扩展的数据仓库以及数据分析解决方案；2、根据具体业务需要，进行行业数据、内部数据收集并进行深度挖掘，提供有价值的专项分析报告。职位要求任职要求：1、本科以上计算机相关专业学历，5年以上工作经验，精通JAVA；2、有2年以上大数据或数据仓库项目经验，了解数据仓库相关理论知识；3、熟悉ETL流程，OLAP分析，数据仓库建模；4、熟练掌握Hadoop的MapReduce应用开发，精通Hive、Pig等大数据开发工具，熟悉分布式计算系统理念；5、熟悉Spark、Storm流式计算优先；6、熟悉R等数据分析语言者优先；7、精通SQL开发，精通MySQL、Oracle等关系型数据库中的一种；8、踏实、细心、认真，有责任心，良好的团队协作，乐于沟通交流和分享。有以下任意一点将优先考虑：1、有大型抓取系统开发经验。2、有大型数据库维护和优化经验。工作地点北京市海淀区上地信息路30号上地大厦502", "北京微宝网络科技有限公司", "50-150人", "成长型(不需要融资)", "移动互联网", "2.8"
"拉勾", "Hadoop", "大数据开发工程师（Hadoop）", "10000-20000", "本科", "上海", "3-5年", "职位描述工作职责:1.负责基于Hadoop产品的研发,建设；2.负责Hadoop 产品部署运维；3.负责整体提升hadoop/Hbase集群的高可用性、高性能、高扩展特性任职要求：1.2年以上hadoop 经验；2.对hadoop的Map/Reduce原理有深入研究，有相关项目的实际开发经验；3.熟悉linux开发环境；4.熟悉hadoop和hive，有MapReduce分布式编程经验 ；5.熟悉hive,hbase, sqoop;6.熟悉java开发,熟悉scala 更佳7.了解 shell, python", "上海中畅信息科技有限公司", "50-150人", "初创型(未融资)", "金融 ,数据服务", "4.0"
"拉勾", "Hadoop", "Hadoop高级/资深研发工程师-北京", "15000-27000", "本科", "北京", "不限", "职位描述岗位职责:1、负责视频播放相关数据统计处理2、负责整个数据基础结构的规划和设计任职资格:1、计算机相关专业或数理统计相关专业，两年以上大数据开发经验2、熟悉Linux/Unix开发环境3、熟练使用shell命令，熟悉python/perl等脚本语言者优先4、了解hadoop，了解HDFS数据存储机制；熟练使用hive数据处理5、接触过Streaming、HBase、Storm、Spark者优先6、思维敏捷，有较强的钻研学习能力；较好的沟通能力、团队合作", "北京爱奇艺科技有限公司", "2000人以上", "成熟型(D轮及以上)", "广告营销,文化娱乐", "4.2"
"拉勾", "Hadoop", "Hadoop运维工程师", "18000-30000", "不限", "杭州", "不限", "职位描述1、 负责Hadoop、HBase等大数据平台的规划、部署、监控、系统优化等工作，有分布式存储系统运维工作者优先；2、 负责公司内部自研大数据平台的运维管理工作；3、 处理各类异常和故障，确保系统平台的稳定运行；4、 深入理解系统平台，为其持续优化提供建设性意见任职资格：1、 本科及以上学历，计算机相关专业；2、 3年以上系统运维或开发经验，熟HadoopHBaseStorm等大数据系统，有大数据平台运维或开发经验者优先；3、 熟悉Linux操作系统，熟悉Java，熟练使用ShellPerlPythonRuby中至少一种语言；4、 具有较强的学习能力、逻辑分析能力、问题排查能力;5、 具有较强的工作主动性，工作认真、负责、细致、敬业；6、 有钻研新技术的热情和能力，善于交流和表达，富有团队精神，具有一定的管理组织能力；", "杭州恩牛网络技术有限公司", "500-2000人", "成熟型(C轮)", "金融,数据服务", "4.0"
"拉勾", "Hadoop", "急招Hadoop开发工程师", "10000-20000", "本科", "上海", "1-3年", "职位描述岗位职责：1.负责hadoop平台上的数据存储，数据维护和优化；2.编写hive-ql脚本做相关的统计计算；3.编写spark程序进行相关报表计算；4.编写map-reduce程序做相关的分析建模；任职要求：5.本科以上学历，1年以上相关工作经验；6.对数据结构、算法有深刻理解；7.熟悉linux开发环境；8.有hadoop集群部署和开发经验；9.熟悉java和sql开发；10.工作积极主动认真负责，具有良好的沟通和学习能力.", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Spark/Hadoop/Storm 高级工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述1. 研究业界最新的大数据技术，负责大数据系统的设计与开发2. 组建及领导团队的机会3. 为公司提供大数据存储、分析、计算支持职位要求：1、本科及以上学历，计算机相关专业；2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。3、熟悉Hadoop/Storm/Spark/HIVE/Hbase等分布式开源项目及其工作原理，并有实际开发经验。4、熟悉常用脚本语言shell,python等。5、良好的trouble shooting能力6、有互联网或移动互联网公司背景优先", "北京小年糕互联网技术有限公司", "15-50人", "成长型(A轮)", "移动互联网", "3.8"
"拉勾", "Hadoop", "Hadoop工程师", "18000-30000", "本科", "上海", "3-5年", "职位描述1. 开发迭代数据产品2. 已有数据产品在各地域的部署，与合作方做必要的沟通协调，确保部署质量3. 参与数据产品设计4. 与数据科学家一道训练、部署模型5. 工作相关文档的撰写6. 其他交付的工作岗位要求：1. 计算机相关本科及以上学历2. 1年以上Hadoop编程经验，1年以上Mapreduce编程经验，熟悉JAVA编程3. 熟悉SQL/NoSQL/JSON/XML，以及相关的数据操作4. 熟悉Shell编程5. 熟悉数据结构，算法的时间空间复杂度 O(?)6. 算法或数学建模相关类竞赛获奖者优先", "上海畅圣计算机有限公司", "50-150人", "成长型(B轮)", "金融", "4.5"
"拉勾", "Hadoop", "大数据开发工程师（HADOOP)（开发，大数据测试", "6000-10000", "本科", "常州", "1-3年", "职位描述1、 基于Hadoop 2.0（YARN）开发MapReduce/Spark/Storm程序，能解决实际线上生产系统（Hadoop，HBase，Zookeeper，Redis以及各种生产任务等）的各种问题；2、设计开发自有离线/实时/流式数据计算平台等；3、维护线上任务的稳定产出，跟踪hadoop社区新动态；4、对Hadoop平台运维不断优化，提升数据产品的质量和响应速度；5、开发各种Hadoop大数据自动化运维与监控工具。能力要求：1、两年或以上JAVA开发经验，并且有Hadoop项目开发经验；2、熟悉Hadoop、Hive、HBase等分布式开源项目及工作原理，有Hadoop集群优化、开发和维护管理经验；3、熟悉Linux操作系统，网络协议，熟练使用Shell；4、软件基础理论知识扎实，具有良好的数据结构、算法功底；5、有实时数据处理经验者或交通行业海量数据处理经验优先。", "上海宝康电子控制工程有限公司", "150-500人", "初创型(未融资)", "其他", "-"
"拉勾", "Hadoop", "Hadoop", "6000-12000", "本科", "福州", "不限", "职位描述工作描述：1、参与大数据相关系统的需求调研和需求分析，撰写相关技术文档；2、项目概要设计、详细设计、开发计划等的编制并实施；3、具有良好沟通能力，能与客户进行需求方面的交流；4、搭建大数据相关系统开发环境，完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具程序代码的实现；5、完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维工作，完成上述工具的故障排除、修复工作；岗位要求:1、全国统招全日制高校计算机软件及相关专业一本学历及以上；2、具备软件设计、编码开发测试、文档编写的能力；3、熟悉主流Linux操作系统，精通shell;4、了解Hadoop、Hive、Hbase、Storm、Spark等技术中的两种以上进行大数据应用开发；5、了解Linux系统运维，了解Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维；6、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；7、责任心强，工作踏实，团队协作精神，能适应严格项目管理；8、具备良好的沟通能力；9、具备电信行业、互联网行业工作经验者优先考虑；10、能够接受出差", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师/Hadoop开发", "10000-18000", "本科", "上海", "1-3年", "职位描述岗位职责：1.负责智子云数据基础架构平台的运维工作，保障服务的高可用行和稳定性。2.负责集群容量规划、扩容及集群性能优化3.集群作业的执行计划和日常运行状态监控4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。职位要求：1. 2年以上大数据集群相关运维经验，熟悉常用的监控及管理工具2.有良好的计算机和网络基础，熟悉linux文件系统、性能调优，TCP/IP、HTTP等协议3.熟悉大数据集群运行基本原理。具备相关大数据集群搭建优化经验者优先（Cloudera CDH/Apache Hadoop/Hbase/Kafka/Zookeeper）4.良好的学习能力、沟通能力、适应能力，责任心强。", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "高级hadoop工程师", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位描述：1. 实现基于Spark框架的开发；2. 对接kafka或flume，使用Spark Streaming和Spark SQL进行实时数据处理岗位要求：1. 熟悉Hadoop相关生态系统和Spark相关技术，至少有1年以上Spark开发经验；2. 熟悉Scala，或Python，Java语言，有丰富的分布式编程经验；3. 熟悉Spark Streaming和Spark SQL。熟悉Spark Mllib优先考虑；4. 较强的分析、动手解决技术问题能力。", "北京蜜莱坞网络科技有限公司", "500-2000人", "成长型(B轮)", "移动互联网,文化娱乐", "4.2"
"拉勾", "Hadoop", "高级hadoop工程师", "16000-25000", "本科", "上海", "3-5年", "职位描述一、主要职责1.负责Hadoop集群相关的开发、调优、监控等工作；2.负责Hbase、Spark项目开发、实施工作；3.负责数据平台的基础架构设计和优化工作。二、任职要求：1.2年以上工作经验，熟悉linux系统；2.技术Geek,对技术有很高的热情；3.深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理；4.熟练掌握Java开发，有开源软件源码阅读和fix经验者优先；5.有大规模Hadoop集群运维经验，能维护Hadoop源码，有Hadoop源代码BUG修复或者源代码优化经验者优先；6.具备kafka/zookeeper/spark/storm/flume/hive等集群运维经验者优先；7.具有快速解决问题的能力和较强的学习能力；8.附上github地址或blog地址有加分。", "拉扎斯网络科技（上海）有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网", "4.0"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "上海", "5-10年", "职位描述1）3年到5年开发经验（硬性）2）精通java开发，并且有数据库开发经验（硬性）3）有高并发开发经验（非硬性）4）有Redis，HBASE开发经验尤佳。（非硬性）5）本科以上学历（硬性）6） 接受学习新技能，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班(硬性)7）要求会大数据 hadoop请看清是外派职位，谢谢！请看清是外派职位，谢谢！请看清是外派职位，谢谢！", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "大数据/Hadoop开发工程师", "8000-15000", "本科", "广州", "1-3年", "职位描述工作职责：（1）负责公司大数据项目架构设计，系统开发工作。（2）负责海量数据仓库设计与开发。（3）负责大数据平台系统持续性优化工作。任职要求：（1）全日制本科及以上学历，2年以上互联网数据开发工作经验。（2）精通sql，必须具备DW/BI开发工作经验。（3）至少熟练掌握hadoop，hive，spark其一开发。（4）熟悉NoSQL数据库开发。（5）熟悉linux/unix操作系统。（6）具备大数据技术钻研精神，对大数据开发感兴趣。（7）有大数据开发工作经验优先。", "铂涛信息技术（广州）有限公司", "500-2000人", "初创型(未融资)", "移动互联网,旅游", "4.2"
"拉勾", "Hadoop", "Hadoop开发运维工程师(000499)", "10000-20000", "本科", "上海", "不限", "职位描述岗位职责:负责Hadoop集群相关的开发、调优、监控、升级等工作；负责Hive、Pig、Spark、Hbase系统开发、实施工作；负责数据平台的基础架构设计和优化工作。任职资格:深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理；熟悉thrift、protobuf、parquet的使用；熟练掌握Java开发，有开源软件源码阅读和fix经验者优先；对技术有很高的热情；有大规模Hadoop集群运维经验者优先；具有快速解决问题的能力和较强的学习能力；熟悉linux系统；", "上海聚胜万合广告有限公司", "500-2000人", "上市公司", "广告营销", "4.7"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "杭州", "1-3年", "职位描述岗位职责：1. 负责公司核心集群的运维工作,保证其高可用和稳定性。2. 负责集群容量规划、扩容及集群性能优化。3. 深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。4. 设计实现分布式集群的运维、监控和管理平台。5. 制定hadoop整体集群使用规范，规范的Hadoop平台开发及应用；制定hadoop整体集群使用规范，规范的Hadoop平台开发及应用；任职要求：1、擅长hadoop生态系统各个组件的运用和调优， 如Spark、hadoop、hbase、hive、flume、sqoop等任意3项以上, 有相关参数调优, 性能优化等有实际经验。2、 擅长Linux shell，及 java编程；3、有实际踩坑经历, 对于相关组件的版本跟进, 补丁跟踪, bug追踪等有相关经验。4、实际处理过各种集群在线版本升级, 数据迁移, 集群扩容, 稳定性监控等工作。5、熟悉Kerberos安全认证系统，实施过集群权限管理, 资源隔离方面的方案规划或二次开发工作。6、有Cloudera的CM使用经验或通过Hadoop相关认证尤佳。", "浙江康健绿线网络技术有限公司", "500-2000人", "成熟型(C轮)", "移动互联网,医疗健康", "4.2"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "上海", "1-3年", "职位描述岗位职责：1、负责搭建hadoop集群，并维护与管理；2、负责hadoop平台上的数据存储，数据维护和优化；3、负责进行Hadoop、Hive、Hbase项目开发；4、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题;5、根据项目设计文档，完成项目模块的设计与开发；任职要求：1、本科以上（含本科）计算机、数学等相关专业；2、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；3、熟悉java开发(精通优先考虑)；4、熟悉SQL语言；5、熟悉linux开发环境；6、熟悉shell、perl、python中的一种；7、有hadoop集群部署和开发经验者优先；8、熟悉hadoop、hive、impala、kafka、flume等，对hive、impala开发有实际经验者优先；9、有银行业工作经验，熟悉银行业务者优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "金融", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "2000-4000", "本科", "广州", "应届毕业生", "职位描述职位职责： 1）参与 Hadoop 相关项目的研发工作； 2）参与海量数据的挖掘分析工作等。职位要求：1）熟悉 Java 语言，熟悉 JVM 原理； 2）熟悉多线程及高性能程序的设计、编码及性能调优； 3）熟悉 Linux 系统，包括 Shell/Python 等脚本编码和软件开发等； 4）熟悉 Hadoop、Hive、HBase 等相关开源项目； 5）熟悉多种列数据库、内存数据库开源项目；", "佳都新太科技股份有限公司", "500-2000人", "上市公司", "移动互联网", "3.6"
"拉勾", "Hadoop", "Hadoop研发工程师", "15000-23000", "本科", "北京", "1-3年", "职位描述岗位职责：1、负责公司核心产品的设计和优化工作；2、参与核心技术的升级和改进工作；任职要求：1、熟练掌握Java基础编程，使用多线程、TCP开发过项目；2、熟练使用hadoop、spark以及kafka等开源工具任意一种；3、具备对linux集群服务器的管理能力优先；4、有分布是系统管理、调优及数据分析挖掘项目工作经验者优先；公司福利：1、提供全额五险一金，提供免费餐饮；2、入职送苹果笔记本；3、提供免费健身卡；4、公司距离城铁步行5分钟即到； ", "北京数介科技有限公司", "15-50人", "成长型(A轮)", "数据服务", "3.9"
"拉勾", "Hadoop", "hadoop", "12000-17000", "大专", "深圳", "3-5年", "职位描述1.2年以上数据挖掘经验，具有统计学理论基础；2.熟悉Hadoop，SAS SPAR.T懂存储过程，sql性能，有过ETL等数据同步工作经验", "北京博纳光辉文化传媒有限公司", "50-150人", "初创型(未融资)", "广告营销,文化娱乐", "-"
"拉勾", "Hadoop", "Hadoop 开发工程师", "10000-15000", "大专", "北京", "1-3年", "职位描述工作职责负责宜搜广告平台部广告数据系统实时/离线统计、分析，系统优化改造、重构、维护等工作。任职要求1.2年以上java工作经验，具备独立完成系统开发、维护能力；2.良好的java基础，深入了解java核心API，反射、IO、多线程等；3.深入了解Hadoop平台，Yarn资源管理，熟悉HDFS系统，MapReduce编程模式；4.熟悉J2EE相关的开发，SpringMVC、Spring、Mybaits框架；5.熟练使用Linux环境，shell脚本编写，maven管理工具；6.熟练使用缓存redis、protocolbuffer工具、thriftRPC框架；7.熟悉Flume、Kafka、Storm者优先；8.强烈的责任心和团队合作能力，性格开朗，善于沟通；9.工作积极主动，认真细致，良好的学习能力，逻辑思维能力并且敢于创新和接受挑战；", "深圳市宜搜科技发展有限公司北京分公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.5"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "深圳", "1-3年", "职位描述岗位职责：1.基于hadoop的海量数据分析系统研发；2.基于hadoop集群的MapReduce程序的开发、测试及优化；3.Hadoop及大数据相关技术研究；4.开发各种Hadoop大数据自动化运维与监控工具。岗位要求：1.两年以上工作经验，本科以上学历；2.对Linux操作系统熟练掌握，熟悉shell等脚本编程；3.扎实的java基础，两年以上java实际开发经验；4.熟悉Hadoop生态系统相关项目的功能、架构、实现；5.熟悉hadoop及hive，有MapReduce分布式编程经验；6.对海量数据的分析、挖掘有浓厚兴趣，有海量数据处理经验；7.对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力；8.理解能力强，有较强的逻辑思维分析能力；9.有强烈的责任心及良好的团队合作精神。", "中国平安人寿保险股份有限公司", "2000人以上", "上市公司", "金融", "4.3"
"拉勾", "Hadoop", "Hadoop", "11000-20000", "本科", "北京", "3-5年", "职位描述岗位职责：1、大数据平台的部署、测试、维护、调优2、基于大数据平台进行数据清洗、提取、结构化3、基于大数据平台进行算法研究应聘要求：1、本科及以上学历，计算机科学、软件工程、统计学、数据挖掘或相关专业2、英语四级以上，能够阅读理解英文API及文档较好的主动性，良好的沟通和协作能力，有责任心3、对以下任意一方面有了解或经验者优先 1）Storm/Flink/Spark Streaming 2）Hive/Spark/Impala 3）MongoDB/HBase/Redis/Memcache 4）Flume/Kafka 5）SQL Server/MySQL/PostgreSQL", "北京智诚智达交通科技有限公司", "50-150人", "成长型(不需要融资)", "数据服务,其他", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "8000-16000", "本科", "上海", "1-3年", "职位描述岗位职责：1.负责智子云数据基础架构平台的运维工作，保障服务的高可用行和稳定性。2.负责集群容量规划、扩容及集群性能优化3.集群作业的执行计划和日常运行状态监控4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。职位要求：1. 2年以上大数据集群相关运维经验，熟悉常用的监控及管理工具2.有良好的计算机和网络基础，熟悉linux文件系统、性能调优，TCP/IP、HTTP等协议3.熟悉大数据集群运行基本原理。具备相关大数据集群搭建优化经验者优先（Cloudera CDH/Apache Hadoop/Hbase/Kafka/Zookeeper）4.良好的学习能力、沟通能力、适应能力，责任心强。", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop大数据运维工程师", "10000-17000", "本科", "北京", "1-3年", "职位描述岗位职责：1、负责搭建hadoop平台部署和调优，保证其稳定运行；2、开发和使用Hadoop大数据自动化运维与监控工具；3、对Hadoop平台运维不断优化，探索、研究新的运维技术方向。4、负责相关工作文档撰写任职要求：1、统招本科及以上学历（硬性要求），211/985优先，2年以上Linux系统管理工作经验；2、熟悉hadoop、hive、hbase、spark、storm等分布式相关技术；3、具备hadoop环境安装、维护、性能调优经验；4、至少会使用1种服务器脚本语言，比如：shell、java、python等；5、优秀的分析问题和解决问题的能力。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "9000-16000", "大专", "南京", "不限", "职位描述大数据的岗位职责要求：1、理解HADOOP体系架构，熟悉HDFS、MapReduce原理2、有一定Hive、Hbase、Spark、Storm等开发经验3、熟悉Linux操作系统及shell等脚本编程4、最好有一定Java开发基础（以上岗位需长期驻场平安科技，稳定，加班少，0出差）", "深圳市网新新思软件有限公司", "500-2000人", "上市公司", "移动互联网,企业服务", "3.5"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-30000", "本科", "上海", "1-3年", "职位描述职位介绍：1、负责spark/hadoop平台的研发与维护；2、负责基于spark/hadoop平台分析处理用户访问数据、订单信息等；3、负责推荐系统的模型建立、特征提取、数据提取、模型训练、效果评估；岗位要求：1、善于学习，对spark开发有实际经验； 2、熟悉java、scala、python等开发语言中的一种；3、熟悉spark、hadoop、hive、kafra、flume等； 4、熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案； 5、了解分布式系统的设计和应用； 6、了解机器学习的优先。", "上海中彦信息科技有限公司", "500-2000人", "成熟型(C轮)", "电子商务", "3.9"
"拉勾", "Hadoop", "Hadoop工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述工作职责：1、负责公司产品数据的多信息源数据采集、传输、存储、计算、分析和挖掘；2、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；3、根据公司产品需求进行Hadoop的部署与开发，协助业务层改进job质量及数据流程优化；4、编制部署、开发和测试相关技术文档；任职要求：1、Hadoop相关技术开发经验1-3年；2、熟练Python/Java服务端编程，有良好的编码习惯；3、熟练mongoDB、MySQL、redis，Oracle等常用数据库与Hadoop结合开发优先考虑；4、深入理解Hadoop/HBase/HDFS／Kafka／Sqoop／Zookeeper，并有相关编程经验；5、熟练使用Spark以及相关组件，有丰富的RDD使用经验，对源代码有一定研究者优先；6、熟悉LEK，有ElasticSearch优化经验者优先；    ", "上海八分量信息科技有限公司北京分公司", "10-50人", "初创型(天使轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-15000", "本科", "上海", "3-5年", "职位描述岗位职责：1、 基于云计算技术进行网站运营数据计算平台的设计、开发、测试和部署；2、 提供网站海量数据存储、分布并行计算、搜索系统、用户行为数据挖掘和智能数据展现；3、 负责个性化系统（推荐服务）的分析、设计、开发和部署。任职要求：1、 熟悉hadoop/spark等一种或几种分布式计算平台，理解mapreduce原理；2、 熟悉java/jvm/内存管理，有分布式任务开发经验；3、 了解hbase/hive/impala/hdfs,了解集群资源管理yarn/mesos等；4、 熟悉Oracle数据库开发，了解Linux基本操作；5、 易于相处和沟通，善于分析和解决问题，有较强的学习和创新能力，有责任心。", "上海盖奇信息科技有限公司", "15-50人", "成长型(B轮)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "杭州", "1-3年", "职位描述1. 计算机、数据等相关专业本科以上学历，工作2年以上2. 熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的设计能力3. 精通SQL，熟悉Oracle、MySQL等关系型数据库4. 熟悉Hadoop/ODPS等分布式计算平台，熟练Hive/Hbase/mysql等数据开发技术5. 掌握Java/python语言能力的优先，熟悉linux/Shell优先6. 在数据统计、算法上有一定基础的优先7. 沟通与交流能力强，业务理解能力强，具有一定的业务建模能力", "杭州数澜科技有限公司", "15-50人", "初创型(天使轮)", "企业服务,数据服务", "4.5"
"拉勾", "Hadoop", "Hadoop_设计/开发/测试/销售/维护/服务", "15000-30000", "本科", "深圳", "3-5年", "职位描述负责华为大数据产品FusionInsight的设计/开发/测试/销售/维护/服务", "华为技术有限公司", "2000人以上", "成熟型(不需要融资)", "移动互联网,企业服务", "4.1"
"拉勾", "Hadoop", "Hadoop PoC 工程师", "13000以上", "本科", "北京", "1-3年", "职位描述职位要求：计算机或相关专业本科（或以上）学历熟悉Linux shell以及SQL 语言熟悉Java语言，对Cloudera版本熟悉优先考虑了解Hadoop，熟悉Hadoop，HBase，Hive基本命令有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先做事认真负责，沟通能力良好，自学能力较强，能够出差。职责： 大数据平台软件的项目实施、安装部署。", "北京红象云腾系统技术有限公司", "15-50人", "初创型(天使轮)", "数据服务", "4.5"
"拉勾", "Hadoop", "Hadoop高级研发工程师", "15000-21000", "本科", "上海", "3-5年", "职位描述职位：Hadoop高级研发工程师职责描述：1. 负责Hadoop系统的运维和研发工作2. 负责Hadoop源码解读、bug解决等工作3. 负责Hadoop生态系统领域新技术的调研、测试、开发等工作职位要求：1. 计算机相关专业毕业，本科3-5年，硕士2-4年经验2. 熟悉Hadoop生态系统各个组件，有相关运维和研发经验3. 熟悉Linux操作系统、开发环境4.熟练掌握Java", "北京爱奇艺科技有限公司", "2000人以上", "成熟型(D轮及以上)", "广告营销,文化娱乐", "4.2"
"拉勾", "Hadoop", "大数据平台工程师 hadoop", "18000-30000", "大专", "深圳", "3-5年", "职位描述职位说明：1.负责搭建大数据平台，能根据实际需求对平台进行优化配置，保障各核心服务运行的稳定、通过技术优化提升数据产品的质量和响应速度；2.开发各种Hadoop&HBase大数据自动化运维与监控工具,建设基于大数据的运维监控体系;3.负责集群容量规划、扩容及性能优化，持续跟进hadoop的变化及新特性;4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向任职要求1.三年以上系统运维或大数据运维工作经验，有大型互联网公司工作经验者优先；2.有Hadoop生态系统的运维经验，了解Hadoop、Storm、Spark、Flume、Kafka这些组件的原理，能部署并进行性能调优；2.具备Java开发能力，对Hadoop源码有研究，具备部署、实施、维护hadoop及相关组件的能力；3.熟悉nagios、cacti、ganglia、zabbix、zenoss优先；熟悉服务器监控、日志分析，熟悉运维自动化，熟悉集群和高可用技术并具备生产环境实施和维护管理的经验；4.具有良好的学习能力、沟通能力、客户服务意识和团队合作精神；具有强烈的进取精神和乐观的工作态度。", "极策科技（深圳）有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,生活服务", "-"
"拉勾", "Hadoop", "hadoop高级研发工程师", "15000-30000", "本科", "北京", "不限", "职位描述岗位职责：负责 hadoop 和其生态系统的源码级修改, 包括但不限于:1, bugfix2, 新功能实现3, 自动化平台实现任职要求：1,熟练使用java语言,兼会scala的做为加分项2,深入理解hdfs的工作原理,给社区提交过patch的做为加分项3,深入理解yarn的工作原理4,有过2年以上的hadoop生态系统使用经验", "精硕世纪科技（北京）有限公司", "150-500人", "成熟型(C轮)", "数据服务", "4.1"
"拉勾", "Hadoop", "数据平台 - Spark/Hadoop工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述        美团崇尚用数据说话，自上线起数据平台团队一直在不断完善公司级的统一数据平台。数据平台基于Hadoop构建，目前每天执行20万次计算流程，负责每天百TB的数据存储、分析和实时计算，有2000多个业务指标，为十几个业务线、各层级的团队管理和产品运营，提供大量的数据决策支持。随着美团以每年超过3倍的速度成长，数据规模带来的存储和计算压力，是我们面临的最大挑战。现在我们开始组建负责 Hadoop 性能的技术专家团队，需要对 Hadoop/Spark 性能优化方面具有丰富经验的人才加入。这个团队负责构建稳定高效的大规模数据存储、计算服务，并确保在数据量快速增长的同时，每天凌晨重要的数据计算任务按时高效的完成。工作职责：- Spark/YARN/HDFS//HBase/Kylin/Presto/Hive 的性能改进、功能扩展、故障分析；- 不断解决规模增长带来的技术和业务问题，确保Hadoop 数据平台每天上午8点完成重要数据的计算。职位要求：- 理工类211、985院校本科及以上学历；- 对技术有着永无止境的追求，自认为是技术Geek，具备很强的问题解决能力；- 熟悉Hadoop生态系统开源项目，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解，有patch源代码经验者优先；- 1年以上 Hadoop/Hive 生产环境工作经验；- 有团队管理经验者优先。    ", "北京三快在线科技有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网,O2O", "3.7"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "上海", "3-5年", "职位描述岗位职责：1.负责大数据平台的搭建；2.负责各种业务数据的采集和存储；3.负责实现数据统计和分析需求的实现和图形化展。岗位要求:1.计算机相关专业,3-5年工作，物流快递行业优先；2.熟悉数据仓库的ETL的开发和数据建模；3.精通Hadoop/Spark平台的配置和搭建,具有基础运维经验优先；4.精通MapReduce原理；5.熟悉Java, Hbase/Hive, Linux Shell编程；6.熟悉Flume配置,具有Kafka经验优先；7.具有数据可视化经验优先。", "上海联尚纵横咨询有限公司", "15-50人", "初创型(未融资)", "移动互联网,电子商务", "-"
"拉勾", "Hadoop", "Hadoop", "25000-50000", "本科", "上海", "5-10年", "职位描述1、负责大数据平台底层架构，设计数据产品的底层架构和实施，主要包括数据的采集、处理、存储； 2、负责或配合开发前端或相关接口对大数据进行分析及消费； 3、负责大数据项目的技术指导和架构设计； 4、6年以上Java开发经验，2年以上大数据相关项目开发经验； 5、团队建设及人才培养；任职资格：1、本科及以上学历，计算机相关专业； 2、2年及以上大数据流程架构经验，熟练Hbase/Hive/Hadoop或等主流分布式开发平台； 3、具有良好的逻辑分析能力、沟通能力和协调能力； 4、对文本挖掘和推荐算法有应用经验优先，有小团队管理经验优先； 5、熟练掌握 HiveSQL/Mysql/SQL Server", "上海厚本金融信息服务有限公司", "2000人以上", "成长型(A轮)", "金融", "3.6"
"拉勾", "Hadoop", "高级Hadoop/hadoop开发工程师", "10000-20000", "本科", "上海", "应届毕业生", "职位描述岗位职责：负责hadoop平台上的数据存储，数据维护和优化；编写hive-ql脚本做相关的统计计算；编写spark程序进行相关报表计算；编写map-reduce程序做相关的分析建模；职位要求：本科以上学历，1年以上相关工作经验；对数据结构、算法有深刻理解；熟悉linux开发环境；有hadoop集群部署和开发经验；熟悉java和sql开发；工作积极主动认真负责，具有良好的沟通和学习能力；", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "大专", "上海", "3-5年", "职位描述岗位职责：1、负责公司的大数据处理框架的研发设计工作；2. 对现有系统的不足进行分析，难点攻关，找到目前系统的瓶颈，改进系统架构设计，提高系统性能3. 根据用户行为分析，挖掘有价值的信息，指导公司运营和决策4、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、3年以上相关工作经验；2、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；3、精通JAVA编程语言，精通面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Haddop开发大数据处理系统；4、拥有实际的Hadoop的项目经验。工作地址", "上海好居信息科技有限公司", "500-2000人", "成长型(B轮)", "移动互联网,O2O", "3.7"
"拉勾", "Hadoop", "Hadoop工程师", "12000-17000", "大专", "上海", "不限", "职位描述岗位职责：1、hadoop相关底层应用研发工作；2、海量数据分析挖掘。职位要求：1、大专以上学历，至少一年大数据经验，熟悉linux，掌握java；2、熟悉网络编程、多线程、BOOST、ACE等工具；3、熟悉关系型与非关系型数据库；4、有hadoop、hbase、spark、strom的研发或维护经验；5、具备hadoop集群研发运维工作经验优先。", "深圳市超级符号文化创意有限公司", "15-50人", "初创型(未融资)", "移动互联网,电子商务", "1.0"
"拉勾", "Hadoop", "Hadoop 工程师", "15000-25000", "本科", "上海", "3-5年", "职位描述职位描述负责大数据平台基础平台设计和实现. 包括但是不限于hadoop/Hive/Hbase/storm/spark/数据仓库引擎的设计和实现. 保证大数据平台的稳定,高效为负载的大数据业务提供保障.职位要求计算机及相关专业，熟练掌握各类常用数据结构和相关算法有3年以上 Hadoop/Hive/Hbase/spark 生产环境工作经验，有MR开发和分析经验。互联网、电商行业优先熟悉 Hadoop/Hive/Hbase 原理及运维、调优方法，阅读和修改过源代码者优先良好的数据敏感能力，敏锐而富有耐心熟悉python、shell、php 至少1种很强的工作责任心和良好的沟通协调能力，能在压力下独立解决问题有钻研精神，对技术、大数据充满热情，有团队合作精神符合以下任一条件者优先有数据平台，搜索，广告等领域研发经验熟悉mysql/memcached/mongo/redis等开源框架 ，有T级及以上大规模数据处理经验了解数据仓库基本理论，有数据仓库建模经验具有以下任一或以上领域相关的理论背景：机器学习/数据挖掘/信息检索/自然语言处理具有机器学习、自然语言处理、人工智能研发和应用经验", "上海西示网络科技有限公司", "50-150人", "成长型(A轮)", "移动互联网,旅游", "3.9"
"拉勾", "Hadoop", "Hadoop/Spark数据开发工程师", "25000-35000", "本科", "北京", "5-10年", "职位描述职位描述：岗位职责：1.搭建大数据平台，为海量数据的处理和分析提供高效解决方案；2.研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；3.维持线上服务高效稳定，支撑业务和数据量的快速扩张。任职要求：1.5年以上大型数据平台工作经验，扎实的计算机系统和算法基础知识；良好的英文阅读能力；2.扎实的Java语言基础，对JVM运行机制有深入了解；3.熟悉Hadoop、Spark并有丰富的开发经验；4.对常见开源框架代码有研究；5.熟悉SQL和noSQL的设计和开发；6.熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等；7.善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新；8.责任心强，具备良好的团队合作精神；9.有深入研究过Hadoop/Spark源码者优先。", "北京东奥时代教育科技有限公司", "500-2000人", "成熟型(不需要融资)", "电子商务,教育", "4.2"
"拉勾", "Hadoop", "视频-产品技术中心-Hadoop开发工程师", "15000-20000", "本科", "北京", "3-5年", "职位描述岗位职责:1、参与hadoop及其周边系统的运维工作，包括hdfs、yarn、flume、kafka、spark等；2、基于大数据处理平台的模型设计与数据处理工作；3、Hadoop相关业务脚本的性能优化与提升，不断提高系统运行效率；4、参与hadoop中间件的开发工作。任职资格:1、计算机软件相关专业本科或以上学，JAVA3年以上开发经验； 2、熟悉Hadoop/Spark生态环境体系的搭建和管理；有大平台架构开发经验；具有实际集群搭建和调优经验；3、精通Java、Scala开发，掌握Hadoop、Spark、HBase、MapReduce、HDFS Hive、Zookeeper、flume、kafka等开源项目的原理和使用方法；4、具备大规模并行计算spark等开发经验者优先考虑；5、富有创新精神，对解决具有挑战性的问题充满激情。", "北京搜狐新动力科技有限公司", "500-2000人", "上市公司", "文化娱乐", "3.0"
"拉勾", "Hadoop", "Hadoop", "12000-20000", "本科", "北京", "3-5年", "职位描述岗位描述:1、负责基于大数据平台的海量数据存储、多种来源、多种数据结构等数据采集等工作；2、负责基于大数据平台的数据处理、数据分析等工作；3、负责大数据平台的建设部署及日常监控及运维。任职资格：1、大学本科以上，有2年及以上大数据平台开发及运维经验；2、精通scala，java等编程语言。2、熟悉Hadoop技术体系，包括Hbase\\Hive\\Impala\\Kafka\\Spark等相关技术，具有Hbase\\Hive\\Impala\\Spark的相关开发经验；4、具有数据仓库开发经验。5.开发过用户画像系统优先。", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "Hadoop工程师", "15000-20000", "本科", "上海", "不限", "职位描述岗位职责：负责Hadoop集群的搭建、管理与维护；负责Hadoop平台中数据存储、维护及结构优化；负责Hadoop上的数据项目开发，HDFS、HBase、Hive等；对医学临床数据进行数据提取及转换、数据挖掘及分析。岗位要求：熟悉主流Linux操作系统的配置、管理及优化，能够独立排查系统配置问题；熟悉Hadoop集群的部署与性能调优；熟悉Java/Python/Perl等开发语言的其中一种或多种；有医疗临床数据经验者优先；良好的沟通技巧接团队协作能力；有较强的意愿及能力学习适应新的技术。", "新屿信息科技（上海）有限公司", "50-150人", "成长型(A轮)", "数据服务", "4.9"
"拉勾", "Hadoop", "Hadoop研发工程师", "15000-30000", "硕士", "北京", "不限", "职位描述工作职责：设计和开发昆仑数据自主研发的KMX机器大数据平台实现千万测点/秒机器数据7*24小时采集、存储、查询和分析；实现KMX性能优化、高可用和故障恢复；为KMX上线系统提供专家支持；岗位要求：211、985本科及以上学历，计算机、电子工程，数学相关专业；（必要）扎实的编程基础，熟悉Java开发，理解面向对象方法;深入了解数据库管理系统、操作系统和分布式系统实现原理；熟悉Linux操作系统和脚本语言；良好的沟通和分析问题与解决问题能力；有责任心，工作积极，对新技术有热情；优先条件：熟悉Kafka, Storm, MapReduce, HDFS, Zookeeper, Impala等开源项目，用主流产品处理TB以上数据，能应对发布版的bug，理解主流产品的性能特性；能阅读和理解顶级会议（SIGMOD/VLDB)大数据系统相关论文，理解优缺点和技术方向；复杂分布式系统功能和性能调试、并发错误调试、内存泄漏调试、性能profiling、加速比提升等；有Docker、DevOps和敏捷开发经验；有企业级产品开发经验；", "昆仑智汇数据科技（北京）有限公司", "50-150人", "成长型(B轮)", "数据服务", "4.4"
"拉勾", "Hadoop", "大数据运维工程师（hadoop运维）", "15000-30000", "本科", "北京", "3-5年", "职位描述主要职责：- 负责公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；- 负责公司分布式存储的设计，选型和开发；- 负责大数据基础架构平台的监控、资源管理、数据流管理；- 负责自动化运维系统及平台的建设。职位要求：- 有一定的java开发工作经验，熟悉MapReduce原理；- 掌握Linux操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；- 掌握Hadoop, Kafka, Zookeeper, Hbase, Spark的安装与调试；- 至少精通Python, Perl, Ruby, Bash脚本语言中的一种；- 有良好的系统性能优化及故障排除能力；- 熟悉大数据周边相关的数据库系统，关系型数据库和NoSQL；- 熟悉Puppet, Chef, Ansible等配置管理工具。加入宜人贷Family，你将get：1.国内第一家纽交所上市，顶尖互联网金融平台，繁华CBD办公环境。2.令人振奋的薪酬（13~18薪六险一金我会乱说?），还有14天超长春节带薪年假。3.弹性上下班不打卡，各种兴趣俱乐部一起嗨。4.大牛多多供你调戏，妹子还会为你准备花式下午茶。还有5、6、7、8......关注“宜人贷招聘”公众号，了解更多最新岗位详情；加入宜人贷精英交流QQ群：541109383 ，直接与HR对话；快来与宜人贷一起，雕刻专属于你的神奇吧！", "普信恒业科技发展（北京）有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网,金融", "3.9"
"拉勾", "Hadoop", "高级hadoop开发工程师", "15000-25000", "本科", "北京", "3-5年", "职位描述工作职责：1、从事部门大数据相关的平台实施、运维、培训等工作。        2、完成对事业部各智慧城市IOC项目的支援和建设。          3、大数据支撑平台相关产品的开发、测试。任职要求：1、必备知识：本科学历，计算机或者相关专业。对Linux SQL基础有很强的掌握。 2、计算机技术：.熟悉hadoop体系架构，熟悉 hbase、hive、zookeeper等工作原理；熟练掌握Hive，并有相当优化经验，理解 Hbase 体系架构，并有相当开发经验；熟练Java编程语言，深入理解面向对象编程思想；熟悉某种关系型数据库（oracle、Mysql）；.熟练掌握linux/UNIX shell 、熟悉(Perl/python/shell)任意一种脚本语言；              3、工作经验：至少1年以上工作经验，1-3年大数据经验。至少1年以上真实的Hadoop平台使用经验，必须有hadoop集群搭建实际经验；   4、个人素质要求：目光长远、态度诚恳、岗位有稳定性，能够长期培养、具备很强的自学能力、承压能力强、接受出差支援项目等工作。对coding有浓厚的兴趣并有明确职业规划，优秀的学习能力和团队沟通协作能力，对新技术有浓厚兴趣并有钻研精神。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop平台测试工程师", "8000-10000", "本科", "北京", "1-3年", "职位描述联想企业大数据平台是帮助企业快速实施大数据系统并发现数据价值的统一管理平台。此岗位将参与联想企业大数据平台测试工作。负责大数据平台的相关测试工作，完成测试方案、测试用例的设计、执行工作1)熟悉Linux开发环境，熟悉一款主流数据库，能看懂和编写SQL语句。2)熟悉Hadoop生态圈，了解hdfs，mr，hive，hbase等模块。3)熟悉Java语言， 能独立编写脚本者优先。4)有软件开发经验优先。有大数据、BI相关工作经验者优先。2年以上Linux/Java测试经验 或1年以上Hadoop/Spark平台测试经验", "北京联想利泰软件有限公司", "500-2000人", "初创型(未融资)", "移动互联网,招聘", "3.9"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "北京", "1-3年", "职位描述岗位职责：1、负责Hadoop平台的部署、开发和维护；2、利用大数据平台实现对数据的分析和处理；3、负责大数据平台的性能参数调整和优化；4、参与大数据平台的设计；5、负责相关项目的技术支持和服务。任职要求：1、了解Linux操作系统，熟练掌握操作系统基本原理概念；2、熟悉常用的数据结构和算法；3、了解Hadoop构架体系，了解Hadoop生态系统相关开源项目和其基本原理；4、至少熟练掌握一种编程语言，如 java、C语言；5、具有通信、计算机、软件、数学等相关专业本科或以上学历；掌握以下技能中的某项或多项者优先：1、有大数据分析经验优先；2、掌握一种脚本语言perl、Python、Bash等中的一种脚本语言。", "北京浩瀚深度信息技术股份有限公司", "150-500人", "上市公司", "硬件,数据服务", "4.7"
"拉勾", "Hadoop", "Hadoop", "18000-25000", "大专", "上海", "3-5年", "职位描述Spark、storm,metaq集群搭建、运维、调优以及Topology计算逻辑实现1、三年以上软件开发和设计经验，两年实时计算设计开发经验；2、熟悉Hadoop，具有1年以上Spark/Storm等实时/准实时数据处理平台开发经验；3、精通Java语言，熟悉Shell编程，熟悉Linux系统；4、精通网络编程、多线程编程、Java服务器后台编程，深入理解分布式系统；5、对于大规模数据存储和处理有丰富的经验，对于系统性能优化有实践经验", "上海德邦物流有限公司", "2000人以上", "成熟型(不需要融资)", "企业服务", "3.9"
"拉勾", "Hadoop", "Hadoop 数据平台开发", "15000-20000", "本科", "北京", "1-3年", "职位描述新浪集团大数据平台开发团队，负责：1、Hadoop 集群的开发、调优、监控等工作；2、为 Hadoop 集群使用用户提供技术支持；", "新浪网技术（中国）有限公司", "2000人以上", "上市公司", "文化娱乐", "4.3"
"拉勾", "Hadoop", "Hadoop", "12000-18000", "本科", "北京", "3-5年", "职位描述1、大学本科以上，有3年及以上大数据平台开发经验；2、精通java等编程语言。2、熟悉Hadoop技术体系，包括Hbase（硬性）\\Hive\\Impala\\Kafka\\Spark等相关技术，具有Hbase（硬性）\\Hive\\Impala\\Spark的相关开发经验；", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "Hadoop平台测试工程师", "8000-10000", "本科", "北京", "1-3年", "职位描述项目背景：联想企业大数据平台是帮助企业快速实施大数据系统并发现数据价值的统一管理平台。此岗位将参与联想企业大数据平台测试工作。主要职责：负责大数据平台的相关测试工作，完成测试方案、测试用例的设计、执行工作。岗位描述1)熟悉Linux开发环境，熟悉一款主流数据库。2)熟悉Hadoop生态圈，了解hdfs，mr，hive，hbase等模块。3)熟悉Load Runner/JMeter/Selenium等一款常用测试工具者优先。4)熟悉JS、CSS语言者优先。 5）2年以上Web测试经验 或1年以上Hadoop/Spark平台测试经验", "北京联想利泰软件有限公司", "500-2000人", "初创型(未融资)", "移动互联网,招聘", "3.9"
"拉勾", "Hadoop", "Hadoop", "7000-10000", "本科", "合肥", "1-3年", "职位描述岗位职责：1、熟悉Linux操作系统的基本概念和应用，熟练使用BASH或Python中的至少一种进行数据文件分析；2、熟悉Java开发，熟练掌握Java集合类、IO、并发变成，并熟悉Jvm原理及内存管理；3、熟悉海量数据分析相关的数据结构和算法；4、熟悉Hadoop、PIG、HIVE、HBase等分布式开源项目和基本原理，有丰富的集群部署、开发和维护管理经验；任职要求：1、具有通信、计算机、软件、数学等相关专业本科或以上学历。本科阶段毕业于国家统招的正规院校。2、有带团队工作经验者优先；3、对规范化、标准化、团队化软件开发有正确理解和认识，具有良好的代码和技术文档编写习惯；4、身体健康，有良好的敬业精神、学习能力和团队协作能力，勇于迎接挑战。", "北京浩瀚深度信息技术股份有限公司", "150-500人", "上市公司", "硬件,数据服务", "4.7"
"拉勾", "Hadoop", "Hadoop大数据高级工程师", "18000-25000", "本科", "北京", "3-5年", "职位描述【岗位职责】1. 负责公司大数据平台搭建、功能设计、及核心模块的开发；2. 参与公司内外部大数据项目的需求分析及数据建模、方案评估；3. 对现有大数据架构进行分析，并给出优化建议；4. 编写大数据技术方案及大数据平台设计开发规范；5. 能够带领并指导大数据小组进行研发；6. 相关数据源及应用，涉及车联网、导航、自动驾驶等； 【职位要求】  1. 计算机软件及相关专业，本科及以上学历；2. 2年以上大数据处理经验；3. 精通Java编程，具备扎实的数据结构与算法功底；4. 熟悉hadoop技术体系，hive、pig、hbase、sqoop等开源项目；5. 对hadoop底层原理及及实现有深入的理解，有实际hadoop集群搭建及维护经验；6. 理解MapReduce计算框架的思想，熟悉分布式计算模型；7. 熟练使用Kafka、Flume等开源数据收集工具；8. 有互联网分布式大数据挖掘、分析、熟悉Mahout及分析算法优先；9. 热爱大数据技术，主观能动性强，性格积极乐观，良好的沟通能力，工作认真、严谨，有团队精神；", "北京图为先科技有限公司", "150-500人", "成熟型(D轮及以上)", "移动互联网,企业服务", "3.6"
"拉勾", "Hadoop", "Hadoop(002403)", "8000-10000", "本科", "深圳", "3-5年", "职位描述岗位职责:1、负责卡中心大数据系统（包括Hadoop、Hive、Spark、ElasticSearch、Kafka等，下同）的规划设计及建设、系统集成等；2、负责卡中心大数据系统的日常运维管理，如业务及系统监控，故障应急处置，变更管理、容量管理、备份恢复、性能调优、切换演练等；任职资格:1、本科以上学历，计算机或者相关专业，3年及以上工作经验；2、熟悉Linux，精通Greenplum/PostGreSQL/Hadoop等其中至少一种主流分布式数据库运维管理，包括但不限于规划设计、安装、部署、配置、升级、扩容、迁移、性能调优及故障诊断等；3、掌握shell/perl/python等其中至少一门脚本语言，熟悉SQL开发、分析及调优，了解java/scala；4、熟悉Hive、Hbase、Yarn、Spark、Storm、Kafka等组件的原理及运维管理；5、性格开朗，能持续承受较大工作压力和工作强度，愿意挑战自我潜能，有优秀的敬业精神；6、具有良好的沟通协调能力和团队合作精神，较好的文档撰写能力，乐于与善于学习新知识新技术。1、拥有大型互联网或者金融行业从业经验者优先；2、具有大数据开发经验优先；", "中信银行股份有限公司信用卡中心", "2000人以上", "上市公司", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "北京", "1-3年", "职位描述岗位职责：基于大数据平台，为公司业务提供分布式计算及推荐服务任职要求：1、1年以上Hadoop的Java开发经验2、熟悉Yarn,Hadoop,并能够独立进行Map-Reduce应用开发3、具有良好的分析和解决问题能力，对攻关疑难问题具有浓厚兴趣4、有实际的hadoop集群部署经验有以下一项或多项经验者优先考虑：1、有推荐系统开发经验者优先；2、有mahout二次开发者优先；3、掌握Shell或Python脚本者优先4、有大规模、高性能互联网网站系统相关的设计和开发经验者优5、有海量数据挖掘算法开发经验者优先。", "美信网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "社交网络,电子商务", "4.4"
"拉勾", "Hadoop", "Hadoop", "12000-24000", "本科", "北京", "3-5年", "职位描述1. 精通Hadoop、Hbase、Hive、ZooKeeper， 熟悉Map/Reduce编程，两年以上Hadoop实际开发经验；2. 熟悉Mysql数据库、Oracle等数据库，可熟练编写SQL； 3. 熟悉Linux开发环境，熟练部署和维护Hadoop平台； 4. 有Spark或Redis、Storm计算技术优先。", "北京汇通金财信息科技有限公司", "150-500人", "成长型(不需要融资)", "电子商务,金融", "4.0"
"拉勾", "Hadoop", "hadoop运维", "15000-25000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责Hadoop平台的容量规划、部署、及扩容；2、负责Hadoop平台各组件服务的监控及故障处理；3、负责Hadoop平台的用户管理、权限分配、资源分配、性能优化；4、负责撰写相关技术文档；职位要求：1、了解Hadoop、Hbase、Kafka、Hive、Spark等组件的工作原理，并有2年以上Hadoop生态系统运维经验；2、精通一门以上脚本语言（shell、Python、perl）；3、具备团队合作精神、责任心强，善于沟通；4、熟悉Cloudera优先；我们为您提供：1、工资奖金——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；2、五险一金——按工资基数全额缴纳五险一金；3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；4、多种激励——月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；5、员工旅游——春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！7、健康体检——每年一度的健康体检让您的身体定期做个检查；8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；9、上班时间——每天弹性工作制，错峰上下班；10、培训分享——新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！", "竞技世界（北京）网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,游戏", "4.2"
"拉勾", "Hadoop", "数据分析工程师（Hadoop/Hive）", "8000-14000", "本科", "北京", "1-3年", "职位描述数据分析工程师职位描述：1、负责数据仓库各种主题的离线数据的集成、清洗和统计等开发工作；2、根据业务和产品需求提取数据和抽象出常态化分析，自动提供数据结果，为数据可视化提供支持；2、配合业务等部门构建BI；职位要求：1、具有一定独立分析，技术研究能力，具有良好的团队合作精神；2、有过linux开发经历，熟练使用shell脚本；3、精通Hadoop，具有Hive、Hbase、等有实际应用开发经验；4、熟悉MapReduce思想，熟悉ETL开发过程，具有Hive使用及优化经验，熟悉UDF/UDAF/UDTF开发；5、熟悉php，python，perl其中一种脚本语言者优先；6、有过MySql开发经验者优先；正式员工福利：五险一金，商业补充医疗保险，带薪年假，年终奖金，通讯补助，节日福利，生日福利，员工旅游等", "北京卓思天成国际市场研究咨询有限公司", "150-500人", "初创型(未融资)", "企业服务", "-"
"拉勾", "Hadoop", "Hadoop工程师", "8000-10000", "本科", "成都", "3-5年", "职位描述岗位职责：1、负责相关大数据服务产品的设计及开发2、参与产品技术架构设计与技术方案评估3、负责大数据平台的相关新技术研究4、参与大数据平台的安装部署与维护任职要求：1、本科以上，计算机或相关专业，具有三年以上大数据平台开发经验；2、熟悉linux开发环境，能够熟练使用shell、python等脚本；3、熟悉Hadoop、HDFS、Hbase、Hive、Spark、Storm等分布式计算框架；4、熟悉oracle、mysql等数据库技术优先；5、有两个以上Java项目经验或大数据项目经验；5、对大数据分析处理有强烈兴趣，乐于接收挑战，自学和独立工作能力强，勤奋肯干，有责任心；", "成都数联易康科技有限公司", "15-50人", "初创型(未融资)", "数据服务,医疗健康", "-"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "北京", "5-10年", "职位描述岗位职责：1. 协助建立和维护公司大数据存储及管理的技术基准，参与规划大数据平台硬件和软件结构；2. 负责协助编制、优化大数据平台管理、运维流程及规范；3. 独立负责某细分专业领域或研发流程环节的研究工作，独立解决常规性技术问题；4. 参与大规模数据的业务分析、采集处理、分布存储、应用、安全等解决方案的设计、开发与优化；5. 参与大数据平台的日常管理及运维；6. 负责相关大数据存储及应用技术的具体开发；7. 开展大数据存储及应用技术的应用培训和客户服务；8. 协同数据架构师进行大数据存储、安全及应用架构最新技术的跟踪调研、分析。任职要求：1.本科以上学历，计算机、电子、数学等相关专业；2.三年以上相关专业工作经验，2年以上大数据建设及应用相关职位工作经验；3.了解数据库相关理论知识，对关系型数据库、数据仓库、分布式数据库等有一定了解，具有一定的数据库设计及管理经验；4.熟悉与数据架构设计相关的数据存储、性能调优、负载均衡、容错、安全等相关知识，具有实际大数据存储和应用的设计及开发经验，能够解决项目过程中的技术难题；5.熟悉Hadoop分布式系统架构，了解分布式文件存储，了解Hive、HBASE、Zookeeper、Chukwa、Storm、Spark、Sqoop等原理且具有实际安装、配置、调优、管理及应用开发经验；6.熟悉至少一种主流数据库系统（如Oracle/Mysql/ PostgreSQL/MongoDB等）的安装、配置、调优、维护及管理，精通Sql语言；7.具有NoSQL、Key-Value 存储设计、开发及实施经验、数据分析及BI展示应用设计及实施经验优先；职位发布者yangjunna 招聘 66%                        简历及时处理率                        投递后7天内处理完成的简历所占比例5天                        简历处理用时                        完成简历处理的平均用时你在拉勾还没有简历呢，你可以完善在线简历，也可上传附件简历直接投递投个简历", "北京东润环能科技股份有限公司", "150-500人", "上市公司", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "资深Hadoop工程师", "18000-30000", "本科", "上海", "3-5年", "职位描述一、工作职责1、负责Hadoop集群相关的开发、调优、监控等工作；2、负责Hbase、Spark项目开发、实施工作；3、负责数据平台的基础架构设计和优化工作。二、任职要求1、深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理；2、熟练掌握Java开发，有开源软件源码阅读和fix经验者优先；3、技术Geek,对技术有很高的热情；4、有大规模Hadoop集群运维经验者优先；5、具有快速解决问题的能力和较强的学习能力；6、熟悉linux系统；7、附上github地址或blog地址有加分。", "拉扎斯网络科技（上海）有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网", "4.0"
"拉勾", "Hadoop", "Hadoop工程师", "15000以上", "本科", "上海", "1-3年", "职位描述关于复歌我们是一家技术公司，核心产品叫妙算机，是针对中国市场开发的搜索引擎广告管理平台。用户可在妙算机中管理百度、360、搜狗、谷歌、淘宝等竞价广告平台，并利用优化算法和自动化功能提升广告效果，提高工作效率。我们的客户包括品牌客户和4A公司，包括欧莱雅旗下的牌子（兰蔻、美宝莲、碧欧泉…）、LVMH的牌子（LV, Dior...）、中国电信、实力转播等等等等。复歌的目标为中国企业提供一款整合所有线上营销渠道的牛逼工具。你应该成为复歌一员的10个理由1. 不少的钱 和 巨多钱的可能2. 和一群牛逼又好玩的人一起工作3. 有真的长得好看的单身姑娘和小伙4. 从入职的第一年起，拥有10天带薪假期5. 2号线、12号线、13号线南京西路站步行5分钟的办公室6. 不需要你讨好的老板7. 水果+咖啡+零食无限供应8. 只有15和30分钟两种会9. Happy Hour/周 + 吃喝玩乐/月 + Outing/年10. ……当想不到第10条时，空着就可以，不需要硬编一条需要你：1. 负责公司的大数据处理框架的研发设计工作；2. 基于Hadoop进行MapReduce、Hive和HBase的应用开发；3. 维护和管理大规模Hadoop集群，解决不断增长的海量数据带来的存储和计算挑战。希望你：1. 有扎实的Java编程功底，熟悉常用的数据结构，深入理解面向对象、MVC等相关概念，热爱编程；2. 熟悉Hadoop/HBase生态环境体系的搭建和管理，掌握Hadoop、HBase、MapReduce、HDFS、Hive、Pig、Zookeeper等开源项目的原理和使用方法，具有实际集群搭建和调优经验；3. 掌握至少一种NoSQL数据库，拥有实际的Hadoop的项目经验；4. 代码质量精益求精，注重性能，良好的代码管理及重构意识，逻辑思维清晰；5. 熟悉Linux基本命令，能基于Linux环境进行开发；6. 一年以上互联网产品开发经验；7. 良好的沟通协作能力，较强的学习能力，责任心强。如有以下经验，优先考虑：1. 熟悉一种或多种以下语言（shell、ruby、python、scala、golang）2. 大规模高并发访问的Web应用架构设计和开发经验者优先，有主导大型成功项目经验者优先。3. 熟悉storm，flume，spark，kafka，redis；4. 将Linux或OSX作为桌面系统使用者；5. 有互联网广告行业工作经验者。最后：加入一家创业公司，通常都是个比较艰难的决定，因为你必须离开一些已经习惯了的舒适感，去面对远超预期的困难和压力，做很多自己没做过的事儿并为之承担责任。为了所谓内心的荣耀，而结果却非常非常可能是失败。所以绝大多数人，不会这么做。但总有那么一些人，天生就跟绝大多数人不一样。你怎么想？", "上海复歌信息科技有限公司", "15-50人", "初创型(天使轮)", "企业服务,数据服务", "-"
"拉勾", "Hadoop", "数据工程师（Hadoop）", "11000-16000", "本科", "广州", "1-3年", "职位描述工作职责：1.在技术总监的领导下，负责数据分析平台的设计与搭建2.负责产品架构演化，性能调优技能要求1.熟悉C/C++/JAVA/PYTHON语言中一种，有海量数据处理和并行计算开发经验2.熟悉Hadoop、Hive、Spark、Impala、Storm中一种或多种技术，熟悉MapReduce编程3.熟悉但不限于聚类，个性化标签，属性挖掘等领域4.具备金融行业数据开发、有海量数据分析、熟悉大规模推荐系统经验者优先5.良好的业务理解与建模能力，能够快速学习新领域6.良好的团队合作精神，较强的沟通能力和钻研能力", "广州玄润信息科技有限公司", "15-50人", "初创型(不需要融资)", "移动互联网,信息安全", "-"
"拉勾", "Hadoop", "Hadoop 大数据应用研发工程师", "12000-24000", "大专", "广州", "3-5年", "职位描述岗位职责：1、负责金融hadoop平台中间层的设计、跟进平台开发项目;2、处理金融业务的数据统计和分析需求；3、参与金融客户画像，分析金融客户的行为特征、路径、产品偏好、营销响应情况。任职要求：1、有至少2年hadoop平台编程经验,熟悉hive、hbase、mr，flume、hdfs、spark2、能独立处理业务数据需求，熟悉SAS和SQL优先；3、熟悉基本的数据分析方法，对数据具有足够的敏感性；4、有互联网，金融，电商数据处理工作，客户画像和金融大数据分析经验者优先；5、良好的团队合作精神和解决问题分析能力。6、熟悉kylin、lens优先", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "企业服务,金融", "3.8"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "北京", "3-5年", "职位描述1.3年以上的大数据相关工作经验；2.扎实的java或者scala基础，对JVM的工作原理以及调优有深入的了解；3.熟练的多线程以及NIO的开发，熟练多种数据结构算法的开发；4.熟悉Hadoop、Hive、spark、storm、hbase的工作原理和思想，能够开发基于hadoop之上的数据应用；5.熟悉zookeeper开发，能够开发高效、自动故障切换的分布式应用；6.熟悉netty+protobuf、mina、thrift等至少1种轻量RPC实现；7.熟悉linux，熟练开发shell脚本；8.熟悉JMX框架，有相关研发经验者优先。", "美信网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "社交网络,电子商务", "4.4"
"拉勾", "Hadoop", "Hadoop", "13000-17000", "本科", "北京", "3-5年", "职位描述1.负责基于大数据平台的海量数据存储、多种来源、多种数据结构等数据采集等工作；2、负责基于大数据平台的数据处理、数据分析等工作；3、负责大数据平台的建设部署及日常监控及运维。任职资格：1、大学本科以上，有2年及以上大数据平台开发及运维经验；2、精通scala，java等编程语言。2、熟悉Hadoop技术体系，包括Hbase\\Hive\\Impala\\Kafka\\Spark等相关技术，具有Hbase\\Hive\\Impala\\Spark的相关开发经验；4、具有数据仓库开发经验。5.开发过用户画像系统优先。（不接受外派的勿扰，谢谢）", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "广州", "1-3年", "职位描述大数据平台工程师工作职责：1、基于hadoop、spark等构建数据分析平台，进行设计、开发分布式计算业务;2、辅助管理Hadoop集群运行，稳定提供平台服务;3、搭建数据开发、部署的流程，保证日常数据稳定、安全、准确；岗位要求：1、计算机相关专业本科及以上学历，1年以上编程经验，熟悉hadoop原理、熟悉hadoop集群的搭建、管理及优化；2、熟悉HDFS/HBase/Hive/MapReduce，有丰富的分布式编程及海量数据处理经验；3、熟悉Core Java, 熟悉Java IO, NIO, 多线程编程. 熟悉JVM运行机制和内存管理, 网络协议；4、熟练掌握Linux操作系统，熟悉shell等脚本编程；5、熟悉storm、kafka、spark streaming等CEP流式计算技术优先;", "广州永哲信息技术有限公司", "50-150人", "成长型(不需要融资)", "移动互联网", "-"
"拉勾", "Hadoop", "Hadoop开发", "15000-20000", "硕士", "北京", "应届毕业生", "职位描述岗位职责：1.负责游戏运营平台数据中心的开发以及相关技术研究，解决实际发生的问题；2.负责游戏运营平台数据中心的数据需求分析、数据统计、分析和建模。任职要求：1.有Hadoop实际项目工作经验；2.熟悉Hadoop、HBASE、Hive、Spark等分布式计算平台；3.熟悉Linux，熟练使用Shell脚本；4.精通SQL，有较好的SQL性能调优经验，最好有Hadoop,Hive,Hbase开发经验；5.熟悉Postgresql、Mysql等关系型数据库及常用SQL；6.良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力；7.对数据挖掘实际工作经验者优先；8.有游戏相关相关工作经验者优先；", "北京青果灵动科技有限公司", "150-500人", "成长型(不需要融资)", "游戏", "4.7"
"拉勾", "Hadoop", "大数据平台高级工程师（Hadoop）", "10000-20000", "本科", "成都", "3-5年", "职位描述大数据平台高级工程师关键字：大数据平台,hadoop,spark工作内容：1负责大数据平台架构、构建、开发和维护2完善大数据平台能力建设，负责平台工具开发，平台组件二次开发3编写需求、设计文档，参与核心开发及开发团队指导、技术培训等职位要求：1本科以上学历，三年及以上工作经验，能力强者可相应放低要求2熟悉java/scala/python/shell至少两种语言，熟悉Linux操作系统,熟悉maven,sbt等主流编译工具3熟悉hadoop,hive,hbase基本原理，熟悉spark,ES,ranger,falcon,slider,zookeeper,amabri等相关技术，有HDP实际部署、运维经验4熟悉docker等容器技术，熟悉mesos，cgroup等资源调度，有实际使用、调优、问题解决经验优先考虑5熟悉mongodb,redis,tachyon,apacheingite等内存技术6有责任心，良好的团队合作精神，积极上进，能承受一定工作压力7有很强的学习能力，优秀的分析、问题抽象和解决问题。可以阅读英文官方文档8熟悉电信相关业务，有银行业、电商行业、相关大数据行业二年以上工作经验优先考虑", "深圳天源迪科信息技术股份有限公司", "2000人以上", "上市公司", "移动互联网 ,电子商务", "2.9"
"拉勾", "Hadoop", "hadoop工程师", "15000-25000", "不限", "上海", "5-10年", "职位描述岗位描述：负责数据平台基础架构搭建工作。包括数据埋点，采集，数据同步、数据校验、存储、前端UI等工作。岗位要求：1、3年以上JAVA编程经验；2、熟悉mysql,oracle数据库。熟练运用mybatis,ibatis,spring等常用框架；3、有hadoop集群日常运维工作经验，包含hbase,kafka,zookeepr,hive,sqoop有实际使用经验；4、有web开发经验，熟悉javascrip，熟悉常用shell命令。", "好买财富管理股份有限公司", "500-2000人", "成熟型(C轮)", "电子商务,金融", "3.6"
"拉勾", "Hadoop", "数据库开发工程师（BI,ETL/hadoop）", "10000-20000", "大专", "上海", "1-3年", "职位描述BI/ETL数据库开发工程师岗位职责：负责银行金融项目数据库开发工作任职要求：1、熟悉DB2、ORACLE等大型数据库之一，能熟练运用SQL2、熟悉Linux/AIX基本命令3、能够独立编写shell脚本，理解能力好，责任心强，具有一定的沟通能力4、双证齐全，有ETL/BI经验优先5、薪资根据个人能力面议2.hadoop开发工程师岗位职责：1、负责搭建hadoop集群，并维护与管理；2、负责hadoop平台上的数据存储，数据维护和优化；3、负责进行Hadoop、Hive、Hbase项目开发；4、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题;5、根据项目设计文档，完成项目模块的设计与开发；任职要求：1、本科以上（含本科）计算机、数学等相关专业；2、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；3、熟悉java开发(精通优先考虑)；4、熟悉SQL语言；5、熟悉linux开发环境；6、熟悉shell、perl、python中的一种；7、有hadoop集群部署和开发经验者优先；8、熟悉hadoop、hive、impala、kafka、flume等，对hive、impala开发有实际经验者优先；9、有银行业工作经验，熟悉银行业务者优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "金融", "3.9"
"拉勾", "Hadoop", "spark/hadoop工程师", "7000-12000", "不限", "杭州", "1-3年", "职位描述岗位职责：负责改进、维护流计算统计基础平台；负责Spark数据处理、统计、挖掘工作(20亿数据/天)；数据仓库的设计、开发、维护；机器学习算法开发、完善。任职要求：精通Scala或JAVA任一语言；熟悉Spark或Hadoop任一框架；熟悉Linux和IDE开发环境；对Hive/HBase/zookeeper/Kafka/Flume熟悉优先；机器学习算法包熟练优先；福利：1. 五险一金是必须滴；2. 双休也是必须滴；3. 完善的培训（入职培训+岗位技能培训+产品培训）；4. 员工成长计划，让你看到自己的进步；5. 老带新制度，每一个入职的新人都会有老同事一对一指导。6. 年休假满1年5天；7. 每年一次体检，关爱你的健康；8. 每年两次旅游，我们都爱玩~9.每月举办各种的团建活动~10.年终奖....写不下了，总之，我们崇尚“认真工作，快乐生活”，欢迎加入我们！", "杭州酷玛网络技术有限公司", "15-50人", "成长型(A轮)", "电子商务,数据服务", "4.4"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "成都", "5-10年", "职位描述一、岗位职责：1、参与hadoop大数据平台的相关项目开发和应用实施，负责平台维护和优化；2、参与历史数据库与数据仓库数据运维管理，性能分析及应用调优；3、参与历史数据库、数据仓库的建模开发和建设维护工作；4、参与数据集市、数据分析门户、BI的建设及维护；5、负责数据应用实施项目的维护、管理优化和推广培训工作。二、任职资格：1、全日制本科及以上学历，计算机相关专业，4年以上工作经验；2、熟悉关系型数据库，熟悉存储过程开发，熟悉脚本语言开发；3、精通基于Hadoop的Java开发，熟悉Linux系统；4、熟悉Zookeeper、Spark Streaming、Pentaho；5、具有较强的责任心、执行力，有良好的沟通技巧和团队合作精神；6、在大数据处理和分析领域具有技术规划、架构设计经验者优先；7、有电信行业、互联网行业大数据处理经验者优先。", "四川创立信息科技有限责任公司", "150-500人", "上市公司", "移动互联网,硬件", "3.8"
"拉勾", "Hadoop", "Hadoop", "13000-22000", "本科", "北京", "1-3年", "职位描述岗位职责：参与设计、研发大数据处理平台；帮助平台用户快速构建基于大数据的数据产品和应用，将大数据快速转变成商业价值；从事大数据的并行计算、实时流计算的研究和开发；从事大数据数据挖掘、数据分析的研究和开发；负责数据仓库系统和hadoop集群的审核、部署、发布、监控、维护和优化。负责大数据系统的性能分析与系统优化，不断提高系统运行效率。任职要求:本科以上学历，计算机或者相关专业。熟悉Linux或Unix系统，熟悉网络技术，尤其是TCP/IP协议，2年以上大规模集群的运维经验，熟悉ganglia/salt/puppet等监控和管理工具；熟悉Hadoop平台及主要子项目，有一年以上Hadoop平台mapreduce的开发经验；熟悉shell,perl,python,php至少一种，有java,C/C++语言基础更好；对Hadoop、HBase、Storm、Zookeeper、impala或MPI之一有深入理解并在现实项目中大规模应用；熟悉MongoDB、Redis、Memcache 其一，对pig,hive,hbase, spooq,flume,scribe有研发经验者优先；熟悉HDFS、Hbase、Hive的原理、特性和常用配置且有实战开发经验；具备快速学习掌握新知识的能力，优秀的分析、解决问题能力，具备良好的抽象归纳能力和创新能力；熟悉Storm、Spark等实时统计技术有相关实战经验者优先。", "时趣互动（北京）科技有限公司", "500-2000人", "成熟型(D轮及以上)", "移动互联网", "4.0"
"拉勾", "Hadoop", "大数据开发工程师（Hadoop）", "15000-20000", "本科", "深圳", "3-5年", "职位描述岗位职责：1、从事Hadoop、Spark、Storm等分布式大数据平台产品的设计和开发；2、针对部门大数据业务进行大数据分析、挖掘应用的开发；3、为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题。任职要求：1、二年以上Java Web应用开发经验，本科及以上学历；2、熟练掌握Java、Scala中的至少一门语言，有Python、R语言开发经验优先；3、熟悉开源框架Spark、Hadoop、Storm中的一种，有实际项目应用经验；4、熟悉Oracle、Mysql等常用关系数据库，熟练编写SQL语句；有分布式nosql数据库应用经验优先；5、熟悉Linux环境，能够熟悉使用shell脚本；6、对大数据技术有强烈兴趣，有志于往大数据处理方向发展；工作认真踏实，动手和学习新技术能力强。", "深圳市康拓普信息技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网", "3.7"
"拉勾", "Hadoop", "高级Hadoop开发工程师", "15000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：构建数据仓库，运用良好的设计思想升华数据价值；负责业务的数据收集、建模、统计与可视化，全方位支撑产品和业务迭代扩张；构建数据的监测与分析体系，帮组业务运营人员快速、及时发现问题并找到原因；进行数据应用开发，从海量数据中挖掘用户编好、关联信息，完成用户端的精准推广。职位要求3年以上大数据工作经验，熟练掌握Python/Java/PHP至少一种编程语言；熟悉hadoop或spark、具有M/R程序开发经验、具备分布式数据存储于计算平台搭建/应用开发/运维相关实践经验；熟练掌握sql,理解Hive/Mysql/Sqlserver基本原理和调优策略；具备优秀的业务理解能力，对数字敏感，有较强的逻辑分析能力；熟悉Mongdb、Redis等非关系型数据库和内存数据库；了解数据仓库开发流程，有数据仓库(DW)/商业智能(BI)/数据统计 相关工作经验优先。", "北京市起源财富网络科技有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,金融", "3.9"
"拉勾", "Hadoop", "JAVA高级工程师（Hadoop）", "20000-40000", "本科", "北京", "5-10年", "职位描述岗位职责：      软件产品研发与服务支持任职要求：1、计算机专业本科及以上毕业2、JAVA工程师，8年及以上工作经验 3、熟悉使用Spring、SpringMVC、IBatis开发框架4、熟悉Oracle、MySQL任意一种数据库5、读过至少一种开源组件6、熟悉网络通讯协议7、熟悉Hadoop、Zookeeper、Flume、Sqoop、Kafka、Hive、HBase、Storm、Spark等大数据框架优先8、理解MapReduce工作原理,Spark RDD工作原理,DAG优化原理优先9、熟悉ElasticSearch分布式搜索、ELK大数据日志分析", "北京优锘科技有限公司", "150-500人", "初创型(未融资)", "移动互联网,企业服务", "4.2"
"拉勾", "Hadoop", "hadoop大数据开发工程师", "12000-19000", "本科", "上海", "1-3年", "职位描述岗位职责：1、负责搭建hadoop集群，并维护与管理；2、负责hadoop平台上的数据存储，数据维护和优化；3、负责进行Hadoop、Hive、Hbase项目开发；4、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题;5、根据项目设计文档，完成项目模块的设计与开发；任职要求：1、本科以上（含本科）计算机、数学等相关专业；2、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；3、熟悉java开发(精通优先考虑)；4、熟悉SQL语言；5、熟悉linux开发环境；6、熟悉shell、perl、python中的一种；7、有hadoop集群部署和开发经验者优先；8、熟悉hadoop、hive、impala、kafka、flume等，对hive、impala开发有实际经验者优先；9、有银行业工作经验，熟悉银行业务者优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "企业服务,金融", "3.8"
"拉勾", "Hadoop", "HADOOP开发", "10000-16000", "本科", "郑州", "3-5年", "职位描述岗位职责：1、负责大数据方向教研体系，设计、规划课程和任务体系；2、通过面授方式进行学员答疑、任务讲解；3、按照规范和课程体系规划制作专业的大数据相关教学课程；4、管理并协调全职助教、兼职老师进行作业批改、问题解答、助教培养；5、负责设计作业和作业批改的范本；6、研究最新的大数据技术、人才市场发展趋势，确保教研体系的专业性和时效性。任职要求：1、精通Java语言，具备实际的开发经验；2、熟练掌握大数据相关的技术，如：Hadoop、HDFS、MapReduce、Spark、Impala、Hbase、Hive、Mahout、Storm等；3、熟悉掌握互联网项目的架构与设计，对分布式、集群、缓存技术等有深入的理解，有商业大数据系统构建经验者优先；4、有技术步道，就业培训班经验者优先；5、普通话标准，逻辑思路清晰，流畅的语言表达能力；6、热爱教育行业，有责任心，有强烈的自我学习和成长欲望；", "河南智游臻龙科技有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,教育", "3.7"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "北京", "5-10年", "职位描述工作职责：1.负责艺龙整体用户行为数据的收集、整理和挖掘分析；2.MVT系统模型研发；3.配合工程实现人员不断优化模型。职位要求：熟练掌握java开发，hive/hadoop/spark等大数据开发经验。2. 熟练通过python/shell等脚本语言处理数据。3. 有kafka/storm实时计算优先。4. 熟悉数据建模、用户画像等经验。目前java/算法/数据挖掘均有岗位放开，可加Q:3204763822，Q群：435606411", "艺龙网信息技术（北京）有限公司", "2000人以上", "上市公司", "移动互联网,旅游", "4.1"
"拉勾", "Hadoop", "hadoop大数据开发工程师", "15000-19000", "本科", "上海", "3-5年", "职位描述岗位职责：1、负责搭建hadoop集群，并维护与管理；2、负责hadoop平台上的数据存储，数据维护和优化；3、负责进行Hadoop、Hive、Hbase项目开发；4、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题;5、根据项目设计文档，完成项目模块的设计与开发；任职要求：1、本科以上（含本科）计算机、数学等相关专业；2、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；3、熟悉java开发(精通优先考虑)；4、熟悉SQL语言；5、熟悉linux开发环境；6、熟悉shell、perl、python中的一种；7、有hadoop集群部署和开发经验者优先；8、熟悉hadoop、hive、impala、kafka、flume等，对hive、impala开发有实际经验者优先；9、有银行业工作经验，熟悉银行业务者优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "金融", "3.9"
"拉勾", "Hadoop", "Hadoop高级工程师", "15000-30000", "本科", "深圳", "3-5年", "职位描述岗位职责:1、搭建并维护管理Hadoop&spark集群，优化底层数据架构；2、负责Hadoop平台上的MapReduce、Hive、HBase、Mahout应用维护、管理；3、负责指导其他软件工程师基于Hadoop的MapReduce、Hive、HBase、mahout应用开发；4、承接部门上各种技术工作。岗位要求：1、计算机及相关专业，本科以上学历，4年以上工作经验（至少2年以上数据分析经验），参与过较完整的数据采集、清洗、抽取、分析和建模工作；2、精通Java，3年以上Java开发经验，对Java系统开发熟练（spring，mybatis等），对数据结构、算法有深刻的理解；3、熟悉Hadoop、spark、mahout，深入理解Map/Reduce、Hive相关原理及高级特性，具有丰富的海量数据处理开发经验，熟悉YARN；4、有丰富的Hadoop集群部署、开发和维护管理经验；5、熟悉常见的开源大数据处理软件（MongoDB、Storm、Kafka、Sqoop等）；6、热爱开发，有极强的责任心和良好的沟通能力，有较强的学习能力和快速解决问题的能力，具备优化和不断改善产品的激情。", "深圳市核聚创新科技有限公司", "50-150人", "初创型(天使轮)", "移动互联网", "1.9"
"拉勾", "Hadoop", "Hadoop开发", "15000以上", "本科", "上海", "1-3年", "职位描述职位描述：1. 参与系统概要设计和详细设计。2. 广告产品的运营报表的设计与实现3.基于Hadoop的离线数据处理程序的设计与实现4.基于Spark的实时数据处理程序的设计与实现职位要求：1.计算机,通信,数学等相关专业本科以上学历。2.熟悉Hadoop平台及HDFS、Hbase、Hive的原理，有超过一年Hadoop平台的开发经验 ；3.熟悉Storm、Spark等实时统计技术有相关实战经验者优先；4.熟悉Linux系统环境，了解Linux群集技术，熟悉hadoop日志处理机制；5.熟练掌握基本的计算机科学知识，包括算法与数据结构，基本的OS与网络知识等6.2年以上Java或scala编程开发经验。7.责任心强，工作认真负责，能够承受一定的工作压力；8.具备良好的沟通技能和团队合作精神。", "上海晶赞科技发展有限公司", "150-500人", "成熟型(C轮)", "数据服务,文化娱乐", "4.6"
"拉勾", "Hadoop", "Hadoop高级讲师", "18000-25000", "本科", "北京", "5-10年", "职位描述岗位职责：1、进行Hadoop课程的教授；2、参与课程研发，课程体系完善； 3、参与基于Hadoop/Spark/Storm/Hbase/Hive生态系统的数据挖掘、大数据组件开发/维护/测试等；4、参与专业市场调研，课程开发工作。任职要求 ：1、金融、投资、计算机、统计学、数学等相关专业本科及以上学历；2、精通Java语言并掌握一种统计分析和数据挖掘软件；3、熟悉Hadoop/Spark/Storm/Hbase/Hive，及集群搭建，调优，开发；4、有大数据项目开发经验，开发过storm，mapreduce，lucene/solr/elasticsearch等程序优先；5、有大数据或互联网行业项目经验。6、具有极强的沟通和协调能力，快速学习的能力，团队合作精神，具有敬业精神，并且愿意接受挑战和承担压力。", "北京八维研修学院", "2000人以上", "初创型(未融资)", "教育", "2.7"
"拉勾", "Hadoop", "Hadoop", "13000-20000", "不限", "北京", "3-5年", "职位描述任职资格：1、大学本科以上，有3年及以上大数据平台开发经验；2、精通java等编程语言。2、熟悉Hadoop技术体系，包括Hbase（硬性）\\Hive\\Impala\\Kafka\\Spark等相关技术，具有Hbase（硬性）\\Hive\\Impala\\Spark的相关开发经验；", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "数据工程师 （Hadoop）", "10000-15000", "本科", "广州", "1-3年", "职位描述岗位职责1.在技术总监的领导下，负责数据分析平台的设计与搭建2.负责产品架构演化，性能调优技能要求1.熟悉C/C++/JAVA/PYTHON语言中一种，有海量数据处理和并行计算开发经验2.熟悉Hadoop、Hive、Spark、Impala、Storm中一种或多种技术，熟悉MapReduce编程3.熟悉但不限于聚类，个性化标签，属性挖掘等领域4.具备金融行业数据开发、有海量数据分析、熟悉大规模推荐系统经验者优先5.良好的业务理解与建模能力，能够快速学习新领域6.良好的团队合作精神，较强的沟通能力和钻研能力", "广州玄同投资有限公司", "15-50人", "初创型(不需要融资)", "金融", "2.7"
"拉勾", "Hadoop", "大数据技术总监（Hadoop资深）", "20000-35000", "本科", "武汉", "5-10年", "职位描述岗位职责：1.作为大数据平台架构师及技术负责人，负责规划和研究大数据基础平台技术；2.负责数据挖掘产品.海量数据采集. 处理及存储. 应用方案的技术选型及架构实现；3.负责海量数据挖掘分析/查询. 分布式存储. 流式/实时计算等应用层核心代码实现；4.负责大数据技术应用的技术难点攻关. 技术发展研究；5.负责大数据方向技术团队管理，负责团队成员招聘. 业务技能和技术能力培养；任职要求：1. 计算机相关专业，本科及以上学历，8年以上工作经验；2. 熟悉大规模数据挖掘. 机器学习. 自然语言处理. 分布式计算中一项或多项技术，并具备多年的实际工作经验；3. 精通Hadoop生态及高性能缓存相关的各种工具并有实战经验，包括但不限于hadoop/hive/spark/storm/elasticsearch/redis/hbase/kafka/flume等；4. 优秀的分析和解决问题的能力，对挑战性问题充满激情；5. 深厚的软件技术和工程功底，在分布式计算技术，架构设计及技术流程规范方面有深刻领悟；6. 有很好的沟通能力，跨部门协作能力，推动能力，很强的团队合作精神 ；7. 有优秀的业务理解能力，能理解清楚业务并进行合理的模块和架构设计；8. 对事业充满激情，责任心强，能够承受较大的工作压力；9.具有实时计算. 复杂计算. 图计算经验优先。；10. 具有主动性，具有大局观，具有创业精神；", "武汉泰迪智慧科技有限公司", "15-50人", "初创型(天使轮)", "数据服务", "4.2"
"拉勾", "Hadoop", "Hadoop", "18000-35000", "本科", "杭州", "不限", "职位描述Hadoop工程师职位描述1.负责Hadoop集群的搭建、管理、开发以及调优工作；2.负责对接产品需求，并制定相应解决方案；3.参与新技术选型以及调研工作，解决不断增长的海量数据。职位要求1. 熟悉Linux操作，具有java开发经验；2.掌握MapReduce思想，并实际运用Hadoop、Hive、HBase等分布式开源项目，有丰富的集群部署.3.熟悉其他分布式计算框架者，有数据仓库相关工作经验者优先；4. 具有较强的学习能力，有一点的算法基础，对新技术敏感, 有独立分析和技术研究能力；5.具备极强的团队精神和合作精神，对工作有热情，能够承受住压力.", "杭州龙本教育科技有限公司", "2000人以上", "成熟型(不需要融资)", "移动互联网,教育", "-"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "大专", "上海", "3-5年", "职位描述""岗位职责：1、基于Hadoop进行MapReduce、Hive和HBase的应用开发；2、维护和管理大规模Hadoop集群，解决不断增长的海量数据带来的存储和计算挑战；3、大数据平台数据清洗、转换和建模的开发。任职资格：1、大专以上学历，3年及以上工作经验；2、熟悉Hadoop/HBase生态环境体系的搭建和管理，掌握Hadoop、HBase、MapReduce、HDFS、Hive、Pig、Zookeeper等开源项目的原理和使用方法，具有实际集群搭建和调优经验；3、精通Java开发，有大平台架构开发经验；4、掌握至少一种NoSQL数据库，具有真正项目使用经验；5、良好团队协作和沟通能力。""", "上海百联全渠道电子商务有限公司", "500-2000人", "成熟型(不需要融资)", "电子商务,O2O", "3.9"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "大专", "上海", "1-3年", "职位描述1年以上大数据开发经验即可要求懂hive开发，oracle数据库，有海量数据处理经验当然如果你的领悟能力比较强，基础知识扎实，也可投递", "南京融泰信息技术有限公司", "150-500人", "初创型(未融资)", "其他", "3.2"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "本科", "武汉", "1-3年", "职位描述岗位要求：1、本科以上学历，熟悉Hadoop生态环境，对Hadoop, Hbase, Hive, Spark等至少一个项目有着深入的了解。2、扎实的Java基础，3年以上java实际使用经验。3、熟悉Linux系统常用操作。4、对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先。5、良好的学习能力，保持对新技术的敏感性。", "北京亚鸿世纪科技发展有限公司", "150-500人", "成长型(不需要融资)", "移动互联网", "3.2"
"拉勾", "Hadoop", "Hadoop实习生", "2000-3000", "本科", "北京", "应届毕业生", "职位描述岗位描述：1、负责数据仓库各种主题的离线数据的集成、清洗和统计等开发工作； 2、根据业务和产品需求提取数据和抽象出常态化分析，自动提供数据结果，为数据可视化提供支持；  职位要求：1、在校生，本科以上学历，计算机等理工类专业优先考虑；2、具有一定独立分析，技术研究能力，具有良好的团队合作精神； 3、有过linux开发经历，熟练使用shell脚本； 4、精通Hadoop，具有Hive等有实际应用开发经验； 5、熟悉ETL开发过程，具有Hive使用及优化经验，熟练掌握HQL语句； 6、熟悉MySql及相关关系型数据库，熟练掌握SQL语句；", "天脉聚源（北京）传媒科技有限公司", "500-2000人", "成熟型(D轮及以上)", "数据服务", "3.6"
"拉勾", "Hadoop", "Hadoop工程师", "15000-30000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责Hadoop /Hive的性能评测和优化，线上问题跟踪和解决2、负责MapReduce作业和Hive作业的性能评测和优化，能通过开发工具/平台以服务化的方式解决问题3、协助维护和管理Hadoop集群，参与新技术选型和调研，解决不断增长的海量数据带来的存储和计算挑战4、能运用分布式计算/大数据挖掘思路和技术开发产品，以服务化的方式提升产品质量和研发效率 和研发效率职位要求：1、深厚的Java/C++功底，多年的并发编程经验2、熟悉Linux操作系统，网络协议，熟练使用Shell、Python等脚本语言编程3、参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验4、精读过多个优秀开源软件源码，并对coding保持强烈兴趣5、熟悉Hadoop、Hive、HBase等分布式开源项目及工作原理，有丰富的集群部署、开发和维护管理经验布署、开发和维护管理经验", "北京易车互联信息技术有限公司", "2000人以上", "上市公司", "移动互联网,电子商务", "4.1"
"拉勾", "Hadoop", "高级Hadoop开发工程师", "12000-18000", "本科", "深圳", "5-10年", "职位描述工作职责：1、负责数据收集、建模、统计与可视化；2、负责构建数据的监控与分析平台，帮助业务人员快速、及时发现问题并找打原因；3、负责数据应用开发，挖掘用户偏好、关联信息，完成用户端的精准推送；要求：1、大学本科及以上学历，计算机、统计学、信息管理相关专业，两年以上工作经验；2、熟悉hadoop、storm等开源平台、具备分布式数据存储于计算平台搭建/应用开发/运维的相关实践经验；3、熟练掌握SQL，理解hive、spark sql基本原理与调优策略；4、具备优秀的业务理解能力，对数字敏感，有较强的逻辑分析能力；5、熟练掌握java，了解PYTHON、R等；6、海量数据处理经验优先", "深圳雁联计算系统有限公司", "500-2000人", "成熟型(不需要融资)", "金融,信息安全", "4.0"
"拉勾", "Hadoop", "Hadoop研发工程师", "15000以上", "本科", "上海", "1-3年", "职位描述岗位描述：1、Hadoop 数据平台建设、开发、测试、部署和优化2、基于Hadoop的存储平台架构设计与性能优化3、设计和开发海量数据的管理系统岗位要求：1、计算机或相关专业本科以上学历，具有扎实的算法和数据结构基础2、1年以上Hadoop/Hbase/Hive/storm开发经验，或者有相关的分布式平台开发经验者3、精通Java，熟悉Java开发工具4、对Hadoop源代码有研究和有贡献者优先5、有海量数据挖掘算法开发者优先6、较好的沟通理解能力，有修的团队合作品质，乐观向上，踏实上进7、熟悉linux系统，包括shell/python等语言开发", "上海晶赞科技发展有限公司", "150-500人", "成熟型(C轮)", "数据服务,文化娱乐", "4.6"
"拉勾", "Hadoop", "大数据技术总监（Hadoop资深）", "20000-35000", "本科", "武汉", "5-10年", "职位描述岗位职责：1.作为大数据平台架构师及技术负责人，负责规划和研究大数据基础平台技术；2.负责数据挖掘产品. 海量数据采集. 处理及存储. 应用方案的技术选型及架构实现；3.负责海量数据挖掘分析/查询. 分布式存储. 流式/实时计算等应用层核心代码实现；4.负责大数据技术应用的技术难点攻关. 技术发展研究；5.负责大数据方向技术团队管理，负责团队成员招聘. 业务技能和技术能力培养；任职要求：1. 计算机相关专业，本科及以上学历，8年以上工作经验；2. 熟悉大规模数据挖掘. 机器学习. 自然语言处理. 分布式计算中一项或多项技术，并具备多年的实际工作经验；3. 精通Hadoop生态及高性能缓存相关的各种工具并有实战经验，包括但不限于hadoop/hive/spark/storm/elasticsearch/redis/hbase/kafka/flume等； 4. 优秀的分析和解决问题的能力，对挑战性问题充满激情； 5. 深厚的软件技术和工程功底，在分布式计算技术，架构设计及技术流程规范方面有深刻领悟；6. 有很好的沟通能力，跨部门协作能力，推动能力，很强的团队合作精神 ；7. 有优秀的业务理解能力，能理解清楚业务并进行合理的模块和架构设计；8. 对事业充满激情，责任心强，能够承受较大的工作压力；9. 具有实时计算. 复杂计算. 图计算经验优先。；10. 具有主动性，具有大局观，具有创业精神；在这里，你将拥有——一群让你为之骄傲的小伙伴：热情坚定、懂得分享、自我驱动、追求极致的高效团队自由平等的潜力平台：就连总理都为我们点赞了，你觉得呢？非常美好的福利体系（这只是一部分）：爱心午餐：午餐补贴倍儿爽温馨健康福利：头痛脑热公司报销生日会：全体伙伴陪你过不让你孤单热闹的年度旅游：来一次说走就走的旅行各种分享培训：丰富多彩的内容......总有人与你志同道合欢迎你来发现更多的精彩......我们做大数据挖掘、机器学习的产品和服务，创业征途上，一个人无法走远，总得有人并肩作战，这就是我们需要你的原因！", "武汉泰迪智慧科技有限公司", "15-50人", "初创型(天使轮)", "数据服务", "4.2"
"拉勾", "Hadoop", "Hadoop Java大数据", "12000-20000", "本科", "北京", "3-5年", "职位描述1、大学本科以上学历；2、有3年及以上大数据平台开发经验；3、精通java等编程语言；4、熟悉Hadoop技术体系，包括Hbase\\Hive\\Impala\\Kafka\\Spark等相关技术，具有Hbase\\Hive\\Impala\\Spark的相关开发经验；5、长期外派岗位", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "Hadoop高级工程师", "15000-25000", "本科", "上海", "3-5年", "职位描述工作职责：基于大数据平台的数据仓库建设与数据应用开发；支撑公司各业务线数据需求；分布式平台应用程序开发（Hadoop/Hive/Storm/Spark）。任职资格：1. 具有3年以上的Hadoop大数据平台开发经验，深入了解Hadoop数据处理体系（Hadoop/HDFS/MR/Hive/YARN/ HBase/Impala/Sqoop/Spark/Zookeeper/Storm/Kafka/Azkaban）。2. 具有丰富的数据仓库开发经验，了解数据仓库体系相关的技术。3. 了解大数据的基本处理思路与常用算法，技术基础扎实；至少熟悉使用2种编程语言（Java/Shell/Python/Scala），精通Hive SQL。4. 熟悉Linux操作系统，熟练掌握awk/sed等文本处理工具。5. 优秀的问题分析与解决能力，条理逻辑清晰；具备良好的分析、组织、沟通能力。6. 热爱开源技术，关注并了解最新的大数据前沿技术。7. 良好的抗压能力与团队合作精神", "沪江教育科技（上海）股份有限公司", "500-2000人", "成熟型(D轮及以上)", "移动互联网,教育", "3.7"
"拉勾", "Hadoop", "Hadoop运维工程师", "15000-30000", "本科", "上海", "3-5年", "职位描述岗位职责：1、负责各生产系统、测试环境的自动化安装部署维护；2、负责系统日常运维，保证网站 7*24 稳定运行；3、负责完善系统监控、报警、自动部署等运维内部的自动化工具和辅助系统；4、负责系统日常调整和故障处理，保证系统的高并发和高可用性，遇到故障及时定位并找出解决办法；5、负责应用安全，数据的日常备份和应急恢复；任职要求：1、具备系统运维2年以上工作经验，熟练linux系统，掌握各种运维流程和工具；2、对服务器的监控、日志分析有深入理解，熟练运用常见开源监控软件及日志分析软件；3、熟悉自动化运维工具，熟练编写shell脚本，熟悉Perl、Python、PHP任其一种语言能编写自动化运维脚本4、熟练掌握各种负载均衡机制，熟悉IDC机房部署、负载均衡，网络、安全、审计等；5、高度的责任心，较强的故障分析及排除能力，良好的团队合作精神，工作认真、细心、虚心好学、沟通能力好；6、熟练掌握各种四、七层负载均衡机制，深入了解nginx的反向代理机制，并能够快速部署；7、熟悉虚拟化技术、熟悉kubernetes、docker运维经验者优先考虑", "平安健康互联网股份有限公司", "500-2000人", "成长型(A轮)", "移动互联网,电子商务", "4.2"
"拉勾", "Hadoop", "Hadoop研发工程师", "8000-15000", "本科", "成都", "3-5年", "职位描述我们需要你：1.基于hadoop的海量数据分析系统研发2.基于hadoop集群的MapReduce程序的开发、测试及优化我们希望你：1.对Linux操作系统熟练掌握，熟悉shell等脚本编程2.扎实的java基础，两年以上java实际开发经验3.熟悉hadoop集群的搭建、管理及优化4.熟悉hadoop及hive，有MapReduce分布式编程经验5.熟悉关系型数据数据库，熟练使用SQL6.对海量数据的分析、挖掘有浓厚兴趣，有海量数据处理经验7.对技术有激情，喜欢钻研，能快速接受和掌握新技术，有较强的独立、主动的学习能力8.理解能力强，有较强的逻辑思维分析能力9.有强烈的责任心及良好的团队合作精神我们为你提供：1、免费午餐；2、购买六险；3、周末双休，享受带薪法定假日、带薪年假等；4、免费定期体检；5、拓展活动及旅游等福利活动。", "成都达拓智通科技有限公司", "15-50人", "初创型(天使轮)", "移动互联网,电子商务", "-"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "武汉", "3-5年", "职位描述1. 本科及以上学历，计算机或相关专业毕业； 2. 两年以上Hadoop（Mapreduce, Hive, PIG, Sqoop, Flume, HBASE, Spark, Shark）相关大型环境设计和应用开发经验；3. 三年以上JAVA 编程经验；4. 熟悉Hadoop 2.X生态系统以及基于Hadoop生态系统的各种开源组件的安装、维护、管理、调优； 5. 具有HADOOP项目架构经验；6. 具有良好的团队合作精神和高度的责任心，能在较大压力下工作；7. 具有优秀的学习能力、独立分析问题和解决问题的能力。8. 工作踏实认真，有责任心；9. 具备项目管理经验者优先；10. 具备银行行业项目经验者优先；11. 能适应出差者优先。", "北京联创智融信息技术有限公司", "500-2000人", "成熟型(不需要融资)", "企业服务,招聘", "3.7"
"拉勾", "Hadoop", "Hadoop", "18000-30000", "本科", "北京", "3-5年", "职位描述岗位职责1、根据业务需求，建立模型并解决问题。2、结合业务需求，对数据进行深度分析，为运营和决策提供有质量的数据支持；3、用户画像/产品分析/用户行为分析等相关领域的算法研究，并结合实际业务，对算法进行优化4、和大数据平台工程师一起开发数据产品任职要求1）计算机相关专业本科及以上学历2）精通SQL语言，掌握java语言，熟悉至少python或者R中的一种3）熟悉常见的数据模型以及相关算法、有linux环境下的开发经验4）熟悉hadoop或者spark生态圈，掌握mahout、mlib等大数据环境下数据挖掘框架的一种。5）掌握常用的数据可视化的工具(熟悉tableau优先）6）具有较强的分析问题的能力，以及良好的沟通和表达能力。我们为您提供：1、工资奖金——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；2、五险一金——按工资基数全额缴纳五险一金；3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；4、多种激励——月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；5、员工旅游——春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！7、健康体检——每年一度的健康体检让您的身体定期做个检查；8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；9、上班时间——每天弹性工作制，错峰上下班；10、培训分享——新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！", "竞技世界（北京）网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,游戏", "4.2"
"拉勾", "Hadoop", "Hadoop工程师", "18000-25000", "本科", "上海", "3-5年", "职位描述岗位职责：1. 参与基于hadoop(CDH5)大数据系统平台核心模块设计、开发；2. Hadoop及相关组件Flume、Hive、Hbase、Spark的监控、故障处理和性能优化；3. 基于Map/Reduce、Flume、Hive(UDF)等的大数据开发；4. 基于Hive的分布式数据仓库ETL；5. 为数据挖掘算法、数据产品等提供运行环境；任职资格：1. 本科及以上学历，计算机、统计学等相关专业，2年以上相关工作经验；2. 熟悉Mysql、Oracle等数据库及sql数据查询；3. 熟悉Linux开发环境和shell脚本；4. 熟悉Java开发，有实际项目经验；5. 熟悉分布式数据存储和计算理论；", "上海透云物联网科技有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop", "8000-12000", "本科", "北京", "1年以下", "职位描述岗位职责：1）参与部门产品设计与开发；2）负责相关算法实现；3）编写相关文档；4）相关技术预研和维护。岗位要求：1）统招本科及以上学历，工作经验不限，应届生亦可；2）掌握Java、Spring MVC，理解面向对象编程思想，熟悉jQuery、extjs等前端技术；3）掌握Mysql数据库开发及调优；4）熟悉Hadoop/HBase/Hive/MapReduce等大数据工具；5）了解多线程、高性能应用的设计与编码及性能调优；6）熟悉LINUX开发环境；有机器学习相关算法、nutch、Hadoop项目经验等优先；7）良好的团队合作精神、头脑灵活、思维清晰及良好的文档编写能力。", "北京天融信网络安全", "2000人以上", "上市公司", "信息安全", "4.1"
"拉勾", "Hadoop", "hadoop/spark 运维工程师", "15000-30000", "本科", "上海", "1-3年", "职位描述岗位职责：负责Hadoop/spark平台运维和优化工作；保证Hadoop/spark平台各核心服务运行的稳定、高效；对Hadoop/spark平台运维不断优化，提升数据产品的质量和响应速度；开发各种Hadoop大数据自动化运维与监控工具。岗位要求：1年以上Linux系统管理工作经验；1年以上Hadoop平台管理经验；熟悉Apache spark部署、性能调优精通Shell/Python/Java/Php语言的一种或多种；对大数据和自动化运维开发有浓厚兴趣，熟悉spark，storm等分布式相关技术优先。", "上海合合信息科技发展有限公司", "150-500人", "成长型(B轮)", "移动互联网", "4.5"
"拉勾", "Hadoop", "Hadoop架构师", "18000-36000", "本科", "上海", "3-5年", "职位描述任职资格：1、2年以上中等规模集群环境下的Hadoop/Impala/Hive/Spark集群相关运维经验。2、对各种HDFS/Yarn/Hive/Impala/Spark/Hbase等相关参数调优, 性能优化等有实际经验。3、有实际踩坑经历, 对于相关组件的版本跟进, 补丁跟踪, bug追踪等有相关经验。4、实际处理过各种集群在线版本升级, 数据迁移, 集群扩容, 稳定性监控等工作。5、熟悉Kerberos安全认证系统，实施过集群权限管理, 资源隔离方面的方案规划或二次开发工作。6、有Cloudera的CM使用经验尤佳。工作职责：1、负责公司核心集群的运维工作,保证其高可用和稳定性。2、负责集群容量规划、扩容及集群性能优化。3、深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。4、设计实现分布式集群的运维、监控和管理平台。", "上海陆家嘴国际金融资产交易市场股份有限公司", "2000人以上", "成长型(B轮)", "金融", "3.1"
"拉勾", "Hadoop", "Hadoop", "13000-26000", "本科", "北京", "不限", "职位描述职位要求1、有想法，有思考，强烈的责任心;2、熟悉linux。至少熟练使用Python、shell等语言之一;3、精通SQL，有较好的SQL性能调优经验。有hadoop数据维护经验优先；4、有Hadoop、hive、Spark等大数据应用系统使用者经验者优先；5、有数据仓库监控告警经验优先。职位责任1、数据平台及hadoop集群稳定性保障7*24;2、支持业务条线ETL的各类技术问题3、数据运维工具开发；4、监控告警系统维护", "京东商城-技术研发体系-大数据部", "2000人以上", "上市公司", "电子商务", "4.5"
"拉勾", "Hadoop", "Hadoop", "9000-18000", "本科", "上海", "1-3年", "职位描述任职要求：1、本科以上（含本科）计算机、数学等相关专业；2、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；3、熟悉java开发(精通优先考虑)；4、熟悉SQL语言；5、熟悉linux开发环境；6、熟悉shell、perl、python中的一种；7、有hadoop集群部署和开发经验者优先；8、熟悉hadoop、hive、impala、kafka、flume等，对hive、impala开发有实际经验者优先；9、有银行业工作经验，熟悉银行业务者优先。", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "企业服务,金融", "3.8"
"拉勾", "Hadoop", "数据挖掘/大数据平台开发 Hadoop", "20000-35000", "本科", "北京", "3-5年", "职位描述岗位职责：1.负责hadoop平台上的数据处理；2.使用spark、mapreduce进行数据处理任职要求：1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce2.对数据结构、算法有深刻理解3.精通Java、Python4.熟悉linux开发环境5.熟悉hadoop、hbase、spark的源码的优先6.对新技术充满激情，认真负责、有良好的沟通和学习能力7.计算机或数学相关专业本科及以上学历", "车好多旧机动车经纪(北京)有限公司", "2000人以上", "成长型(A轮)", "O2O", "4.1"
"拉勾", "Hadoop", "Hadoop运维", "10000以上", "本科", "上海", "3-5年", "职位描述工作职责：1.负责公司核心集群的运维工作,保证其高可用和稳定性；2.负责集群容量规划、扩容及集群性能优化；3.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技术及发展方向；4.跟进了解开源社区Hadoop的功能，及时了解新的技术架构和功能特性，有针对性地应用于公司大数据业务；5.深度参与业务系统的设计与实施，主导业务系统架构的可运维性设计；6.设计实现大规模分布式集群的运维、监控工具和管理平台。\u3000任职资格:1.大学本科及以上学历，具有良好的学习能力、沟通能力、团队合作能力及适应能力。2.掌握目前主流Linux操作系统（ubuntu/centos/redhat）的配置、管理及优化，能够独立排查及解决操作系统层的各类问题。3.3年以上大规模hadoop集群的运维经验，熟悉ganglia/salt/puppet等监控和配置管理工具。4.掌握Python/Shell/Java中至1种开发语言。5.能够结合产品需求制定并实施综合运维技术方案。6.具备Hadoop/Hbase/Hive/Zookeeper/Spark等大规模（500台以上）集群运维经验者优先。7.能维护Hadoop源码，有Hadoop 源代码BUG修复或者源代码优化经验者优先。8.具备搜索引擎、电子商务平台、云计算平台的开发、运维经验者优先。9.强烈的主动性与工作责任心，对所负责工作有owner意识，并能自我驱动不断成长。", "上海晶赞科技发展有限公司", "150-500人", "成熟型(C轮)", "数据服务,文化娱乐", "4.6"
"拉勾", "Hadoop", "Hadoop", "13000-25000", "本科", "北京", "3-5年", "职位描述1、大学本科以上，有3年及以上大数据平台开发经验；2、精通java等编程语言。2、熟悉Hadoop技术体系，包括Hbase（硬性）\\Hive\\Impala\\Kafka\\Spark等相关技术，具有Hbase（硬性）\\Hive\\Impala\\Spark的相关开发经验；", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责大数据平台的数据体系以及数据仓库的规划与设计。2、业务数据产品的开发。与分析人员一起，面向业务目标进行数据分析与模型定义，并完成支撑业务BI的数据产品的开发。3、基础数据服务建设。对各种数据分析场景和模型进行抽象，建设一个通用的可配置的基础数据服务平台。4、大数据计算分析以及数据可视化相关领域的新技术、新框架的调研。任职要求：1、本科以上学历，3年及以上相关开发经验。（硕士以上可适当放宽相关经验年限）2、熟悉算法与数据结构。3、精通Java语言。4、熟悉Unix/Linux系统工作环境。5、精通HDFS，HBase/Hadoop，MapReduce，spark，Hive……等相关技术。6、有良好的技术文档功底，有较强的抽象，提炼能力，有一定的分析、设计、架构能力。7、有较强的探索精神，积极主动、责任心强，具有良好的沟通能力和团队合作精神。8、有海量数据开发经验者优先。9、精通Python、R其中一种语言的优先。10、有相关数据可视化经验者优先我们为您提供：1、工资奖金——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；2、五险一金——按工资基数全额缴纳五险一金；3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；4、多种激励——月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；5、员工旅游——春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！7、健康体检——每年一度的健康体检让您的身体定期做个检查；8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；9、上班时间——每天弹性工作制，错峰上下班；10、培训分享——新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！", "竞技世界（北京）网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,游戏", "4.2"
"拉勾", "Hadoop", "Hadoop", "8000-13000", "本科", "深圳", "1-3年", "职位描述1、两年以上数据挖掘/数据建模工作经验，具有统计学理论基础；2、熟练使用Hadoop、SAS、Spar；3、统招本科以上学历。", "深圳市雁联计算系统有限公司", "500-2000人", "成熟型(不需要融资)", "金融", "4.3"
"拉勾", "Hadoop", "Hadoop开发工程师", "18000-28000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责大数据BI产品的研发工作2、对公司海量数据进行处理分析任职要求：1.计算机或相关专业本科及以上学历2.两年以上JAVA开发经验，一年以上spark streaming项目开发经验3.熟悉主流的大数据处理架构（kafka、hadoop、mongodb、redis等系统）4.做事认真，有耐心；强烈责任感、和良好的沟通能力", "北京当当网信息技术有限公司", "2000人以上", "上市公司", "移动互联网,电子商务", "3.6"
"拉勾", "Hadoop", "高级hadoop开发工程师", "18000-30000", "本科", "北京", "3-5年", "职位描述职位描述：1.负责大数据平台数据的实时对接、实时处理、入库的研发和设计工作2.理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设3.负责基于Spark/Storm流式计算引擎的设计开发工作，满足业务平台化建设职位要求：1.统计、数学及计算机等相关专业本科及以上学历，3年以上互联网电商行业hadoop/spark开发经验，熟悉分布式计算或者并行计算2.至少精通Java、Scala、Python语言中的一门，有数据统计分析能力、机器学习能力、数据挖掘能力优先3.具有良好的逻辑思维能力和学习能力，工作积极主动、认真负责", "影时光网络技术（北京）有限公司", "500-2000人", "成熟型(C轮)", "移动互联网,文化娱乐", "3.8"
"拉勾", "Hadoop", "Spark/Hadoop/Storm特性开发高级工程师", "15000以上", "本科", "北京", "3-5年", "职位描述1.有Spark/Hadoop/Storm DevOps经验，偏开发。熟悉组件源码，了解Jira中组件开发状态。2.或有数据库内核，快数据，复杂事件处理CEP等领域工作经验。   3.或互联网/运营商数据平台经验。广告交易，搜索推荐，算法模型类均可。   4.或在技术背景比较好的独立软件提供商公司工作过。   5.想做，能做。team player和individual contributor两种角色都能演好。身心均衡。不浮躁。个人定位清晰。有Get it done的态度。部门同时急需这些高工组建团队，职位职责有交叉，都是我们需要的：1、Spark/Hadoop/Storm特性开发高工2、数据库内核开发高工3、实时流处理系统开发高工职位具体情况可用“百分点”搜索本站。", "北京百分点信息科技有限公司", "500-2000人", "成熟型(D轮及以上)", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "15000-20000", "大专", "上海", "3-5年", "职位描述岗位职责：1、负责公司的大数据处理框架的研发设计工作；2、负责公司产品研发过程中的数据库设计文档的撰写；3、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、大专以上学历，计算机相关专业，3年以上工作经验；2、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；3、精通JAVA编程语言，精通面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。", "上海昕之励信息科技有限公司", "15-50人", "初创型(未融资)", "移动互联网", "-"
"拉勾", "Hadoop", "hadoop开发工程师(000752)", "10000-17000", "不限", "深圳", "3-5年", "职位描述岗位职责:1）基于 Hadoop 系统的分布式大数据处理平台的设计与实施；2）分布式技术研究，及关键技术的开发工作；3）相关数据平台系统的开发与调试。任职资格:1）本科及以上学历，计算机相关专业，二年以上工作经验；2）精通Java编程；3）熟悉Linux系统，包括Shell/Python等脚本编码和软件开发等；4）熟悉Hadoop、Hive、HBase、spark、storm等相关开源项目，有一年以上从事hadoop分布式系统的设计、开发、运维工作经验；5）工作认真，细心，有条理；积极性高，求知欲强；具有较强的沟通能力及团队合作精神。", "东方网力科技股份有限公司", "500-2000人", "上市公司", "信息安全,数据服务", "3.6"
"拉勾", "Hadoop", "Hadoop大数据开发工程师（成都） 入职购买五险", "10000-20000", "本科", "成都", "1-3年", "职位描述岗位职责： 1. 研究与跟踪大数据技术发展方向，参与大数据平台架构的设计； 2.负责数据平台的设计、开发、维护、优化，满足公司各级部门的数据分析需求；任职要求： 1.本科及以上学历，2年以上互联网产品或分布式系统开发设计经验，1年以上大数据产品经验； 2.熟悉HADOOP、spark原理，了解大数据周边技术如Storm、Flume、Kafka、hbase、mongodb等，有相关开发运维经验，具备源码级问题解决和集群优化改造能力者优先； 3.熟悉常见的机器学习算法，有实际分析模型开发、训练经验者优先；工作地点：成都高新区软件园G区入职购买五险一金！双休！零食！弹性工作制！", "北京建飞无限科技有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop", "9000以上", "本科", "南京", "应届毕业生", "职位描述职位描述：1、与产品经理，UX设计师一起工作来分析、评估和细化功能需求2、与软件开发团队一起再快速迭代中不断发布新功能3、作为软件产品模块的代码负责人，保持代码质量、完整性、效率和可用性4、与软件测试工程师交流设计信息并提供测试建议我们对您的期望：1、本科毕业生，重点院校计算机等相关理工科专业背景。2、对软件开发有浓厚的兴趣，有开发出完美的软件产品的热情，喜欢钻研。3、极强的逻辑思维能力和问题解决能力，数学基础优秀。4、熟练java，熟练掌握Hadoop、spark平台，做基本的分析处理。5、有开源项目经验加分。公司介绍：1、在数据产品领域有15年行业经验，一直被模仿，从未被超越。2、合作客户超过4500家;中国500强中285家合作过；中国软件100强中, 62家是合作伙伴,中国244家一级系统集成商,137家牵手了帆软。3、2005年，帆软公司人数200人，行业内规模最大；销售额破亿，业内遥遥领先。4、公司成员90%来自全国重点985、211院校，牛人到处都是，我们招聘的每一个你，都期待能够在未来有能力独当一面。5、关于工作回报，我们除了提供有竞争力的薪酬，更有能够参与公司利润分配的股权激励，我们坚持，不让某一个人创始人暴富，与优秀的人一起共赢才是王道。", "南京帆软软件有限公司", "150-500人", "成长型(不需要融资)", "数据服务", "4.7"
"拉勾", "Hadoop", "Hadoop高级研发工程师（信息平台）", "8000-15000", "本科", "北京", "3-5年", "职位描述岗位职责：1.医疗大数据平台的搭建、优化和运行；2.医疗大数据平台搜索、分析工具的设计和研发工作；3.中文分词、词性标注等相关功能的研发工作；4.高效数据收集和传输、处理系统的设计和研发工作。任职要求：1、统招本科以上学历，2年以上工作经验，有大型互联网公司任职经历为佳；2、熟悉Hadoop生态系统的搭建、管理及优化；3、有hadoop、mahout、spark 或 mllib等大数据平台实践经验；4、理解MapReduce、HDFS原理、spark RDD原理，并有一定基础的相关开发经验；5、熟练使用Hive、Spark SQL、Hbase，对关系型数据库有一定的基础；6、熟练使用java、scala等编程语言；7、熟悉分类、聚类、推荐、自然语言处理等算法者优先；8、熟悉linux系统，熟悉bash shell；9、具有良好的数据结构、算法功底，熟悉网络编程、多线程编程技术；10、乐于学习新的知识，动手能力强，有进取心，责任心强。", "北大医疗信息技术有限公司", "500-2000人", "成熟型(不需要融资)", "医疗健康", "4.0"
"拉勾", "Hadoop", "HADOOP架构师/开发经理", "20000-30000", "不限", "深圳", "3-5年", "职位描述岗位职责：1、对公司大数据业务进行框架设计；2、主要负责大数据技术平台的搭建，设计，运维，调优；3、负责数据仓库逻辑模型、物理模型的分析与设计；4、把控数据质量。任职要求：1、本科及以上学历，具有三年以上软件项目开发经验或架构设计经验，具有开源项目架构设计经验优先； 2、熟悉Hadoop、Hive、Hbase、Storm、Spark等平台搭建，开发及调优；3、熟悉数据仓库实施方法论、深入了解数据仓库体系架构； 4、熟悉逻辑模型和物理模型建模、中间层模型理论以及多维模型的设计； 5、熟悉主流数据库技术（如Oracle、SQLServer 2000、GP、MySQL等），精通SQL，有较强的SQL编码及调优经验； 6、熟悉Tableau/Cognos/BO/Datastage/SAS/SPSS等BI工具软件优先； 7、有大型集群或高并发、海量数据经验者优先考虑。", "上海南方银谷科技有限公司", "150-500人", "成熟型(D轮及以上)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop", "18000-30000", "本科", "北京", "5-10年", "职位描述大数据工程师（Hadoop/Spark）岗位职责：1.负责大数据平台的数据实时对接、实时处理、入库的研发和设计工作2.理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设3.负责基于Spark/Storm流式计算引擎的设计开发工作，满足业务平台化建设4.负责hadoop和Spark部署、监控、调优。岗位要求：1.2年以上spark/Hadoop开发经验，熟悉分布式计算或者并行计算；2.熟悉Hadoop生态系统开源项目，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解；3.至少精通Java（jdk8及以上）或者Scala、Python语言 中一门；4.有良好的系统分析能力、故障诊断能力者优先；5.有数据统计分析能力、机器学习能力、数据挖掘能力优先。", "北京每日优鲜电子商务有限公司", "150-500人", "成长型(B轮)", "移动互联网,电子商务", "3.5"
"拉勾", "Hadoop", "高级Hadoop/Spark大数据开发", "10000-20000", "本科", "武汉", "3-5年", "职位描述岗位职责：1、负责公司各类数据的处理、大数据平台框架的研发设计工作；2、使用Spark、MapReduce、Storm、Kafka等组件进行数据处理；3、新技术框架和解决方案预研与落地，以提高处理和分析大数据的效率和速度。任职要求：1、熟悉Hadoop以及Hadoop生态圈中的多个组件，如HBase、Hive、Kafka、Storm、Impala等；2、精通JAVA编程语言，熟悉Linux操作，可以编写代码编程使用Hadoop生态中的组件和基于组件开发的大数据处理；3、熟悉开源组件源码者优先。", "武汉斗鱼网络科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "高级数据分析师（熟悉hadoop)", "15000以上", "本科", "上海", "1-3年", "职位描述【工作内容】  1、负责互联网业务和移动互联网业务的海量数据分析，包括数据汇总，分析、挖掘、总结规律；  2、协助广告投放部门优化投放算法；  3、协助销售部门针对各种统计分析类项目需求提供售前、售后的数据支持；  4、定期发布专题分析报告，为产品和运营提供决策支持；  5、负责与相关工作的人员做各类数据需求与对接，以业务分析推动产品的发展方向与改进思路。   【任职要求】  1、计算机、应用数学或统计学等相关专业本科及以上学历；  2、理智、逻辑性强，具有优秀的学习能力、独立分析和解决问题能力，具有强烈的责任心及工作积极性；  3、熟悉hadoop和hive，有map/reduce编程经验；  4、熟悉linux操作系统，熟悉python脚本编程；  5、参加过以下项目者优先：数据仓库、海量数据分析、数据挖掘、Mahout或SPSS相关项目。", "上海晶赞科技发展有限公司", "150-500人", "成熟型(C轮)", "数据服务,文化娱乐", "4.6"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责手机游戏服务器端的设计开发；2、与客户端人员联调测试游戏功能；3、与PC后台人员开发、联调测试新游戏功能；4、配合组内成员开发大数据相关的数据输入、输出等工作。任职要求：1、大学本科以上学历，熟练掌握C/C++或者JAVA；2、熟悉各种常用数据结构及算法，对linux下的网络数据库开发有足够经验；3、有2年以上C++实战经验者优先；4、有大数据挖据方面经验和技能者优先；如hadoop、hbase、hive等；5、善于与其他部门的成员沟通、协作。", "竞技世界（北京）网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,游戏", "4.2"
"拉勾", "Hadoop", "Hadoop", "9000以上", "本科", "无锡", "不限", "职位描述职位描述：1、与产品经理，UX设计师一起工作来分析、评估和细化功能需求2、与软件开发团队一起再快速迭代中不断发布新功能3、作为软件产品模块的代码负责人，保持代码质量、完整性、效率和可用性4、与软件测试工程师交流设计信息并提供测试建议我们对您的期望：1、本科毕业生，重点院校计算机等相关理工科专业背景。2、对软件开发有浓厚的兴趣，有开发出完美的软件产品的热情，喜欢钻研。3、极强的逻辑思维能力和问题解决能力，数学基础优秀。4、熟练java，熟练掌握Hadoop、spark平台，做基本的分析处理。5、有开源项目经验加分。公司介绍：1、在数据产品领域有15年行业经验，一直被模仿，从未被超越。2、合作客户超过4500家;中国500强中285家合作过；中国软件100强中, 62家是合作伙伴,中国244家一级系统集成商,137家牵手了帆软。3、2005年，帆软公司人数200人，行业内规模最大；销售额破亿，业内遥遥领先。4、公司成员90%来自全国重点985、211院校，牛人到处都是，我们招聘的每一个你，都期待能够在未来有能力独当一面。5、关于工作回报，我们除了提供有竞争力的薪酬，更有能够参与公司利润分配的股权激励，我们坚持，不让某一个人创始人暴富，与优秀的人一起共赢才是王道。", "南京帆软软件有限公司", "150-500人", "成长型(不需要融资)", "数据服务", "4.7"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "北京", "5-10年", "职位描述·计算机相关专业本科。 ·熟练掌握JavaEE项目开发技能，具备扎实的Java知识，熟练使用SpringMV，Struts2，Mybatis等开源框架； ·熟练掌握一种关系性数据库系统； ·熟悉Hadoop、HBase、Kafka，Flume、Spark等相关开源项目，并从事过海量数据的实践与流数据(SparkStreaming)处理经验者优先； ·熟悉ETL工具或流程，例如sqoop/hive等开源工具者优先；", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "大数据工程师（Hadoop/Spark 实习岗位）", "3000-5000", "本科", "武汉", "应届毕业生", "职位描述岗位职责：1.了解Hadoop/Spark集群以及Hive、HBase、Pig等相关软件使用；2.负责Hadoop数据分析模块与其它系统/模块之间的衔接，为BI提供基础数据分析；3.熟悉常用数据挖掘算法，解决海量数据分析、挖掘方面的业务需求。岗位要求：1.计算机、数学或统计等相关专业本科及以上学历；2.具有优秀的学习能力、独立分析问题和解决问题能力；3.有过大数据相关的项目经验者优先；4.热爱技术，善于沟通。", "武汉斗鱼网络科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "大专", "北京", "3-5年", "职位描述工作职责：1、负责Hadoop /Hive的性能评测和优化，线上问题跟踪和解决2、负责MapReduce作业和Hive作业的性能评测和优化，能通过开发工具/平台以服务化的方式解决问题3、协助维护和管理Hadoop集群，参与新技术选型和调研，解决不断增长的海量数据带来的存储和计算挑战4、能运用分布式计算/大数据挖掘思路和技术开发产品，以服务化的方式提升产品质量和研发效率和研发效率职位要求：1、深厚的Java功底；2、熟悉Linux操作系统，网络协议，了解使用Shell、Python等脚本语言编程；3、参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验优先；4、熟悉Hadoop、Hive、HBase等分布式开源项目及工作原理，有丰富的集群部署、开发和维护管理经验布署、开发和维护管理经验优先。", "中国商业联合会项目数据分析专业委员会", "150-500人", "成长型(不需要融资)", "教育,分类信息", "3.7"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "本科", "北京", "不限", "职位描述工作职责：1.负责与局方沟通需求，分配开发人员，带领开发人员进行程序开发；2.负责程序关键代码编写工作；2.负责ETL数据处理过程的设计；3.负责shell脚本架构设计；4.负责Hive-sql,spark-sql,hbase，sqoop等的数据模型设计工作。职位要求：1、计算机或应用数据相关专业或参加过计算机社会培训；2、有管理经验或带队经验，具备良好的沟通能力；3、精通至少一种关系型数据库开发或NOSQL开发，并使用过内存数据库；4、熟练JAVA或python开发语言的一种，可以设计程序架构；5、熟练在linux上配置Nginx、lua和shell的设计和开发；6、具备快速学习能力，思路清晰，善于思考；7、工作严谨细致、责任心强；勤奋踏实，善于思考问题；有良好的团队合作观念；8、具备linux上lua语言开发经验、LOGSTASH、KIBANA4、ZOOKEEPER、CODIS、rabbitmq使用经验优先；9、有电信行业经验者优先；", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop (移动广告部)", "15000-30000", "本科", "北京", "1-3年", "职位描述职位描述：1. 负责数据仓库系统和hadoop集群的审核、部署、发布、监控、维护和优化。2.负责突发事件管理，问题跟踪与管理，提供运维报告。3.负责系统的性能分析与系统优化，不断提高系统运行效率。岗位要求：1.本科以上学历，计算机或者相关专业。2.熟悉Linux或Unix系统，熟悉网络技术，尤其是TCP/IP协议，2年以上大规模集群的运维经验，熟悉ganglia/salt/puppet等监控和管理工具；3.熟悉Hadoop平台及主要子项目，有一年以上Hadoop平台mapreduce的开发经验；4.熟悉shell,perl,python,php至少一种，有java,C/C++语言基础更好。5.对Hadoop、HBase、Storm、Zookeeper、impala或MPI之一有深入理解并在现实项目中大规模应用；6.熟悉MongoDB、Redis、Memcache其一，对pig,hive,hbase, spooq,flume,scribe有研发经验者优先；7．熟悉HDFS、Hbase、Hive的原理、特性和常用配置且有实战开发经验；8．熟悉Storm、Spark等实时统计技术有相关实战经验者优先；7.具有大型网站的运维经验；有参与开源项目等优先；", "时趣互动（北京）科技有限公司", "500-2000人", "成熟型(D轮及以上)", "移动互联网", "4.0"
"拉勾", "Hadoop", "资深Hadoop开发工程师", "12000-24000", "本科", "深圳", "不限", "职位描述工作职责：负责数据接入、大数据计算、数据清洗、数据平台搭建负责金融大数据计算和管理平台的开发和应用岗位要求：有5年以上数据仓库、数据挖掘方面的相关工作经验熟悉数据仓库、数据建模相关的技术细节，熟悉SQL/Hadoop/Hive/Hbase/Spark等大数据工具至少熟悉C++、JAVA、Python、Shell中的一种语言有BAT相关数据分析平台的工作经验优先。", "平安科技（深圳）有限公司", "2000人以上", "成熟型(不需要融资)", "金融", "2.7"
"拉勾", "Hadoop", "Hadoop", "10000-15000", "本科", "合肥", "3-5年", "职位描述1、参与 Hadoop 平台的数据模型设计和应用的研发；2、负责公司 Hadoop 数据平台项目运维和优化工作；3、负责集群容量规划、扩容及集群性能优化岗位要求：1、具有2年以上 J2EE 系统应用开发经验，对分布式计算有深刻理解，熟悉 Linux 系统环境，致力于大数据项目的研发；2、熟悉 Hadoop平台及HBase、Hive等项目，有过 Hadoop、Hbase、Hive平台的搭建与开发经验；3、熟悉大数据周边相关的数据库系统，如Mysql/Redis；4、学习能力强，具有良好的逻辑分析、语言表达和文档编写能力，强烈的责任心和团队合作精神；", "合肥 城市云数据中心股份有限公司", "50-150人", "上市公司", "O2O", "-"
"拉勾", "Hadoop", "Hadoop开发工程师(java)", "6000-8000", "本科", "沈阳", "3-5年", "职位描述岗位职责:1.协助项目组长完成后台开发项目开发；2.独立完成个人承担模块的开发和测试。任职要求:1、有2年以上JAVA 发工作经验，具备互联网行业项目经验优先；2、精通Core Java, 熟悉Java IO, NIO, 多线程编程. 熟悉JVM运行机制和内存管理, 网络协议；3、熟悉Linux操作系统及Linux操作命令，熟练使用Shell；4、熟悉MYSQL/oracle等数据库，熟悉SQL语法；5、熟悉Hadoop/HBase生态环境体系的搭建和管理掌握Hadoop、HBase、MapReduce、HDFS、Hive、Pig、Sqoop、Oozie、Flume、Zookeeper等开源项目的原理和使用方法；6、有良好的沟通能力和团队协作能力，有责任心和创新意识，有较强的学习能力和快速解决问题的能力。", "北京和勤联创技术有限公司", "50-150人", "初创型(天使轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "BI报表/大数据开发/hadoop/数据库开发", "15000-17000", "大专", "深圳", "3-5年", "职位描述1、两年以上数据开发相关工作经验，一年实际hadoop开发经验，对Hive，sqoop开发语言熟练掌握；2、熟悉大数据平台后台脚本开发，熟悉oracle、mysql后台开发;3、熟练掌握Linux操作系统基本操作；4、能够按照开发规范，标准、规范、严格地进行项目编码开发；5、在按照需求完成编码开发工作的前提下，能通过大数据量压力测试。6、计算机相关专业，大专（含）以上学历；具备良好的学习能力；拥有良好的工作态度和职业道德，能承受较大的工作压力，能适应加班；表达沟通能力强，容易相处。", "深圳市网新新思软件有限公司", "500-2000人", "上市公司", "移动互联网,企业服务", "3.5"
"拉勾", "Hadoop", "Hadoop/spark开发工程师", "14000-25000", "本科", "杭州", "1-3年", "职位描述岗位职责：1.负责公司大数据平台基础架构的研发2.日常数据系统开发3.负责调优数据平台性能，保证数据平台高可用性任职要求：1.具有搭建维护维护hadoop相关环境,troubleshooting,turning的经验2.熟悉jvm运行机制，有java开发经验优先3.熟练的java、shell、python开发能力4.有海量数据开发经验优先加分项：• 在GitHub或其他平台上有过开源项目• 有个人技术博客，公开发布过技术文章、论文等• 喜爱运动• DOTA & LOL我们将能提供：• 宽松的办公环境• 五险一金是必须的• 极具潜力的期权数• 灵活的考勤方式• 足够多的水果和零食• 免费的咖啡和茶• 每年不少于一次旅游• 充分的学习机会（培训与分享）• 餐补+年休假• 报销所有职业书籍你要能扛得住：• 做为创业公司，加班是必然的，但是会有调休• 边做业务边改进架构的压力• 业务快速增长下，能力也要快速提升", "杭州迪火科技有限公司", "150-500人", "成长型(B轮)", "移动互联网 ,O2O", "4.4"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位职责：负责Hadoop系统的资源管理和日常维护；负责Hive/HBase/Spark/Impala等组件的优化和二次开发。任职资格：1.熟悉Hadoop、Hbase、Hive，两年以上Hadoop开发经验；2.理解MapReduce计算框架的思想，熟悉分布式计算模型或有高效索引技术经验者优先；3.精通JAVA语言，熟悉J2EE相关技术；4.至少熟练使用Shell、Python、Perl等脚本语言之一；5.热爱技术，工作认真、严谨，有团队精神。", "京东金融", "2000人以上", "上市公司", "金融", "4.0"
"拉勾", "Hadoop", "Hadoop工程师", "8000-15000", "本科", "广州", "1-3年", "职位描述岗位职责：1、 从事Hadoop、Spark、Storm等分布式大数据平台产品的设计和开发；2、 针对部门大数据业务进行大数据分析、挖掘应用的开发；3、 为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题。任职要求：1、1 年以上Hadoop/Spark大数据相关工作经验；2、熟悉Java、Shell等脚本语言；3、熟悉Hadoop、Spark、Hbase、Storm等软件源码优先；4、有有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑； 5、强烈的责任心和团队合作能力，良好的学习能力，逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。", "蓝盾信息安全技术股份有限公司", "500-2000人", "上市公司", "信息安全", "3.6"
"拉勾", "Hadoop", "hadoop高级运营工程师(深圳）", "15000-30000", "本科", "深圳", "不限", "职位描述岗位职责：1.负责Hadoop、spark、hbase、oozie、hive等平台运营和优化工作；保障平台服务运行稳定、高效。2.开发Hadoop大数据自动化运维与监控工具。3.负责hadoop平台部署、监控建设；生产问题、告警、故障处理及服务器维护、日常值班；4.负责集群网络架构、数据安全方案设计。岗位要求：1. 三年以上后台系统运营工作经验。2. 熟悉hadoop原理，具有Hadoop平台应用及管理经验，熟悉hadoop、hive、spark、hbase、oozie等开源项目及部署、维护、调优。3. 熟悉linux操作系统及调优；熟悉sql编程；4. 熟悉Shell/Python/Java/Perl语言的一种或多种，有开发经验优先。5. 熟悉nagios,cacti,ganglia,zabbix,zenoss优先；6. 对大数据和自动化运维开发有浓厚兴趣，有大规模hadoop运维经验者优先;有hadoop/hbase/spark/hive 开发经验者优先。", "平安科技（深圳）有限公司", "2000人以上", "成熟型(不需要融资)", "金融", "2.7"
"拉勾", "Hadoop", "hadoop工程师", "7000-14000", "本科", "惠州", "1-3年", "职位描述岗位职责:1.负责Hadoop集群的搭建、管理、开发以及调优工作；2.负责对接产品需求，并制定相应解决方案；3.参与新技术选型以及调研工作，解决不断增长的海量数据。任职要求:1.本科及以上学历，计算机相关专业；2.熟悉Java，熟悉linux操作能写复杂的shell脚本；3.2年以上大数据相关项目经验，有分布式系统开发经验；4.熟悉MapReduce思想，熟悉Hadoop、Hive、HBase、Elasticsearch、Spark等分布式开源项目；5.熟悉CDH搭建、维护优先；6.有一定的算法基础，有较强的学习能力，有独立分析和技术研究能力；7.优秀的团队合作精神，对工作有热情，能够承受住压力。", "惠州酷友网络科技有限公司", "2000人以上", "成长型(A轮)", "移动互联网 ,电子商务", "4.0"
"拉勾", "Hadoop", "Hadoop工程师", "15000-25000", "本科", "北京", "1-3年", "职位描述岗位职责：1、负责网站产品前端CSS/JavaScript开发；2、负责移动产品Html5页面开发；3、负责基于大数据统计的前端图表功能及组件的开发和维护任职资历：1、熟练掌握使用JavaScript、HTML5、CSS3进行Web App开发；2、精通JavaScript、HTML5、CSS，有基于Ajax的应用开发经验，能够手写页面代码；3、熟悉JQuery、Dojo、Kendo等一种或几种框架；熟悉DOM、AJAX、XML、JSON等相关技术；4、精通Photoshop图像处理软件；5、对网页标准有成熟的理解，能够很好地解决兼容问题；充分理解前端开发对视觉设计、用户体验和网站性能的重要性；6、有前端图表框架、库有使用经验者优先", "北京趣拿软件科技有限公司", "2000人以上", "上市公司", "移动互联网", "3.8"
"拉勾", "Hadoop", "资深大数据工程师（Java/Scala+Hadoop/Hbase/Hive/Spark）", "18000-30000", "本科", "上海", "5-10年", "职位描述职位描述：1. 参与公司大数据产品规划,大数据处理分析平台的设计;2. 负责数据分析、加工、清理、处理程序的开发;3. 负责数据相关平台的搭建、维护和优化;岗位要求：1. 计算机相关专业本科学历以上；2. 5+年以上相关大数据工作经验；3. 熟悉Hadoop、Hbase、Hive、Spark集群搭建维护、优化及异常问题解决;4. 能够发现系统性能瓶颈,并能对IO、网络通讯、任务调度调优;5. 熟悉Java和Scala语言、熟悉常用设计模式、具有代码重构意识;6. 使用Spark Streaming和Spark SQL进行数据处理, 并具有SPARK SQL优化经验;7. 熟悉MySQL数据库性能优化方法, 了解常见NO-SQL数据库;8. 有数据挖掘、数据分析、机器学习研发实践经验者优先;", "上海帜讯信息技术股份有限公司", "500-2000人", "上市公司", "移动互联网,其他", "4.2"
"拉勾", "Hadoop", "Hadoop", "12000-15000", "本科", "北京", "1-3年", "职位描述岗位职责：1、主要负责后台服务器设计和开发工作；2、为后台大数据平台提供数据输入；3、持续学习并分享优秀经验，与团队一同成长。任职资格：1、有扎实的编程功底，3年以上C/C++实际工作经验2、精通TCP/IP协议及编程，熟悉互联网常见应用层协议；3、熟悉linux网络编程与多线程编程，熟悉shell脚本；4、熟悉关系数据等基本应用；5、有大数据经验或对大数据感兴趣者优先；我们为您提供：1、工资奖金——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；2、五险一金——按工资基数全额缴纳五险一金；3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；4、多种激励——月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；5、员工旅游——春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！7、健康体检——每年一度的健康体检让您的身体定期做个检查；8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；9、上班时间——每天弹性工作制，错峰上下班；10、培训分享——新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！<", "竞技世界（北京）网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,游戏", "4.2"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-25000", "大专", "深圳", "3-5年", "职位描述职责：1、负责公司大数据平台的开发；2、支撑日常业务数据需求，问题跟进并及时解决。要求：1、计算机、数学等相关专业，本科以上学历； 2、熟练掌握Java/Scala语言，具有2年及以上Java/Scala开发经验，熟悉linux操作；3、具有1年以上大数据系统开发经验；4、熟悉Hadoop、Spark、Storm等相关技术，具有1个以上大数据平台项目实施经验；5、熟悉Zookeeper、Kafka等相关技术；6、有较强的学习能力，对技术有钻研精神，热衷于新技术学习和实践并乐于分享；7、优秀的团队合作精神，对工作有热情；8、有大数据实时计算工作经验者优先。", "深圳市新华云帆科技有限公司", "150-500人", "成长型(B轮)", "数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "大专", "南京", "3-5年", "职位描述1、理解 HADOOP 体系架构，熟悉HDFS、MapReduce原理2、有一定Hive、Hbase、Spark、Storm等开发经验3、熟悉Linux操作系统及shell等脚本编程4、最好有一定Java开发基础", "深圳市网新新思软件有限公司", "500-2000人", "上市公司", "移动互联网,企业服务", "3.5"
"拉勾", "Hadoop", "Hadoop高级/资深研发工程师", "15000-27000", "本科", "北京", "3-5年", "职位描述hadoop大数据处理工程师岗位职责1、负责视频播放相关数据统计处理2、负责整个数据基础结构的规划和设计职位要求1、计算机相关专业或数理统计相关专业，两年以上大数据开发经验2、熟悉Linux/Unix开发环境3、熟练使用shell命令，熟悉python/perl等脚本语言者优先4、了解hadoop，了解HDFS数据存储机制；熟练使用hive数据处理5、接触过Streaming、HBase、Storm、Spark者优先6、思维敏捷，有较强的钻研学习能力；较好的沟通能力、团队合作", "北京爱奇艺科技有限公司", "2000人以上", "成熟型(D轮及以上)", "广告营销,文化娱乐", "4.2"
"拉勾", "Hadoop", "hadoop", "10000-18000", "本科", "杭州", "1-3年", "职位描述岗位职责：1、负责和产品经理及项目经理沟通，了解需求2、负责新功能开发和产品中bug修复任职要求：1. JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；2. 2年以上java开发工作经验；对于用过的开源框架，能了解到它的原理和机制；3. 熟练掌握Hadoop、Spark 生态系统组件（MR、HBase、Hive、ZooKeeper、Spark SQL、Spark Mlib等），；4. 熟悉Linux工作环境，熟悉SQL语言，除MySQL之外，至少熟悉以下一种NoSQL数据库：MySQL/ HBase/Redis/MongoDB；5. 具备阅读英文技术资料的能力,有较强的动手实践能力及学习能力；6. 对大数据行业有强烈兴趣，较强的团队合作与沟通能力，对解决挑战型问题充满激情；", "杭州安恒信息技术有限公司", "500-2000人", "成熟型(不需要融资)", "信息安全 ,数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop", "25000-35000", "本科", "北京", "3-5年", "职位描述1、负责大数据存储计算平台等基础设施的搭建、维护、优化、改造，如hadoop, storm等 ；2、负责各种数据源的处理流程，并提供基础数据服务 ；3、协同数据仓库的设计；4、完成项目数据统计与分析任务，对业务组提供数据支持服务任职要求：1、3年以上开发经验,使用Java/C++/C/Python等编写过足量代码；3、Hadoop/Hbase/Hive/Pig开发维护经验，熟悉Map/Reduce编程；4、对常见开源系统的架构设计有研究；5、喜欢钻研新技术、新系统、新工具。", "奇虎360科技有限公司", "50-150人", "上市公司", "移动互联网,游戏", "4.3"
"拉勾", "Hadoop", "Hadoop", "10000-15000", "本科", "上海", "1-3年", "职位描述岗位职责：1) 计算机软件等相关专业，有相关工作经验者优先；2) 熟练掌握c、c++、java语言，具备独立编程实现复杂项目的能力；3) 熟练掌握oracle等常用关系型数据库系统；4) 有Hadoop分布式平台工作经验，熟练掌握Hive、Hbase、Pig、Hdfs、Map/Reduce、Storm中两种以上开发技术；5) 熟悉分布异构系统通信机制与基础方法；", "上海客鹭信息技术有限公司", "15-50人", "初创型(未融资)", "信息安全,其他", "-"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "南京", "3-5年", "职位描述大数据工程师岗位职责：1、用户海量日志统计分析2、 利用storm、spark等框架做数据的实时及离线分析3、大数据产品的WEB接口设计，算法设计4、负责公司产品研发过程中的集群的维护岗位要求：1、熟练精通数据结构与算法，熟悉分布式开发框架 (Hadoop Spark,Storm,Kafka等 至少精通一种)；2、熟悉NOSQL 数据库,redis，MongoDB；3、熟练mysql数据库；4、熟悉Linux 操作系统 可以自行部署开发环境；5、精通java python。", "上海石易电子科技有限公司", "50-150人", "上市公司", "电子商务", "-"
"拉勾", "Hadoop", "Hadoop运维开发", "9000-18000", "本科", "上海", "1-3年", "职位描述岗位职责：1、Spark、hadoop、Hive、Hbase等整体集群的调优、提供在线大数据应用平台。2、建立Hadoop所有集群的自动化监控、自动化任务调度、自动化数据入库等。3、提供可对外安全开放使用的集群平台及应用、建立集群数据安全管控体系；4、建立hadoop整体集群使用规范，规范的Hadoop平台开发及应用；5、系统维护、权限管理、Trouble Shooting。6、制订并推广在线数据的各种规范：命名、管控、建模、清洗、转换、存储、检索、使用；", "北京和讯在线信息咨询服务有限公司上海分公司", "50-150人", "成长型(不需要融资)", "移动互联网,金融", "-"
"拉勾", "Hadoop", "大数据Hadoop测试开发工程师", "15000以上", "本科", "上海", "1-3年", "职位描述工作职责:负责大数据软件产品质量控制, 优化产品周期; 设计开发测试自动化流程, 产品发布工具等.职位要求：名校本科以上学历，计算机/软件工程专业优先两年以上软件开发或自动化测试框架开发经验, 有独立完成项目的能力.具有良好的抗压能力, 逻辑清晰有耐心.熟练掌握一门主流编程语言：Java、scalar等。熟练操作Linux命令及脚本语言(shell, python, ruby, javascript等) , 熟悉Selenium, Django 框架者尤佳.熟悉docker技术, 或jenkins，maven等持续构建工具的优先考虑理解hadoop技术者优先考虑工作地点：上海", "星环信息科技（上海）有限公司", "150-500人", "成长型(B轮)", "数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "大专", "佛山", "1-3年", "职位描述1、具有金融业BI系统2年以上开发经验；2、精通SQL的计算与调优，并具有严密的逻辑分析能力；3、熟悉主流的Hadoop处理技术，有Hive、SparkSQL的项目开发经验（至少半年）；4、熟悉Linux操作系统操作，具有Shell、Python（非必需）程序开发经验；5、具有较强的文档撰写能力。", "广州永霸信息科技有限公司", "50-150人", "初创型(未融资)", "金融", "4.7"
"拉勾", "Hadoop", "Hadoop", "4000-5000", "本科", "上海", "不限", "职位描述工作职责:PoC（Proof of Concept，原型验证），在客户业务场景下验证产品的功能与性能。在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现大数据平台软件的项目实施与安装部署培训会议材料整理场景设计职位要求：计算机或相关专业本科（或以上）学历熟悉Linux shell以及SQL 语言熟悉Java语言，会编写Oracle/DB2 存储过程了解Hadoop，熟悉Hadoop，HBase，Hive基本命令有Hadoop/HBase/Hive/Sqoop/Flume使用经验者优先做事认真负责，沟通能力良好，自学能力较强，能够出差。", "星环信息科技（上海）有限公司", "150-500人", "成长型(B轮)", "数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop", "20000-40000", "本科", "北京", "5-10年", "职位描述工作职责：1、负责数据平台的多信息源数据采集、传输、存储、计算、分析和挖掘；2、负责数据平台的建设与开发。3、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；4. 根据业务需求整合优化大数据架构，协助业务层改进job质量及数据流程优化。任职要求：1、计算机相关专业本科及以上，5年及以上互联网系统或者其他企业应用系统开发相关经验；2、熟练Python服务端编程，有良好的编码习惯，有Java 开发经验者（spring）优先；3、熟练mongoDB、MySQL、redis，Oracle等常用数据库，；4、深入理解Hadoop/HBase/HDFS／Kafka／Sqoop／Zookeeper，并有相关编程经验；5、熟练使用Spark以及相关组件，有丰富的RDD使用经验，对源代码有一定研究者优先；6、熟悉LEK，有ElasticSearch优化经验者优先；7、有云计算领域经验者，开源社区参与者和贡献者优先；8、有数据统计分析、机器学习、推荐系统、数据挖掘经验者，有MLLib／mahout使用经验的优先；9、具有良好的团队合作能力，工作严谨，有激情，关注用户体验。", "和创（北京）科技股份有限公司", "2000人以上", "上市公司", "移动互联网,企业服务", "4.2"
"拉勾", "Hadoop", "Hadoop运维工程师", "20000-30000", "本科", "杭州", "1-3年", "职位描述岗位职责:1、负责公司大数据平台的运维保障；2、负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划等；3、为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张；4、深入理解大数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的大数据平台；5、持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；任职资格:1、计算机相关专业本科及以上学历；3年以上相关工作经验2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；3、熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark等；4、有1年以上Hadoop相关运维开发经验，了解Hadoop各组件的原理，并有实际部署维护经验；5、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；6、深入理解Hadoop各组件的原理和实现，有阅读源码能力者优先；7、具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；8、良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强。", "滴滴打车（小桔科技）", "2000人以上", "成熟型(D轮及以上)", "移动互联网,电子商务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "13000-26000", "本科", "深圳", "不限", "职位描述岗位职责：1.负责Hadoop集群的搭建、管理、开发以及调优工作；2.负责对接产品需求，并制定相应解决方案；3.参与新技术选型以及调研工作，解决不断增长的海量数据。任职资格：1.本科及以上学历，计算机相关专业；2.熟悉Java，熟悉linux操作；3.1年以上大数据或数据仓库相关项目经验，有分布式系统开发经验；4.熟悉MapReduce思想，熟悉Hadoop、Hive、HBase等分布式开源项目；5.有一定的算法基础，有较强的学习能力，有独立分析和技术研究能力；6.优秀的团队合作精神，对工作有热情，能够承受住压力。", "深圳金蝶随手网科技有限公司", "150-500人", "成长型(B轮)", "移动互联网,金融", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述岗位职责：1、Hadoop数据平台建设、开发、测试、部署和优化；2、基于Hadoop的存储平台架构设计与性能优化；3、设计和开发海量数据的管理系统。任职要求：1、计算机或相关专业本科以上学历；2、具有扎实的算法和数据结构基础；3、2年以上Hadoop/Hbase/HIVE/Storm开发经验，或者有相关的分布式平台开发经验者；4、精通Java，熟悉java开发工具和工具；5、有海量数据挖掘算法开发经验者优先；6、熟悉linux系统，包括shell/python等语言开发；7、较好的沟通理解能力，优秀的团队合作品质，乐观向上，踏实上进。", "北京荣程创新科技发展股份有限公司", "50-150人", "成长型(A轮)", "数据服务", "3.8"
"拉勾", "Hadoop", "Hadoop高级工程师", "12000-20000", "不限", "广州", "3-5年", "职位描述岗位职责：1、从事Hadoop、Spark、Storm等分布式大数据平台产品的设计和开发；2、针对部门大数据业务进行大数据分析、挖掘应用的开发；3、为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题。岗位要求：1、熟练掌握JAVA SE技术，精通JDK的使用(IO,NIO,容器,反射机制、异常)；2、熟练掌握hadoop或hbase设计原理，至少有二年以上实际开发经验；3、熟悉常用设计模式，并能根据不同场景选择合适的设计模式来优化系统处理模式； 4、善于不断学习新技术，具备较强的研发能力；5、理解面向对象编程思想（类、对象、重载、继承、多态）； 6、熟悉Linux管理和使用及SHELL使用； 7、有良好的沟通表达能力，善于团队合作。", "广州卡宝宝互联网金融信息服务股份有限公司", "50-150人", "上市公司", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Hadoop开发工程师", "20000-35000", "大专", "深圳", "5-10年", "职位描述1. 具有7年以上工作经验；1年以上大数据经验；                                 2. 具备一定的开发设计能力，精通Java语言， 熟悉shell、python或其他脚本语言中的一种；3.熟悉hadoop,hive,hbase,storm,lucene,elasticsearch,zookeeper,spark至少三个以上，有排错和调优经验优先； &nb    ", "日立咨询（中国）有限公司", "150-500人", "成长型(不需要融资)", "电子商务,企业服务", "1.8"
"拉勾", "Hadoop", "hadoop开发负责人", "20000-40000", "本科", "杭州", "3-5年", "职位描述岗位描述：Hadoop、Spark方向技术负责人2. 打造有影响力的开发团队岗位要求：计算机相关专业本科以上学历2. 至少精通Hadoop、Spark或者相关大数据系统的一种3. 具有广阔的技术视野， 熟悉开源生态，熟悉实时计算、离线计算等大数据解决方案4. 具备扎实的性能优化和问题诊断能力", "百度在线网络技术(北京)有限公司上海软件技术分公司", "2000人以上", "上市公司", "移动互联网,数据服务", "3.9"
"拉勾", "Hadoop", "搜索云平台-Hadoop高级开发工程师-北京-01334", "15000-30000", "本科", "北京", "1-3年", "职位描述【项目介绍】1.基于ApacheHadoop生态系统，建设搜狗海量数据存储和计算平台。2.提供稳定高效可靠的数据处理智能诊断系统。3.提供稳定高效的数据分析系统，为搜狗各类型大数据应用，提供一站式数据处理服务4.每天数十亿的数据增量，数以万计的数据计算流程，使数据的价值得到充分利用5.最前沿技术落地及对云计算前沿技术的推进【职位诱惑】海量数据,大规模机群，前沿技术；核心业务，快速成长；技术氛围浓厚，全面接触互联网生态系统；足够竞争力的薪水；如果你是技术极客,对大数据、云计算技术充满热情,希望你钟爱的技术得到更大规模的运用,那么加入我们吧！【特别提示】搜狗欢迎专情的你，所以提醒你只能选择两个项目，请慎重投递。【岗位职责】1.调研、开发、测试hadoop系统的功能、性能和扩展；2.提升集群处理能力/高可用性/高扩展性的各种解决方案进行跟踪和落地；3.解决海量数据不断增长面临的挑战，解决业务需求与问题。4.开发大数据处理平台，满足公司数据驱动为主的各种业务5.参与数据产品的设计和开发，助力业务增长【任职条件】1.两年以上的大数据hadoop相关的经验；2.熟练运用java集合类、io、多线程、concurrent包，熟悉linux系统，熟悉shell编程；3.熟悉jvm运行机制及内存管理，有gc调优经验；4.熟悉hadoop、hbase、hive等，至少精读过其中某一个的源码5.深入理解大数据应用系统架构，熟悉数据仓库，数据挖掘技术6.为人积极向上，具有良好的沟通能力和快速学习的能力", "北京搜狗科技发展有限公司", "2000人以上", "成熟型(C轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "资深Hadoop开发工程师/专家", "25000-35000", "本科", "杭州", "3-5年", "职位描述职位描述1.负责Hadoop集群的搭建、配置和管理；2.负责Hadoop相关项目的开发工作；3.系统的性能分析与系统优化，不断提高系统运行效率。职位要求1.对新技术敏感, 有一定独立分析，技术研究能力，具有良好的团队合作精神；2.熟悉java, 熟悉linux；3.熟悉各种hadoop相关的开源项目, 具有Hive、Hbase等有实际应用开发经验者优先；4.掌握MapReduce思想, 熟悉分布式计算模型或有高效索引技术经验者优先；5.有数据仓库相关工作经验者优先。", "杭州卷瓜网络有限公司", "500-2000人", "成熟型(D轮及以上)", "电子商务", "4.0"
"拉勾", "Hadoop", "Hadoop大数据开发", "20000-30000", "本科", "深圳", "5-10年", "职位描述1. 5 年以上 Java编程经验，2年以上 Hadoop 相关工作经验，熟练掌握Hdfs、 MapReduce、Hbase 、Hive的设计和开发技能；有实际大数据项目的成功经验。2. 熟练掌握Storm、Spark streaming等大数据实时处理框架的一种，具备实时处理框架的设计和开发能力；3. 熟悉Lucene、Solr、Elasticsearch等搜索引擎框架中的一种；4. 熟悉Linux开发环境；熟练掌握Python、Shell、Perl中的一种；5. 良好的团队精神及沟通表达能力；6. 有较好的沟通理解和表达能力，性格乐观，工作踏实，积极上进。", "西艾（广州）软件开发有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,企业服务", "2.6"
"拉勾", "Hadoop", "Hadoop", "9000-15000", "本科", "合肥", "不限", "职位描述1、熟悉Linux操作系统的基本概念和应用，熟练使用BASH或Python中的至少一种进行数据文件分析；2、熟悉Java开发，熟练掌握Java集合类、IO、并发变成，并熟悉Jvm原理及内存管理；3、熟悉海量数据分析相关的数据结构和算法；4、熟悉Hadoop、PIG、HIVE、HBase等分布式开源项目和基本原理，有丰富的集群部署、开发和维护管理经验；5、具有通信、计算机、软件、数学等相关专业本科或以上学历。本科阶段毕业于国家统招的正规院校。6、有带团队工作经验者优先；7、对规范化、标准化、团队化软件开发有正确理解和认识，具有良好的代码和技术文档编写习惯；8、身体健康，有良好的敬业精神、学习能力和团队协作能力，勇于迎接挑战。", "北京浩瀚深度信息技术股份有限公司", "150-500人", "上市公司", "硬件,数据服务", "4.7"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "深圳", "3-5年", "职位描述【岗位职责】1、IT系统需求分析及解决方案制定；2、保质高效完成数据类需求评估、开发、测试、上线、业务推广3、制定和完善需求开发规范、流程和制度4、形成条线清晰的项目产品开发模式和经验，并在内部推广与分享5、完成上级交办的其他工作【任职要求】1、具有大学本科及以上学历，计算机软件工程方向专业；2、3年以上银行BI（商业智能）项目开发工作，具有BI系统架构规划设计及项目管理经验；3、自信、诚恳、乐观向上、主动性强、积极性高，响应快、执行力高、心思缜密、富有团队精神与创新意识，具备良好的沟通协调和汇报能力；4、性格开朗，能持续承受较大工作压力和工作强度，有良好的工作态度与职业精神；5、熟悉hadoop大数据体系结构、熟悉hadoop基础运维构建，具有hadoop数据需求开发经验。6、了解AIX、LIUNX系统，熟练掌握其shell脚本编写。【优先考虑】1、熟悉中信信用卡某一方向业务流程和业务知识；2、熟悉Greenplum数据库，具有2年以上使用经验；熟悉常用的关系型数据和分布式数据库，精通SQL开发；", "中信银行股份有限公司信用卡中心", "2000人以上", "上市公司", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Hadoop工程师", "7000-12000", "本科", "杭州", "不限", "职位描述岗位职责:1. 负责日志数据的清洗、分析工作以及入库工作;2. 负责Hadoop集群日常维护；3. 负责MapReduce程序的开发，Hive脚本的编写。任职资格：1、计算机相关专业本科学历；2、熟练掌握HADOOP平台hive、HBASE开发技能；3、熟悉任何一种开发语言(java、python、c++等均可)；4、有大数据开发处理经验者优先。", "杭州米络科技有限公司", "150-500人", "成长型(B轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "Hadoop/Hbase平台架构师", "10000-15000", "本科", "广州", "3-5年", "职位描述1、基于Hadoop、Hbase进行设计／二次开发、开发分布式计算业务；2、管理Hadoop、hbase集群运行，稳定提供平台服务。岗位要求：1、熟练掌握JAVA SE技术，精通JDK的使用(IO,NIO,容器,反射机制、异常)；2、熟练掌握hadoop或hbase设计原理，至少有二年以上实际开发经验。3、熟悉常用设计模式，并能根据不同场景选择合适的设计模式来优化系统处理模式； 4、善于不断学习新技术，具备较强的研发能力。5、理解面向对象编程思想（类、对象、重载、继承、多态）； 6、熟悉Linux管理和使用及SHELL使用； 7、有良好的沟通表达能力，善于团队合作。优先录用要求：1、负责大型项目的架构设计职务；2、对hadoop，hbase有深度的调优经验；3、熟悉lucene,solr等搜索技术；4、熟悉数据挖掘，人工智能技术；5、担任过项目经理等管理职务；6、了解hive,zookeeper,strom等技术；", "广州市邦富软件有限公司", "150-500人", "上市公司", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop/hbase/hive资深工程师", "20000-30000", "本科", "杭州", "3-5年", "职位描述职位描述:1.hadoop大规模集群优化;2.各种分布式存储方案构建;3.集群数据安全相关体系建设;4.hbase集群整体优化和功能开发;5.集群性能优化;岗位要求：1.本科及以上学历，计算机及相关专业;2.具有3年以上Java开发经验，熟悉python/shell等脚本语言，熟悉tcp/ip网络协议，熟悉基本存储原理;3.熟悉hadoop相关各种开源项目，Hive/Hbase等有实际应用开发经验，具有一定独立解决问题的能力;4.掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先;5.熟悉多进程、多线程、数据库、IO、内存管理等方面编程者优先;6.熟悉软件开发过程、相关规范和开发工具，能独立完成软件模块的详细设计;7.逻辑思维清晰，沟通能力良好。", "杭州卷瓜网络有限公司", "500-2000人", "成熟型(D轮及以上)", "电子商务", "4.0"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "本科", "杭州", "不限", "职位描述岗位职责:1. 负责日志数据的清洗、分析工作以及入库工作;2. 负责Hadoop集群日常维护；3. 负责MapReduce程序的开发，Hive脚本的编写；任职资格:1、计算机相关专业本科学历；2、熟练掌握HADOOP平台hive、HBASE开发技能3、熟悉任何一种开发语言(java、python、c++等均可)4、有大数据开发处理经验者优先。", "杭州米络科技有限公司", "150-500人", "成长型(B轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "hadoop工程师（数据中心）(000474)", "13000-25000", "不限", "杭州", "不限", "职位描述岗位职责:1、预研新的大数据技术，如storm,spark等； 2、改进现有的数据平台产品，并设计新的产品；3、在团队内积极分享预研过程中学到的新技术；4、与应用开发工程师配合，提供技术上的支持；5、 不断学习新的开源技术，评估现有的平台技术框架，并适时引入新技术，升级数据平台架构；6、指导团队其他开发人员进行代码开发任职资格:1、对HADOOP大数据平台架构了解熟悉，有Map/Reduce开发运维经验；2、具有Storm、Spark Streaming、Slor、Hbase等大数据平台经验者优先；3、熟练掌握JAVA语言开发，懂Python或者C++优先；4、掌握或了解非结构化数据的保存、分析、访问、调优，掌握或使用过至少一种Nosql的开源产品，并真正用于项目中，如mongoDB, Redis, Cassandra等；5、在云计算和云存储方面有丰富经验；6、良好的沟通能力和团队协作能力，技术有浓厚兴趣,并热衷于追求技术极致与创新", "杭州泰一指尚科技有限公司", "150-500人", "成熟型(C轮)", "移动互联网,硬件", "4.3"
"拉勾", "Hadoop", "Hadoop", "6000-12000", "本科", "成都", "1-3年", "职位描述岗位职责：1、负责大数据平台的设计和开发2、负责海量数据的处理、分析、挖掘3、负责高并发、大存储的数据系统，实时计算处理系统的研发任职要求：1、熟悉Map Reduce / Spark编程，或者具有其他并行计算的实践经验2、熟悉Mysql/Redis 等常用SQL和NoSQL数据库3、熟悉 Kfaka等消息中间件4、精通Linux/Unix环境，精通java编程5、精通数据结构和算法6、学习能力强，有创新精神，善于学习钻研新技术7、有相关工作经验两年可放宽至大专。具有以下条件者优先：1、一年以上大数据处理，大规模的数据分析和算法实践2、一年以上hadoop 相关项目实际研发经验，比如/hive/hbase/hdfs/spark/oozie/zookeeper/mahout等3、有数据挖掘经验者或机器学习算法熟练者4、有丰富的大数据集群部署和维护管理经验", "四川华南信息产业股份有限公司", "150-500人", "上市公司", "数据服务,移动互联网", "3.1"
"拉勾", "Hadoop", "Hadoop", "8000-16000", "大专", "南京", "1-3年", "职位描述        岗位要求：搭建数科大数据平台、实现客户画像1熟悉Hadoop生态系统，能熟练使用hive进行开发2能使用java，hive， shell中的一种或多种语言在大数据环境下实现数据的处理3 有针对客户场景，建立用户画像（用户分类，理解和建模）的项目经验者优先4大专以上学历，统招全日制，学信网可验证（必须满足），实际hadoop经验有一年以上注：此岗位为外包，介意外包请勿投递公司福利：五险一金，节日福利，生日福利，结婚生子福利，丧礼福利，年假，一年一次旅游，团队聚餐，其他    ", "深圳市网新新思软件有限公司", "500-2000人", "上市公司", "移动互联网,企业服务", "3.5"
"拉勾", "Hadoop", "Hadoop/Spark工程师", "10000-20000", "本科", "深圳", "1-3年", "职位描述岗位职责： 1.设计与开发大数据平台及应用； 2.完成单元与集成测试； 3.大数据平台的诊断与调优； 岗位要求：1.基础要求：①有Hadoop或Spark经验；  ② Java或Scala编程2年以上经验；2.以下有则更佳： ① 有ambari开发经验者优先； ② 有Docker经验者优先； ③ 国家重点高校本科毕业，硕士优先； ④ 有大数据相关证书优先；  3.  任职要求  ① 注重团队合作和沟通；  ② 在大数据技术领域有极强的自我学习能力；深圳前海信息技术有限公司深圳前海信息技术有限公司（Shenzhen Frontsurf Information Technology Co., Ltd. 简称前信），以深圳市引进海外创新团队“孔雀计划”为契机，由来自硅谷知名上市科技公司高管王界兵博士发起，并引入战略投资，以提供一站式大数据系统解决方案为主业的股份制高科技公司。“孔雀计划”是深圳政府推出的引进高技术人才的项目。“孔雀计划”重点围绕深圳经济特区发展战略目标，以推动高新技术、金融、物流、文化等支柱产业，培育新能源、互联网、生物、新材料等战略性新兴产业为重点，聚集一大批海外高层次创新创业人才和团队。被纳入孔雀计划的高新技术人才团队，称为“孔雀团队”。地址：深圳市南山区笃学路9号国家超级计算中心（深圳云中心）公司福利：1． 入职购买五险，转正购买公积金；2． 入职即享有10天年假；享受国家规定的法定节假日、带薪年假、婚假、产假等各种假期；3． 每年2次旅游，1次年度慈铭或同类型体检，其他户外运动；4． 每天提供下午茶（水果、面包、蛋糕、零食等），加班零食水果补助；5． 部分节假日发送礼品、购物卡等；6． 根据工作绩效考核结果一年1-2次调薪机制；7． 根据年度绩效考核评分年终发放年度奖金；8． 良好的晋升空间。", "深圳前海信息技术有限公司", "50-150人", "初创型(天使轮)", "数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop开发工程师", "25000-45000", "本科", "北京", "3-5年", "职位描述岗位职责：1、参与网易传媒数据仓库的建设。2、参与网易移动大数据统计分析工作。职位要求：1.重点院校硕士毕业，计算机相关专业，优秀本科生亦可;2.具备两年以上java开发经验。3.熟悉Hadoop、Hive，理解云计算，对Hadoop、Hive源码有研究优先，熟悉MapReduce编程，有过大数据处理经验者优先;4.熟悉flume、sqoop等开源项目优先;5.具有良好的团队协作精神，为人正直可靠；6.喜欢数据挖掘工作，有良好的逻辑思维能力。", "网之易信息技术（北京）有限公司", "2000人以上", "上市公司", "数据服务,文化娱乐", "4.3"
"拉勾", "Hadoop", "Hadoop/Spark开发工程师（中高级）", "15000-25000", "本科", "上海", "3-5年", "职位描述岗位职责：1.为海量数据的处理和分析提供高效解决方案；2.研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；3.维持线上服务高效稳定，支撑业务和数据量的快速扩张。任职要求：1.扎实的计算机系统和算法基础知识；良好的英文阅读能力；2.扎实的Java、Scala语言基础，对JVM运行机制有深入了解；3.熟悉Hadoop、Spark并有丰富的开发经验；4.对常见开源框架代码有研究；5.熟悉SQL和noSQL的设计和开发；6.熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等；7.善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新；8.责任心强，具备良好的团队合作精神；9.有深入研究过Hadoop/Spark源码者优先。", "上海证大喜马拉雅网络科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网,文化娱乐", "4.2"
"拉勾", "Hadoop", "hadoop、spark高级开发工程师", "15000-30000", "本科", "深圳", "3-5年", "职位描述工作职责：负责大数据接入、清洗、存储、分析、平台搭建工作搭建并维护管理hadoop、spark集群，优化底层数据架构对大数据业务进行大数据分析、挖掘应用的开发承接部门上各种技术工作岗位要求：本科及以上学历，计算机、统计学、信息管理相关专业具有统计学理论基础有分布式系统开发经验3年以上数据仓库、数据挖掘、数学建模工作经验必须参与过较完整的数据采集、清洗、抽取、分析和建模工作熟悉mysql等常用关系数据库，熟练编写sql语句；有分布式nosql数据库应用经验熟练使用spark、hadoop、storm等开源平台，具有1个以上大数据平台项目实施经验有一定的算法基础，有较强的学习能力，有独立分析和技术研究能力熟悉java、go、python、r、c、c++语言的其中一门熟悉linux系统，对数据结构、算法有深刻的理解对大数据技术有强烈兴趣，有志于往大数据处理方向发展工作认真踏实，动手和学习新技术能力强", "美的集团股份有限公司", "2000人以上", "上市公司", "硬件", "3.9"
"拉勾", "Hadoop", "Hadoop", "15000-28000", "本科", "上海", "3-5年", "职位描述岗位职责： 1、Hadoop集群设计包括软硬件架构、节点配置、网络、存储和容量规划； 2、大规模Hadoop集群部署、管理和日常运维； 3、基于Hadoop各种开发工具和框架实施数据采集、分析和报表。 任职要求： 1、2年以上工作经验，本科计算机及相关专业学历； 2、基础扎实，熟悉数据结构和算法,熟悉Linux操作系统； 3、熟悉Java、Python、Shell语言，较强的独立开发能力，具备良好的代码风格； 4、具备以下1种或多种工具的开发和实施经验：Java-Mapreduce,Hive,PIG,Sqoop,Flume,HBASE,Cassandra,MangoDB,CouchDB,Spark,Shark； 5、有独立分析和解决问题的能力； 6、能够承担一定工作压力，具备创新思维、具备团队协作精神。", "上海方付通商务服务有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,金融", "3.8"
"拉勾", "Hadoop", "Hadoop软件开发工程师", "8000-15000", "本科", "广州", "1-3年", "职位描述岗位职责：-负责公司大数据引擎Hadoop应用程序设计、开发、部署、测试、发布及技术支持1、熟悉基于hadoop大数据平台的部署及配置2、熟悉java/Hive/Hbase/Kafka/Spark/Sqoop/Impala编程及部署3、已有基于hadoop的大数据项目设计、开发、部署、测试、发布及技术支持经验4、熟悉ElasticsSearch编程及部署更佳5、两年以上相关开发经验，良好英文读写能力，大学本科以上", "广州丰石科技有限公司", "50-150人", "初创型(未融资)", "移动互联网,数据服务", "4.6"
"拉勾", "Hadoop", "Hadoop软件开发工程师", "8000-13000", "本科", "广州", "应届毕业生", "职位描述岗位职责：-负责公司大数据引擎Hadoop应用程序设计、开发、部署、测试、发布及技术支持任职要求：-熟悉基于hadoop大数据平台的部署及配置-熟悉java/Hive/Hbase/Kafka/Spark/Sqoop/Impala编程及部署-已有基于hadoop的大数据项目设计、开发、部署、测试、发布及技术支持经验-熟悉ElasticsSearch编程及部署更佳-良好英文读写能力-大学本科-敢于面对挑战及干劲十足本岗位同时接收优秀实习生、应届生！本次招聘入职新成立的大数据子公司研发团队汇集苹果公司、汇丰银行、中国移动等公司的顶尖技术专家，期待你一起加入！", "广州瀚信通信科技股份有限公司", "500-2000人", "成长型(B轮)", "移动互联网", "4.5"
"拉勾", "Hadoop", "Hadoop大数据处理", "15000-25000", "本科", "北京", "不限", "职位描述职位描述岗位职责1、负责爱奇艺VIP业务等付费数据计算处理2、负责视频播放相关数据计算职位要求1、计算机相关专业或数理统计相关专业，两年以上大数据开发经验2、熟悉Linux/Unix开发环境3、熟练使用shell命令，熟悉python/perl等脚本语言者优先4、了解hadoop，了解HDFS数据存储机制；熟练使用hive数据处理5、接触过HBase、Redis、Spark者优先6、思维敏捷，有较强的钻研学习能力；较好的沟通能力、团队合作", "北京爱奇艺科技有限公司", "2000人以上", "成熟型(D轮及以上)", "广告营销,文化娱乐", "4.2"
"拉勾", "Hadoop", "Hadoop大数据开发工程师", "10000-20000", "本科", "武汉", "3-5年", "职位描述岗位职责：1、大数据相关技术的研究、大数据构架设计、关键技术研发；2、开发具有数据分析、数据挖掘能力的创新型产品；3、解决大数据相关的疑难技术问题；4、负责公司产品研发过程中的数据库设计文档的撰写；5、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、本科以上学历，统计学、数学、计算机等相关专业，2年以上数据分析相关工作；2、具有扎实的数据结构和算法功底，掌握C/C++/Java/Python等至少一门高级编程语言；3、对数据敏感，具备良好的逻辑思维能力、沟通技巧、组织沟通能力、团队精神以及优秀的问题解决能力;4、具有较强的责任心、执行力，愿意接受工作挑战；5、具备良好的逻辑分析能力和解决实际问题的能力；6、熟悉Hadoop生态圈体系、熟悉Spark、Storm等主流大数据技术；7、有大数据项目开发经验，开发过storm,mapreduce,lucene/solr/elasticsearch等程序优先；8、熟悉Hadoop集群的搭建、管理、调优和开发；", "至易科技武汉有限公司", "15-50人", "初创型(未融资)", "移动互联网,电子商务", "-"
"拉勾", "Hadoop", "Hadoop大数据开发工程师（数据仓库方向）", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责数据仓库ETL开发运维、数据集市搭建工作；2、负责数据分析指标体系建设及元数据管理；3、负责数据质量稽查和监控设计；4、负责数据报表系统等数据仓库应用数据产品的开发。任职要求：1、计算机或相关专业，本科及以上学历；2、具备数据仓库开发经验，了解数据仓库相关理论知识；3、熟悉Hadoop生态圈，具备Hive、Hbase、Sqoop、MR等开发能力；4、3年以上Java软件项目开发经验；5、熟悉SqlServer、MySQL等关系型数据库，掌握数据库应用开发；6、熟悉Linux系统环境，具备shell、perl等脚本开发能力；7、责任心强，热爱开源技术，有较强的逻辑思维和清晰的表达能力，具备团队协作意识；8、具有海量数据处理、数据分析挖掘相关项目经验、互联网从业背景者优先。", "北京车之家信息技术有限公司", "2000人以上", "上市公司", "移动互联网,文化娱乐", "4.1"
"拉勾", "Hadoop", "大数据高级研发工程师（Hadoop）", "15000-25000", "本科", "杭州", "3-5年", "职位描述工作职责：1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；3、完成各种面向业务目标的数据分析模型的定义和应用开发；4、开发具有数据分析、数据挖掘能力的创新型产品；岗位要求：1、计算机相关专业，本科及以上学历，3年以上Spark,Hadoop相关开发经验；2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；3、精通算法设计/数据结构，精通JAVA或Scala语言编程；4、熟悉Linux/Unix平台上的开发环境；5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；", "杭州泰一指尚科技有限公司", "150-500人", "成熟型(C轮)", "移动互联网,硬件", "4.3"
"拉勾", "Hadoop", "hadoop(大数据)开发工程师", "9000-18000", "本科", "北京", "1-3年", "职位描述招聘职位：Hadoop（大数据）开发工程师主要工作方向：- 参与大数据平台Hadoop组件的功能分析与验证；- 参与使用Hadoop组件搭建应用框架；- 在Hadoop框架下，完成记录的汇集、解析、存储、查询等应用；- 完成上述应用框架和应用相关的单元测试；- 完成上述应用框架和应用的集成测试。- 参与数据仓库（Greenplum）应用开发与维护；- 参与ETL工具开发部署；能力要求：- 大学本科（统招）以上学历，计算机相关专业，1年以上工作经验；- 熟悉Linux系统的基本操作，有1年以上Linux配置及脚本（Shell/Perl/Python之一）的编写经验；- 至少1年的J2SE开发经验；- 具备主流关系型数据库(Oracle、SQLServer 等) 的应用开发经验；- 有Hadoop、Storm、Spark等工作经验者优先；- 学习能力强，具有良好的逻辑分析、文档编写和语言表达能力，强烈的责任心和团队合作精神；", "中国民航信息网络股份有限公司", "2000人以上", "成熟型(不需要融资)", "移动互联网", "4.2"
"拉勾", "Hadoop", "hadoop高级研发工程师", "20000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、主要负责汽车之家大数据平台的任务调度与计算；2、负责Hadoop集群的建设、开发、调优、监控等工作；3、使用hive、spark、mapreduce进行数据处理；4、负责基于hadoop的任务管理系统；5、分析业务具体应用场景，提供数据存储、查询、分析解决方案。任职要求：1、计算机或数学相关专业本科及以上学历，985/211优先；2、熟悉Hadoop、HBase、Hive、Spark、Mapreduce、Azkaban，熟悉hadoop、hive、spark的源码的优先；3、对数据结构、算法有较深刻的理解；4、精通Java、Python其中至少一门语言；5、熟悉linux开发环境；6、对新技术充满激情，认真负责、有良好的沟通和学习能力。", "北京车之家信息技术有限公司", "2000人以上", "上市公司", "移动互联网,文化娱乐", "4.1"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "杭州", "不限", "职位描述岗位职责：1、负责spark/hadoop平台的研发与维护；2、负责基于spark/hadoop平台分析处理用户访问数据、订单信息等；3、负责推荐系统的模型建立、特征提取、数据提取、模型训练、效果评估岗位要求：1、计算机相关专业毕业，1年以上工作经验2、善于学习，对hadoop/spark开发有实际经验；3、熟悉java、scala、python等开发语言中的一种；4、熟悉spark、hadoop、hive、kafra、flume等；5、熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案岗位职责：1、负责spark/hadoop平台的研发与维护；2、负责基于spark/hadoop平台分析处理用户访问数据、订单信息等；3、负责推荐系统的模型建立、特征提取、数据提取、模型训练、效果评估岗位要求：1、计算机相关专业毕业，1年以上工作经验2、善于学习，对hadoop/spark开发有实际经验；3、熟悉java、scala、python等开发语言中的一种；4、熟悉spark、hadoop、hive、kafka、flume等；5、熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案", "上海新炬网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop平台数据仓库开发工程师", "15000-25000", "本科", "上海", "不限", "职位描述数禾科技，是上市公司分众传媒（股票代码002027）旗下互联网金融子公司，团队成员来自于招商银行、中国银联、大众点评、群硕科技等知名金融或互联网企业。公司致力于成为中国最有影响力的个人/家庭财务管理的科技金融企业，现已面市APP产品包括“拿铁财经——智能投顾专家”、“还呗——信用卡余额代偿”等，用户量正处于快速增长趋势，详询我司官网或分众传媒旗下楼宇/框架/电影院等广告展示。工作职责：1. 负责基于Hadoop平台的数据仓库搭建和优化、数据集市搭建和优化、数据ETL流程开发和调优；2. 负责业务需求的需求理解、数据探任职要求:1. 计算机相关专业，至少1~2年数仓经验；2. 熟悉主流数据库，熟悉JAVA基础编程，精通SQL开发和调优；3. 熟悉linux，熟悉shell编程；4. 有良好沟通协调能力；5. 有上进心、责任心和细心；6. 有Hadoop/hive/hbase/flume/sqoop经验者优先；7. 有大型金融行业数据仓库搭建经验者优先；8. 有python开发经验者优先。具有以下条件者优先：1.熟悉分布式系统概念、架构2.熟悉操作系统、文件系统的原理和实现3.熟悉Hadoop/Hive/Spark/Storm等开源技术4.有大型数据仓库开发经验，互联网公司大规模数据平台建设者优先", "上海数禾信息科技有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,金融", "4.6"
"拉勾", "Hadoop", "Hadoop", "25000-50000", "本科", "北京", "3-5年", "职位描述职位描述:1、参与公司基于Hadoop的企业级数据仓库搭建、设计和管理工作。2. 负责基于Hadoop生态环境的架构,算法,代码研究;3.负责对接数据产品需求和问题，并制定相应解决方案。4、指导团队对Hadoop进行代码级优化职位要求：1. 精通Linux操作，有扎实的Java编程经验。2、年以上基于Hadoop架构EDW/BI项目实施和开发经验。3、熟悉Hadoop集群管理及优化，掌握MapReduce思想，并实际运用Hadoop、Hive、Hbase等分布式开源项目。4、精通Hbase、Hive、Sqoop、Strom、Pig、ZooKeeper、Spark等分布式开源软件，有实际开发和应用实战项目经验，具备系统优化与性能调优能力;5、熟练掌握HDFS文件系统的应用开发与性能优化；掌握Map/Reduce算法与原理，具备二次设计与开发能力 ;6、精通Linux/Unix环境下的Java编程，良好的技术功底与长期的开发经验，熟悉脚本编程(Shell/Perl/Python)等；7、有基于海量数据的开发、分析及处理经验。8、 有互联网金融行业数据仓库开发经验者优先。9、有Spark、Strom开发经验者优先。10、熟悉Greenplum、Oracle、Teradata、Mysql等主流数据库。11、熟悉Linux系统，具备shell、perl、python等脚本开发能力。12. 对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。13、具有良好的文档编写能力，善于团队合作、指导新人。14、连续3年以上HADOOP实战项目经验；15、具有互联网金融经验者优先考虑。", "钱包金服集团", "150-500人", "上市公司", "移动互联网,O2O", "1.0"
"拉勾", "Hadoop", "hadoop", "15000-30000", "本科", "深圳", "3-5年", "职位描述【岗位职责】1、负责后台架构设计和优化2、负责后台版本功能开发3、作为接口人，负责与产品、客户端、测试沟通协调【任职要求】1、计算机相关专业本科及以上学历2、2年以上Unix/Linux下Server开发经验3、精通C/C++开发语言4、精通TCP/IP协议，进程间通讯编程，熟悉Unix/Linux下常用架构设计方法5、熟悉Unix/Linux操作系统原理、常用工具6、熟悉Perl/python，shell等脚本语言优先7、具备良好的分析解决问题能力，能独立承担工作任务及把控任务进度8、责任心强，良好的沟通和团队协作能力，主动好学有进取心9、有hadoop或其它分布式计算存储平台经历更佳▶关于乐易◀★极客精神   专注海外精品手机游戏和应用软件的研发、发行和运营，致力于打造世界级一流的产品；★技术深厚   创始人、CTO（原腾讯部门总监），研发经理及技术骨干均为腾讯技术背景；★飞速发展   成立首年盈利，4年每年100%营收增长，已获A轮融资，估值10亿人民币；★导师制    一对一的导师，助你快速成长。▶关于福利◀★一年两次调薪★      ★绩效奖金高达10个月★  ★六险一金★    ★一年两次旅游★  ★7天年假15天带薪事假30天病假★  ★年度体检★        ★高逼格办公环境★   ★每月团建★  ★无限量零食水果供应★", "深圳市乐易网络有限公司", "150-500人", "成长型(A轮)", "移动互联网,游戏", "4.1"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "上海", "1-3年", "职位描述职位编号：YC-F050026岗位职责：1、在大数据计算平台（Hadoop/Spark/storm）上，负责部署、实施、及项目开发2、熟练运用Hive写各种脚本，会用MapReduce编程；3、基于Hadoop各种开发工具和框架实施数据采集、分析和报表。任职要求：1、2年以上工作经验，本科计算机及相关专业学历；2、基础扎实，熟悉数据结构和算法, 熟悉Linux操作系统；3、熟悉Java、Python、Shell语言，较强的独立开发能力，具备良好的代码风格；4、对sqoop、hbase，spark有一定了解;5、有独立分析和解决问题的能力；6、能够承担一定工作压力，具备创新思维、具备团队协作精神。", "上海银橙文化传媒股份有限公司", "150-500人", "上市公司", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop 架构师", "20000-40000", "硕士", "北京", "5-10年", "职位描述岗位职责1.参与大数据平台架构的规划和设计。2.根据业务需求整合优化数据架构，主动思考不断优化。4.关注开源技术动态，推动平台技术架构持续更新。岗位要求1.计算机、通信等相关专业，本科及以上学历2.5年以上大型互联网产品或分布式系统开发设计经验3.精通HADOOP、HIVE、HBASE原理，熟悉大数据生态技术，如Storm、Spark、Flume、Kafka等，有2年以上大规模集群开发运维经验，具备源码级问题解决和集群优化改造能力者优先4.精通JAVA或者SCALA任意一种语言5.熟练使用Linux／Unix系统，至少熟悉perl/bash/python中的一种脚本语言6.有分布式OLAP开发应用经验优先", "北京小桔科技有限公司", "500-2000人", "成熟型(D轮及以上)", "移动互联网", "3.5"
"拉勾", "Hadoop", "Hadoop研发工程师", "7000-14000", "本科", "合肥", "1-3年", "职位描述岗位职责：1、负责公司大数据平台项目的开发、维护工作；2、参与设计、开发完善数据查询分析平台；3、参与日志采集、分析等工作；4、具体工作有：开发hadoop/hbase插件和监控工具；mapreduce job代码优化；hadoop实时查询框架开发。任职要求：1、计算机相关专业，本科及以上学历；2、有1 ~ 3年大数据或数据仓库相关项目经验，有分布式系统开发经验；3、熟练掌握Hadoop、HBase、Solr、Hive等技术，或掌握相关技术框架；4、熟悉hadoop/hbase原理和内部运行机制；5、精通java编程，有较多的java开发技术组件或基础模块的经验；6、有基于Hadoop系统开发和调优经验者优先；7、熟悉lucene相关技术或者熟悉hadoop/hbase源码者优先考虑；8、熟悉Linux系统，熟悉Python/Perl/Bash shell等脚本编程语言，对网络、操作系统知识有一定了解；9、良好的团队合作精神，对解决挑战型问题充满激情；10、本职位接受应届毕业生和实习生。", "安徽中新软件有限公司", "500-2000人", "成熟型(不需要融资)", "硬件,信息安全", "3.4"
"拉勾", "Hadoop", "Hadoop工程师", "15000-25000", "大专", "东莞", "1-3年", "职位描述岗位职责：1、参与大数据平台的设计与开发，解决海量数据面临的挑战；2、协助建立数据模型，对数据进行挖掘、优化及统计；3、保证大数据平台的正常运行、系统问题定位及优化。任职要求：1、大专及以上学历，3年及以上相关经验；2、熟悉Hadoop、Hive、Storm、Spark、Hbase等分布式框架，熟悉Linux/Unix平台，掌握Shell/Python编程；3、熟悉Java/Scala语言，对Java/Scala原理、底层技术有深入研究者或有日志实时分析处理经验者和机器学习经验者优先；4、善于学习新知识，有较强的逻辑分析和解决问题的能力。核心工作内容：负责建立数据模型，设计和开发大数据平台。", "广东俊特团贷网络信息服务股份有限公司", "2000人以上", "上市公司", "移动互联网,金融", "4.2"
"拉勾", "Hadoop", "Hadoop", "25000-40000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责数据平台的多信息源数据采集、传输、存储、计算、分析和挖掘；2、负责数据平台的建设与开发。3、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；4. 根据业务需求整合优化大数据架构，协助业务层改进job质量及数据流程优化任职要求：1、计算机相关专业本科及以上，5年及以上互联网系统或者其他企业应用系统开发相关经验；2、熟练Python服务端编程，有良好的编码习惯，有Java 开发经验者（spring）优先；3、熟练mongoDB、MySQL、redis，Oracle等常用数据库，；4、深入理解Hadoop/HBase/HDFS／Kafka／Sqoop／Zookeeper，并有相关编程经验；5、熟练使用Spark以及相关组件，有丰富的RDD使用经验，对源代码有一定研究者优先；6、熟悉LEK，有ElasticSearch优化经验者优先；7、有云计算领域经验者，开源社区参与者和贡献者优先；8、有数据统计分析、机器学习、推荐系统、数据挖掘经验者，有MLLib／mahout使用经验的优先；9、具有良好的团队合作能力，工作严谨，有激情，关注用户体验。", "和创（北京）科技股份有限公司", "2000人以上", "上市公司", "移动互联网,企业服务", "4.2"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "大专", "上海", "5-10年", "职位描述岗位职责：1、参与并负责大数据架构的搭建、开发和维护监控2、熟悉统计分析/数学建模/数据挖掘等方法3、提供有价值的商业数据、模型、算法支持4、参与公司平台化产品的开发任职要求：1、5年及以上的Java开发经验，了解J2EE相关技术2、熟悉分布式缓存、消息队列、对高并发大流量系统性能优化有一定的经验3、熟悉Hadoop大数据平台架构，有Map/Reduce开发运维经验，具有Storm、Spark、Hbase等大数据平台经验；4、熟悉Linux的基本操作及应用部署，了解Shell命令5、良好的沟通与团队合作能力以及创业心态6、了解DMP或有数据挖掘以及机器学习项目经验相关开发者优先考虑", "先人掌信息科技（上海）有限公司", "少于15人", "初创型(未融资)", "移动互联网", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-15000", "本科", "深圳", "1-3年", "职位描述工作职责：1.负责公司Hadoop系统的底层搭建，构建公司统一的离线和实时计算平台。2.负责公司日志系统及ETL系统的设计和实现。3.负责公司数据体系的架构设计和规划，充分发挥公司的数据价值。4.跟踪Hadoop生态环境的最新进展。任职资格：1、本科以上学历，熟悉Hadoop生态环境，对Hadoop, Hbase, Hive, Storm等至少一个项目有着深入的了解。2.扎实的Java基础，对至少一门动态语言有过使用经验。3.熟悉Linux系统常用操作。4.对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先。5.良好的学习能力，保持对新技术的敏感性。", "深圳市和讯华谷信息技术有限公司", "150-500人", "成熟型(C轮)", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Spark/Hadoop工程师", "20000-30000", "本科", "北京", "1-3年", "职位描述岗位职责1、负责大数据处理模块的架构设计和开发；2、进行数据统计、分析、查询、挖掘等工作。任职资格1、本科及以上学历，计算机相关专业；2、具备1年以上Spark/Hadoop开发经验，熟练使用kafka；3、热于钻研技术，具备优秀的问题解决能力；4、熟悉大数据处理生态圈开源框架，有社区贡献者优先。We will offer u：1.好的领导：海外留学并在美国 Amazon 总部工作，后在硅谷创业的 CEO ，回国与毕业于英国剑桥计算机的硕士、惠普市场高管强强联合。颜值并不是他们唯一制胜的法宝，暖男的心和睿智的头脑才是最 in 的撩妹技巧！2.好的团队：技术团队来自百度、优酷、新浪等主流互联网公司，智商超群，谦虚好学，举手投足间都散发 Scala 的优雅，及青春的活力。 HOOLI 致力于打造小而美的团队，让每个人都有最大的发挥空间，和有能力的人一起工作，远离撕逼和无意义的争吵。3.好的实力：顶级 VC 天使轮投资，财情与能力匹配，不被调薪幅度和次数限制你的成长。4.好的待遇：全员期权鼓励（因为我们要一起做一件事）；硅谷学习机会（老板免费地陪）；弹性工时灵活安排；高标准午餐晚餐，零食软饮水果的 N 种搭配（满足你吃货的胃）；五险一金，带薪年假，国外旅游，节日礼物，生日聚会，团建轰趴（基础标配）；如果你还有其他创意，请入职联系我实现。5.好的效率： HOOLIers 都已熟练使用 Tower 等效率工具和及时通讯软件沟通，这是我们的「入职培训」，通过这些普及率足够高的产品和好的技巧使用，进而管理记录、推进任务、消息共享，实现「简单工作、快乐生活」！6.好的环境：坐落海淀中关村距苏州街地铁站 2 分钟路程，被落地窗围绕的 loft ， 24 小时新风系统，全岗位 Mac 电脑＋ Dell27 寸广色域显示屏（除非你是 windows 或者 Thinkpad 的死忠粉），人体工学座椅，互联网技术畅销书籍，三开门冰箱微波炉......（无限增加中）7.好的发展：我们坚信，在未来，数据分析将使企业在 10%的时间内创造 90%的价值，而构建实现这项生态系统的只会是数据科学家级别的小伙伴。我们提供成为数据科学家的平台，提供去硅谷深造的通路，提供了解并创造机器学习功能产品的机会。", "北京互利科技有限公司", "15-50人", "初创型(天使轮)", "企业服务,数据服务", "4.2"
"拉勾", "Hadoop", "hadoop", "7000-10000", "本科", "深圳", "应届毕业生", "职位描述【岗位职责】1、负责后台版本功能开发2、负责后台技术问题的跟进和处理【任职要求】1、有扎实的C/C++语言基础，熟悉常用数据结构和算法2、逻辑思维出色，责任心强，良好的沟通和团队协作能力，主动好学有进取心3、计算机相关专业本科及以上学历，欢迎2016届优秀毕业生▶关于乐易◀★极客精神   专注海外精品手机游戏和应用软件的研发、发行和运营，致力于打造世界级一流的产品；★技术深厚   创始人、CTO（原腾讯部门总监），研发经理及技术骨干均为腾讯技术背景；★飞速发展   成立首年盈利，4年每年100%营收增长，已获A轮融资，估值10亿人民币；★导师制    一对一的导师，助你快速成长。▶关于福利◀★一年两次调薪★      ★绩效奖金高达10个月★  ★六险一金★    ★一年两次旅游★  ★7天年假15天带薪事假30天病假★  ★年度体检★        ★高逼格办公环境★   ★每月团建★  ★无限量零食水果供应★", "深圳市乐易网络有限公司", "150-500人", "成长型(A轮)", "移动互联网,游戏", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "10000-15000", "本科", "深圳", "不限", "职位描述工作职责1、负责Hadoop集群的部署，运维和二次开发2、负责周边系统的开发，如调度系统，监控告警系统等3、负责基础数据等清洗，处理等职位要求1、本科以上学历，计算机相关专业2、二年以上 Java/Python 开发经验3、熟悉 Hadoop/HBase/Zookeeper/Spark 等的运行机制和工作原理4、熟悉Linux/Unix平台，熟悉bash5、善于学习新知识，有较强的逻辑分析和解决问题的能力6、有较强的责任心和沟通能力", "深圳市和讯华谷信息技术有限公司", "150-500人", "成熟型(C轮)", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Hadoop运维工程师", "13000-26000", "大专", "杭州", "1-3年", "职位描述岗位职责：1、负责hadoop基础服务平台的Hadoop集群扩容升级；2、对hadoop相关产品参数优化；岗位要求：1、计算机相关专业大专以上2年工作经验；2、有大型Hadoop集群部署使用经验；3、对Hdfs、Yarn、Spark、Hive等产品有一定的优化经验；", "传化物流集团有限公司", "2000人以上", "上市公司", "移动互联网,电子商务", "4.0"
"拉勾", "Hadoop", "Spark/Hadoop工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述美团崇尚用数据说话，自上线起数据平台团队一直在不断完善公司级的统一数据平台。数据平台基于Hadoop构建，目前每天执行20万次计算流程，负责每天百TB的数据存储、分析和实时计算，有2000多个业务指标，为十几个业务线、各层级的团队管理和产品运营，提供大量的数据决策支持。随着美团以每年超过3倍的速度成长，数据规模带来的存储和计算压力，是我们面临的最大挑战。现在我们开始组建负责 Hadoop 性能的技术专家团队，需要对 Hadoop/Spark 性能优化方面具有丰富经验的人才加入。这个团队负责构建稳定高效的大规模数据存储、计算服务，并确保在数据量快速增长的同时，每天凌晨重要的数据计算任务按时高效的完成。工作职责：- Spark/YARN/HDFS//HBase/Kylin/Presto/Hive 的性能改进、功能扩展、故障分析；- 不断解决规模增长带来的技术和业务问题，确保Hadoop 数据平台每天上午8点完成重要数据的计算。职位要求：- 理工类211、985院校本科及以上学历；- 对技术有着永无止境的追求，自认为是技术Geek，具备很强的问题解决能力；- 熟悉Hadoop生态系统开源项目，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解，有patch源代码经验者优先；- 1年以上 Hadoop/Hive 生产环境工作经验；- 有团队管理经验者优先。", "北京三快在线科技有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网,O2O", "3.7"
"拉勾", "Hadoop", "Hadoop高级工程师", "10000-20000", "本科", "北京", "5-10年", "职位描述岗位职责：1、开发基于Hadoop、Spark、Storm的项目系统；2、根据业务需要为大数据仓库的实现提供支持；3、撰写规范专业的技术文档，研究行业前沿技术；4、完成项目分配的工程任务。任职要求：1、3年以上Java开发相关工作经验，熟悉Java核心技术；2、一年以上Hadoop项目开发经验，对Hadoop、Hive、HBase、Spark有深入了解；3、对分布式计算原理有较深的理解，熟悉MapReduce编程、Storm计算；4、熟悉Hive开发及优化、了解Hadoop集群管理及优化；5、熟悉linux开发环境，熟悉shell脚本，熟悉Python语言优先；6、有很强的分析问题和解决问题的能力，有强烈的责任心。 ", "北京思特奇信息技术股份有限公司", "2000人以上", "成熟型(不需要融资)", "数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop运维工程师", "15000-25000", "不限", "上海", "1-3年", "职位描述岗位职责:职位描述：1、负责Hadoop&HBase平台运维，保障各核心服务运行的稳定、通过技术优化提升数据产品的质量和响应速度；2、开发各种Hadoop&HBase大数据自动化运维与监控工具。3、建设基于大数据的运维监控体系。岗位要求：1、计算机科学、计算机工程及相关专业的本科、研究生学历2、三年以上系统运维或大数据运维工作经验，有大型互联网公司工作经验者优先；3、熟悉Hadoop、HBase、Hive、Hue、Spark、impala、zookeeper、oozie、yarn、Scribe、Flume、Storm等开源项目的部署、性能调优；4、熟悉nagios、cacti、ganglia、zabbix、zenoss优先；6、具有良好的学习能力、沟通能力、客户服务意识和团队合作精神；具有强烈的进取精神和乐观的工作态度。", "上海游族信息技术有限公司", "500-2000人", "上市公司", "移动互联网,游戏", "4.5"
"拉勾", "Hadoop", "Hadoop/Spark大数据开发工程师（北京）", "20000-40000", "本科", "北京", "3-5年", "职位描述岗位职责- 负责追踪最前沿的大数据技术，并在客户现场实施大数据项目；- 必要时在客户现场部署SequoiaDB并与 Hadoop、Spark、以及各种BI工具等对接；- 必要时在客户现场对已部署的Hadoop、Spark环境提供技术支持服务任职条件- 大学本科及以上学历；- 3年以上Java应用的开发经验；- 熟悉分布式系统架构，包括Hadoop、Spark、NoSQL、分布式关系型数据库等；- 熟悉Hadoop、Spark等大数据技术，并具体实施过相关项目，可以独立开发MapReduce程序以及Spark RDD；- 精通Java底层JVM原理，有深入调优和调错能力；- 了解Scala，Akka等框架者优先；- 具有团队协作精神，工作严谨主动，人际交流能力良好；", "广州巨杉软件开发有限公司", "50-150人", "成长型(B轮)", "数据服务", "4.4"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述工作职责：1、参与大规模数据的业务分析、采集处理、分布存储、应用、安全等解决方案的设计、开发与优化；2、负责数据平台的建设与开发；3、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；4、根据业务需求整合优化大数据架构，协助业务层改进job质量及数据流程优化5、根据业务需求，提出最优的技术解决方案；任职要求：1、本科以上学历，2年及以上互联网开发经验；2、精通Java开发，熟悉Map/Reduce编程；3、深入理解Hadoop/Hive/HBase/HDFS/Kafka/Zookeeper，并有相关编程经验；4、熟悉Spark以及相关组件，有丰富的RDD使用经验，对源代码有一定研究者优先；5、有云计算领域经验者，开源社区参与者和贡献者优先；6、有数据统计分析、机器学习、推荐系统、数据挖掘经验者，有MLLib／mahout使用经验的优先；7、具有良好的团队合作能力，工作严谨，有激情，关注用户体验；", "北京百合在线科技有限公司", "500-2000人", "初创型(未融资)", "移动互联网", "3.9"
"拉勾", "Hadoop", "Hadoop（java）", "18000-28000", "本科", "上海", "5-10年", "职位描述• 5 years experience in design, coding and unit testing of scalable, distributed, fault-tolerant applications• Expertise in OO design methodology and application development in Java and J2EE, including Spring, AJAX, jQuery, JDBC• Knowledge of XML, XSL, CSS, JavaScript, and HTML• Experience with relational database and SQL• Experience with RESTful api design and implementation• Experience with BigData tech stack like Hadoop/Cascading/Pig/Kafka/Spark/Teradata will be a strong plus• Proven results oriented person with a delivery focus in a high velocity, high quality environment• Fluent in English speaking and writing", "康伟实软件（上海）有限公司", "2000人以上", "上市公司", "电子商务", "4.4"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "上海", "1-3年", "职位描述岗位职责： 1、负责分布式数据平台建设、数据应用开发 2、分布式平台应用开发（Hadoop/Hive/Spark/ElasticSearch） 3、开发数据统计及挖掘系统，各类统计及挖掘程序的开发 4、系统的性能分析与系统优化岗位要求： 1、良好的编程开发能力，精通Java开发语言 2、精通Hadoop2.0框架，熟悉分布式系统部署、开发、测试、维护过程与方法 3、Hive、ZooKeeper、Hbase、Spark、ElasticSearch、kafka、flume等分布式开源软件实际开发和应用经验者优先 4、熟练掌握Linux常规命令与工具，熟悉shell脚本语言 5、熟悉数据分析和数据挖掘等技术，具备对常用挖掘算法的使用能力者优先 6、对新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神", "数数信息科技（上海）有限公司", "15-50人", "成长型(A轮)", "游戏,数据服务", "3.6"
"拉勾", "Hadoop", "Hadoop开发工程工程师", "15000-30000", "大专", "广州", "3-5年", "职位描述工作内容/职位描述：1、负责大数据BI产品的研发工作2、对公司海量数据进行处理分析任职资格：1.计算机或相关专业本科及以上学历2.两年以上JAVA开发经验，一年以上spark streaming项目开发经验3.熟悉主流的大数据处理架构（kafka、hadoop、mongodb、redis等系统）4.做事认真，有耐心；强烈责任感、和良好的沟通能力 职能类别： 互联网软件开发工程师 多媒体/游戏开发工程师", "广州市浩隆文化发展有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,电子商务", "3.0"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "北京", "5-10年", "职位描述大数据开发工程师岗位职责：1.大数据环境下的软件开发，数据应用分析；2.大数据平台数据清洗、转换、建模的相关开发；3.保证大数据平台的正常运行、系统问题定位及优化；4.维护公司核心BI系统。职位要求：1.精通数据抓取，数据清洗（ETL），数据仓库建模；2.熟练掌握MySQL、Oracle的数据库技术；3.了解HADOOP大数据平台架构，熟悉HDFS/HBase/Hive/MapReduce，熟练掌握Mapreduce程序开发；4.有电商行业，大数据平台开发经验者优先；5.熟练掌握Linux操作系统，了解shell等脚本编程；6.有责任心，工作积极主动，勤恳踏实，能承担一定的工作压力，具备良好的沟通能力和团队合作精神 。", "南京新与力文化传播有限公司", "500-2000人", "成熟型(D轮及以上)", "电子商务,文化娱乐", "3.9"
"拉勾", "Hadoop", "Java/Hadoop", "12000-20000", "本科", "杭州", "5-10年", "职位描述岗位职责：1、负责大数据平台的设计和开发，负责hadoop、spark等云计算平台的开发和优化2、负责数据分析系统的升级和优化，不断提升系统的稳定性和性能3、规划、设计基于海量数据挖掘分析的解决方案任职要求：1、本科5年（硕士3年）以上软件研发经验2、精通java体系架构，熟悉linux平台，具备扎实的数据结构与编程功底3、精通至少一种Spark或Hadoop生态圈技术，阅读过相关源码，有RDD/MapReduce相关开发经验4、对多线程和JVM调优有深入理解与实践的优先6、责任感强，思维严谨，乐于钻研，对技术流行趋势敏锐的洞察力", "浙江大华技术股份有限公司", "2000人以上", "上市公司", "信息安全", "4.2"
"拉勾", "Hadoop", "hadoop/storm高级数据开发工程师", "10000-20000", "本科", "北京", "1-3年", "职位描述职位描述1.基于hadoop/storm计算框架，实现个性化推荐离线/实时计算模型。 2.为已成型的推荐产品做持续地迭代优化。 职位要求： 1、本科及以上学历，计算机相关专业； 2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。 3、熟悉Hadoop/Storm/HIVE/Hbase等分布式开源项目及其工作原理，并有实际开发经验。 4、熟悉常用脚本语言shell,python等。 5、有互联网或移动互联网公司背景优先。", "北京京东世纪贸易有限公司", "2000人以上", "上市公司", "电子商务", "-"
"拉勾", "Hadoop", "大数据、Hadoop开发工程师", "8000-15000", "本科", "广州", "1-3年", "职位描述工作职责：（1）负责公司大数据项目架构设计，系统开发工作。（2）负责海量数据仓库设计与开发。（3）负责大数据平台系统持续性优化工作。任职要求：（1）全日制本科及以上学历，2年以上互联网数据开发工作经验。（2）精通sql，必须具备DW/BI开发工作经验。（3）至少熟练掌握hadoop，hive，spark其一开发。（4）熟悉NoSQL数据库开发。（5）熟悉linux/unix操作系统。（6）具备大数据技术钻研精神，对大数据开发感兴趣。（7）有大数据开发工作经验优先。", "铂涛信息技术（广州）有限公司", "500-2000人", "初创型(未融资)", "移动互联网,旅游", "4.2"
"拉勾", "Hadoop", "hadoop", "10000-15000", "本科", "深圳", "1-3年", "职位描述【岗位职责】1、负责后台架构设计和优化2、负责后台版本功能开发3、作为接口人，负责与产品、客户端、测试沟通协调【任职要求】1、计算机相关专业本科及以上学历2、1年以上Unix/Linux下Server开发经验3、精通C/C++开发语言4、精通TCP/IP协议，进程间通讯编程，熟悉Unix/Linux下常用架构设计方法5、熟悉Unix/Linux操作系统原理、常用工具6、熟悉Perl/python，shell等脚本语言优先7、具备良好的分析解决问题能力，能独立承担工作任务及把控任务进度8、责任心强，良好的沟通和团队协作能力，主动好学有进取心9、有hadoop或其它分布式计算存储平台经历更佳▶关于乐易◀★极客精神   专注海外精品手机游戏和应用软件的研发、发行和运营，致力于打造世界级一流的产品；★技术深厚   创始人、CTO（原腾讯部门总监），研发经理及技术骨干均为腾讯技术背景；★飞速发展   成立首年盈利，4年每年100%营收增长，已获A轮融资，估值10亿人民币；★导师制    一对一的导师，助你快速成长。▶关于福利◀★一年两次调薪★      ★绩效奖金高达10个月★  ★六险一金★    ★一年两次旅游★  ★7天年假15天带薪事假30天病假★  ★年度体检★        ★高逼格办公环境★   ★每月团建★  ★无限量零食水果供应★", "深圳市乐易网络有限公司", "150-500人", "成长型(A轮)", "移动互联网,游戏", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "10000-15000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责Hadoop相关项目的设计与开发工作；2、基于大数据处理平台的模型设计与数据处理工作；3、Hadoop相关业务脚本的性能优化与提升，不断提高系统运行效率。任职资格：1、本科及以上学历，计算机或者相关专业;2、2年以上JAVA开发经验，对JVM原理有一定的了解;3、熟悉hadoop相关各种开源项目，有Hive/Hive/HBase实际经验者优先;4、掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先;5、熟悉Linux系统，有电信BI行业经验者优先录用; 6、软件基础理论知识扎实，具有良好的数据结构、算法功底;7、对数据分析新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神。", "北京思特奇信息技术股份有限公司", "2000人以上", "成熟型(不需要融资)", "数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop工程师（应届毕业生/实习生）", "4000-6000", "硕士", "北京", "应届毕业生", "职位描述岗位职责:1.大数据环境下的软件开发，数据应用分析；2.大数据平台数据清洗、转换、建模的相关开发；3.保证大数据平台的正常运行、系统问题定位及优化；4.维护公司核心BI系统；任职资格:1.计算机，数学，等相关专业研究生及以上学历，985、211工程大学优先录用；2.熟悉数据抓取，数据清洗（ETL），数据仓库建模；3.了解MySQL、Oracle的数据库技术；4.了解HADOOP大数据平台架构，了解HDFS/HBase/Hive/MapReduce，及Mapreduce程序开发；5.熟悉Linux操作系统，了解shell等脚本编程。", "南京新与力文化传播有限公司", "500-2000人", "成熟型(D轮及以上)", "电子商务,文化娱乐", "3.9"
"拉勾", "Hadoop", "Hadoop工程师", "8000-10000", "本科", "武汉", "1-3年", "职位描述1、 熟悉 Linux 操作系统，有良好的编程能力，以及较强的动手和学习能力；2、 熟悉 Java、Scala等其中一种编程语言；3、 有从事分布式数据存储与计算平台应用开发经验，熟悉 Kafka, Storm,Hadoop, HBase, Hive等相关技术；4、 有从事全文检索elasticseach及与hadoop相结合的经验技术；5、 熟悉软件开发过程，有良好的代码和文档编写习惯；6、 有良好的逻辑思维和表达能力，善于学习，独立思考能力强；7、 最少符合Kafka,Storm,Hadoop,HBase,Hive,ElasticSearch等其中1至2项技术", "武汉电动汽车技术开发有限公司", "50-150人", "成长型(不需要融资)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-30000", "硕士", "上海", "不限", "职位描述岗位职责：1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；4.基于MapReduce、Spark、Flume等的大数据开发；5.学习和研究大数据技术最新动向以满足产品、项目的需求。要求：1.计算机相关专业本科及以上；2.软件基础理论知识扎实，具有良好的数据结构、算法功底；3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；6.对新技术敏感，有一定独立分析，技术研究能力；7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；8.有个人开源项目或参与开源项目者优先；9.有代码洁癖和自发组织Code Review的开发者优先。", "上海宏路数据技术股份有限公司", "50-150人", "初创型(未融资)", "移动互联网", "4.3"
"拉勾", "Hadoop", "大数据开发-Hadoop、Spark、NoSQL", "15000-25000", "本科", "上海", "3-5年", "职位描述岗位描述1、参与大数据平台架构的整体规划和设计；2、负责平台的整体数据架构设计，完成从业务模型到数据模型的设计工作 ；3、负责根据业务功能、业务模型，进行数据库建模设计对调度系统，元数据系统有非常深刻的认识和理解，能解决高并发系统中的关键问题；4、对数据挖掘及业务开发团队提供技术支持，协助方案规划；5、负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品；岗位要求1、 计算机、应用数学、统计学等相关专业，全日制本科以上学历;2、 5年以上大数据经验，包括Hadoop、Spark、NoSQL等； 3年以上技术团队管理经验；3、 熟练掌握Java或者C#编程语言，并熟悉Python/Perl/Shell等至少一种脚本语言；4、 熟悉分布式计算、分布式存储、云计算、大数据相关技术；5、 熟悉分布式系统的架构，有分布式系统架构设计的经验；6、 数据架构规划、数据建模、数据库设计以及程序设计、开发经验；7、 精通至少一种常见数据库,至少一种开源ETL工具、数据建模工具；8、 有基于Hadoop、MPI或Cassandra、MongoDB分布式平台, HBase及类似的NoSQL存储, MySQL，和BI系统等实践经验优先。9、 有移动通信等行业应用经验者优先；", "上海百林通信网络科技服务股份有限公司", "50-150人", "成长型(A轮)", "移动互联网", "3.2"
"拉勾", "Hadoop", "Hadoop 负责人", "25000-35000", "本科", "杭州", "3-5年", "职位描述职责：1、负责Hadoop、Spark方向技术2、打造有影响力的开发团队岗位要求：1.计算机相关专业本科以上学历2.至少精通Hadoop、Spark或者相关大数据系统的一种3.具有广阔的技术视野，熟悉开源生态，熟悉实时计算、离线计算等大数据解决方案4.具备扎实的性能优化和问题诊断能力", "智翔（杭州）企业管理咨询有限公司", "15-50人", "初创型(不需要融资)", "移动互联网,金融", "-"
"拉勾", "Hadoop", "大数据开发工程师(Hadoop/Spark)", "18000-35000", "本科", "上海", "不限", "职位描述Hadoop 工程师Junior （1~3年）熟练使用Java Core各个主要类库，包括IO，Collection, Reflection等了解设计模式，至少能说出1，2个设计模式的常用使用场景了解数据库编程，能独立写SQL语句，使用JDBC，Transaction来和数据库交互使用过Spring， Hibernate, Grails, Groovy 等Java生态的框架会是一个Big Plus写过Map Reduce Job，对Hadoop 生态的各个产品HDFS，Hbase，Hive等有一定了解Senior （3年+）写过大型Hadoop集群的Map Reduce Job，能够熟料使用配置HDFS，Hbase，Hive，Flume，Zookeeper等Hadoop生态圈的各个产品。熟练使用Java Core各个主要类库，包括IO，Collection, Reflection等熟练使用各常用设计模式，能说出各主流框架和Java Core 使用的设计模式有Java Concurrent 开发和NIO/BIO的相关经验对JVM，GC，Classloading有所了解熟练使用过诸如Spring， Hibernate等Java生态圈主流框架对数据库有一定了解，知道隔离级别，索引的作用和实现福利待遇：1、五险一金、年底双薪；2、年度旅游、带薪年假；3、扁平管理、弹性工作；4、定期培训、专家指导；5、团队聚餐、健身福利、股票期权；只要你有能力、有梦想，想和我们一起打造中国移动互联网最牛逼的企业，福利薪资待遇都不是问题！简历及作品请发送至邮箱：shenjun#magicwindow.cn（发送邮件时#替换成@）", "上海猎鸿信息科技有限公司", "15-50人", "成长型(A轮)", "移动互联网,企业服务", "4.0"
"拉勾", "Hadoop", "hadoop运维架构师", "15000-25000", "本科", "上海", "1-3年", "职位描述岗位职责:职位描述：1、负责Hadoop&HBase平台运维，保障各核心服务运行的稳定、通过技术优化提升数据产品的质量和响应速度；2、开发各种Hadoop&HBase大数据自动化运维与监控工具。3、建设基于大数据的运维监控体系。岗位要求：1、计算机科学、计算机工程及相关专业的本科、研究生学历2、三年以上系统运维或大数据运维工作经验，有大型互联网公司工作经验者优先；3、熟悉Hadoop、HBase、Hive、Hue、Spark、impala、zookeeper、oozie、yarn、Scribe、Flume、Storm等开源项目的部署、性能调优；4、熟悉nagios、cacti、ganglia、zabbix、zenoss优先；6、具有良好的学习能力、沟通能力、客户服务意识和团队合作精神；具有强烈的进取精神和乐观的工作态度。", "上海游族信息技术有限公司", "500-2000人", "上市公司", "移动互联网,游戏", "4.5"
"拉勾", "Hadoop", "规划分析岗（Hadoop数据科学家方向）(002240)", "15000-20000", "不限", "深圳", "5-10年", "职位描述岗位职责:1、搭建基于Hadoop/Spark的数据挖掘体系，完善卡中心数据挖掘体系及大数据分析体系；2、研究大数据领域前沿数据挖掘技术，并引入相应技术在卡中心的使用。3、进行大数据分析、并行算法开发；4、负责大型数据挖掘项目方案制定、项目实施落地及优化等；5、开展文本挖掘、舆情分析、产品偏好、渠道偏好、定价策略等领域数据挖掘工作；6、为团队成员各项工作提供技术及业务指导及协助；任职资格:1、熟悉分布式计算框架（hadoop、spark、Storm等）及相关经验；2、熟练掌握Hive/SQL，掌握Python,R等一种以上常用数据挖掘编程语言；熟悉Python、R相关数值科学计算库（NumPy,SciPy等）；3、熟悉常用机器学习算法（如分类、回归、聚类、关联规则等）及其原理，对机器学习、深度学习、集成学习有深入了解；4、丰富的机器学习算法（分类器，推荐系统，NLP模型等）应用场景开发项目经验，掌握机器学习应用于实际问题的完整流程。5、较强的逻辑思维能力、数据敏感度，擅于利用数据发现问题及解决问题；6、自我驱动能力，对新技术有强烈求知欲和学习能力，有较高的外文资料阅读和翻译能力；7、较强的沟通表达能力及良好的团队协助能力。优先考虑：1、3年以上大型数据挖掘项目经验；2、2年以上大规模分布式计算平台的使用和并行算法开发及项目实施经验；3、BAT、华为数据挖掘工作经验；", "中信银行股份有限公司信用卡中心", "2000人以上", "上市公司", "移动互联网,金融", "4.0"
"拉勾", "Hadoop", "Java大数据开发工程师（Hadoop开发）", "15000-25000", "不限", "北京", "3-5年", "职位描述这里是联众游戏—— 1998年创立，18年棋牌文化的传承与发扬—— 2014年6月30日，香港联交所主板公开上市(股票代码06899.HK）—— 产品线涵盖客户端、网页、移动端，并基于云计算实现跨平台完美互通—— 智力运动产业，良性互动，实现高度可持续发展的智力运动生态圈我们可以提供给您1、工作时间 —— 早九晚六，弹性考勤，周末双休2、带薪年假 —— 入职第一年即可享受年假3、薪酬福利 —— 五险一金，补充商业保险，年终奖金4、晋升平台 —— 每年提供晋升机会，提供良性晋升渠道5、团队活动 —— 兴趣小组（棋牌 、羽毛球、篮球、足球等），拓展活动，运动会，冷餐会，team building6、培训课堂 —— 提供形式多样的培训课程，帮助增强业务能力，丰富业余爱好7、增值福利 —— 开年红包，健身房，大厦免费班车，年度体检，工会节日福利，生日福利，咖啡公园，免费会员资格8、协助办理工作居住证岗位描述：参与开发基于大数据的BI运营分析系统以及相关的支持系统.对游戏运行中产生的各种日志数据进行深入分析,生成包括游戏运营报告,游戏运行实时监控,用户画像等各项分析结果.整个系统基于hadoop及相关开源项目(kafka,spark,hive,hbase,redis等)来构建数据分析平台,同时借助D3,R语言等数据分析和可视化工具来提供丰富的数据展现效果.作为一个全栈工程师,你可能需要：1、了解产品特性,与产品设计和开发团队合作,制定日志数据的输出和采集方案；2、基于java,MapReduce,spark和Hive编写代码或脚本对汇集的日志数据进行清洗,转换,建模和分析；3、使用D3,R语言等数据分析和可视化工具,按照业务部门的需求完成各种报表的数据展示；4、开发配置管理系统,权限认证系统,报表系统等支持系统；5、对开发及使用过程中的BUG,疑难问题,分析原因,寻求解决办法；6、对产品和项目研发可能会用到的新技术进行预研。任职要求：1、对开源技术有很强的钻研精神，对主流的开源项目有过深入的研究；2、3年以上Java开发经验, 精通Java语言基础知识（jdbc,net,io,xml,多线程,反射等）；3、2年以上的Linux使用经验, 熟悉Linux Server的日常配置和管理，并能编写简单的shell；4、对hadoop系列(MapReduce,ZooKeeper,Spark,Hive,HBase,Kafka,Tez等)分布式计算工具有过了解或经验者优先；5、有SPSS, D3, R语言等数据分析和可视化工具的使用经验者优先。", "北京联众互动网络股份有限公司", "500-2000人", "上市公司", "游戏", "3.8"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-25000", "本科", "上海", "3-5年", "职位描述岗位职责：1、基于RESTful的远程调度平台的需求分析，开发实施；2、大数据部元数据管理平台开发；3、大数据部后端报警平台的需求分析，开发实施；4、大数据部后端Hadoop作业调度平台开发；5、大数据部Hadoop生态圈应用开发，如Storm,Spark等应用；6、大数据部Hadoop监控管理平台开发，如Zookerper等；7、大数据部日志分析系统开发，如kafka，Flume等。任职要求：1、计算机相关专业，全日制本科以上学历；2、3年以上Java及数据库应用开发经验；3、精通流行的开发框架：SpringMVC/struts2、Hibernate/Ibatis、Spring等；4、精通Html、Css、Javascript（ExtJs）、JSP、Servlet、XML、JDBC、SOA、AOP等J2EE常用技术；5、熟悉JBOSS、Tomcat等服务器产品，熟悉安装、调试、发布配置应用，熟悉Linux操作系统更佳；6、熟悉Oracle，MySQL，SQLServer数据库；7、有Hadoop平台生态圈开发经验优先；8、对工作有热情，富有团队协作精神、责任心强。", "东方财富信息股份有限公司", "2000人以上", "上市公司", "金融", "4.0"
"拉勾", "Hadoop", "Hadoop", "15000-20000", "本科", "北京", "3-5年", "职位描述1.参与Hadoop相关项目开发，公司的标签画像产品开发。2.用Map/Reduce实现业务部门的数据需求3.熟悉etl开发过程；1、2年以上Hadoop或HBase的Java开发经验2、熟悉Hadoop、HBase、Hive、Spark等组件，Map/Reduce编程3、熟悉Lucene，ElastiSearch开发者优先4、有shell、python开发经验优先5、有数据仓库或互联网行业项目经验优先", "北京百分点信息科技有限公司", "500-2000人", "成熟型(D轮及以上)", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "北京", "不限", "职位描述岗位职责：1、根据需求文档完成Hadoop等功能设计、系统部署、程序开发与测试2、分析与解决线上问题，定位线上服务瓶颈与调优系统性能3、构建数据仓库，优化线上代码4、数据分析及撰写分析报告5、监控值班任职要求：1、熟悉至少java,python等任何一门语言，对数据结构和算法设计具有深刻的理解2、具备丰富的Linux/Unix下开发经验3、熟练掌握shell使用者优先4、熟悉分布式系统、大规模分布式存储和数据处理、hadoop、spark等相关技术及其原理", "中国互联网络信息中心", "150-500人", "成长型(不需要融资)", "企业服务,数据服务", "4.5"
"拉勾", "Hadoop", "（大数据）Hadoop研发工程师", "10000-20000", "本科", "深圳", "1-3年", "职位描述（熟悉Linux，熟悉Hadoop、HBase、Hive、MapReduce或有一定实践经验）--------------------------------岗位描述：1、负责公司大数据平台和大数据系统产品的设计和开发。2、针对公司大数据业务进行大数据平台、数据分析、挖掘软件的开发。--------------------------------岗位要求：1、本科及以上学历，两年以上java开发经验，精通Spring、Hibernate、Struct、Junit，熟悉juc与socket编程技术；2、熟悉Hadoop、HDFS、Hbase、Hive、Spark、Storm、Flume等（必备），有一定实践经验；3、熟悉Postgresql、Mysql或Oracle数据库；4、熟悉linux开发环境，能够熟练使用shell、python等脚本；5、对大数据分析和处理计算有强烈兴趣。--------------------------------★傲天科技（股票代码：837929）总部位于深圳南山软件园，大数据安全技术与应用服务商，园内绿化好，临近1号线深大地铁站，发展空间广阔，热忱欢迎您的加盟。", "深圳市傲天科技股份有限公司", "150-500人", "上市公司", "数据服务,信息安全", "3.4"
"拉勾", "Hadoop", "Hadoop", "7000-11000", "本科", "天津", "1-3年", "职位描述岗位职责：1、负责Hadoop相关项目的设计与开发工作；2、基于大数据处理平台的模型设计与数据处理工作；3、Hadoop相关业务脚本的性能优化与提升，不断提高系统运行效率。任职资格：1、本科及以上学历，计算机或者相关专业;2、2年以上JAVA开发经验，对JVM原理有一定的了解;3、熟悉hadoop相关各种开源项目，有Hive/Hive/HBase实际经验者优先;4、掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先;5、熟悉Linux系统，有电信BI行业经验者优先录用;6、软件基础理论知识扎实，具有良好的数据结构、算法功底;7、对数据分析新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神。", "北京思特奇信息技术股份有限公司", "2000人以上", "成熟型(不需要融资)", "数据服务", "4.3"
"拉勾", "Hadoop", "Hadoop工程师", "15000-30000", "不限", "上海", "不限", "职位描述岗位职责：1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；4.基于MapReduce、Spark、Flume等的大数据开发；5.学习和研究大数据技术最新动向以满足产品、项目的需求。要求：1.计算机相关专业本科及以上；2.软件基础理论知识扎实，具有良好的数据结构、算法功底；3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；6.对新技术敏感，有一定独立分析，技术研究能力；7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；8.有个人开源项目或参与开源项目者优先；9.有代码洁癖和自发组织Code Review的开发者优先。", "上海宏路数据技术股份有限公司", "50-150人", "初创型(未融资)", "移动互联网", "4.3"
"拉勾", "Hadoop", "Hadoop工程师", "15000-30000", "本科", "上海", "1-3年", "职位描述工作职责：1、负责Hadoop集群相关的开发、调优、监控等工作；2、负责Hbase、Spark项目开发、实施工作；3、负责数据平台的基础架构设计和优化工作。职位要求：1、深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理；2、熟练掌握Java开发，有开源软件源码阅读和fix经验者优先；3、技术Geek,对技术有很高的热情；4、有大规模Hadoop集群运维经验者优先；5、具有快速解决问题的能力和较强的学习能力；6、熟悉linux系统；7、附上github地址或blog地址有加分。", "上海游竞网路科技有限公司", "500-2000人", "成长型(B轮)", "游戏", "4.2"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "北京", "3-5年", "职位描述任职要求1. 负责部门业务相关指标数据的数据建模、计算；2. 负责日志系统设计开发岗位职责及工作内容1. 计算机、数学等相关专业，硕士及以上学历，4年及以上工作经验，有企业级数据平台相关系统开发经验；2. 熟练掌握Hadoop系列大数据存储、分析计算的工具（如Hive，HBase，MapReduce），3. 至少熟悉一种关系型数据库（如MySQL，Postgresql）和高性能KV存储（如Redis，RocksDB）；4. 精通JAVA/scala等某一种语言，能够将数据处理和计算的能力封装为服务；4. 熟悉Spark、Storm等分布式计算框架者优先；5. 具备海量服务、分布式系统架构设计经验者优先；6. 数据数据仓库相关理论着优先职位发布者", "北京蓝汛通信技术有限责任公司", "500-2000人", "上市公司", "企业服务", "4.0"
"拉勾", "Hadoop", "Spark/Hadoop工程师", "10000-20000", "本科", "上海", "1-3年", "职位描述我们在寻找并肩战斗的小伙伴，我们需要你：•分析数据、使用数据，实现及优化推荐系统效果•理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设•负责设计，实现或改进分实时流式计算平台 (数据量: 数个TB / 天）•我们希望你：•充满好奇心，享受coding，学习能力强，有代码洁癖•技术全面，对技术有热情，关注技术发展方向•极强的责任心，追求完美的习惯，刨根问底的精神•我们有着共同的价值观:正直，创新，合作，严谨，尽责，情怀技术上：•熟悉Scala语言，对Scala原理、底层技术有深入研究者优先•熟练使用spark BDAS各组件，对基于内存的计算框架有深入理解• 精通Hadoop、Hive、Storm、Spark、Hbase、zookeeper、Kafka、Flume等分布式框架• 熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，精通源代码尤佳•熟练使用spark机器学习算法包你将加入这样一群人：•追求自由、平等，提倡简单、透明和分享•对新事物充满好奇，对技术充满热情•热爱生活、热爱运动，热爱科技", "上海坤雁数据服务有限公司", "50-150人", "初创型(天使轮)", "移动互联网,数据服务", "4.0"
"拉勾", "Hadoop", "hadoop/spark 开发工程师", "10000-18000", "本科", "北京", "3-5年", "职位描述主要负责开发（hadoop数据分析系统、spark 实时数据分析系统、ES搜索系统）【岗位职责】1、负责基于Hadoop/Spark生态系统的研发；2、负责基于搜索引擎（ElasticSearch）的产品研发；3、负责Hadoop/Spark集群调优；4、负责对数据进行建模。【任职要求】1、大学本科或以上学历，计算机相关专业；2、对Hadoop / Spark 生态系统组件（HBase、Hive、Pig、ZooKeeper、Mahout等）熟悉，对Flume、Kafka熟悉；3、熟悉linux开发环境；熟练掌握python、ruby中的一种；4、有hadoop / Spark调优、统计学知识的优先；5、有机器学习经验者优先；6、熟悉ElasticSearch、Lucene优先；7、能够读懂英文文档。", "高升控股股份有限公司", "150-500人", "上市公司", "企业服务,数据服务", "4.5"
"拉勾", "Hadoop", "大数据开发工程师（Hadoop、spark方向）", "20000-40000", "本科", "成都", "5-10年", "职位描述职位要求：计算机或相关专业本科（或以上）学历熟悉Linux shell以及SQL 语言熟悉Java语言精通Hadoop，熟悉Hadoop，HBase，Hive基本命令有Hadoop/HBase/Hive/Spark/Flume使用经验者优先做事认真负责，沟通能力良好，自学能力较强", "北京联想利泰软件有限公司", "500-2000人", "初创型(未融资)", "移动互联网,招聘", "3.9"
"拉勾", "Hadoop", "Hadoop运维工程师", "18000-30000", "本科", "北京", "3-5年", "职位描述【职位描述】1.负责Hadoop&HBase平台运维、各核心服务运行的稳定、高效和优化工作,提升数据产品的质量和响应速度；2.开发各种Hadoop&HBase大数据自动化运维与监控工具。【职位要求】1. 熟悉GFS/Hadoop、Hive、HBase等开源项目；2.熟悉Apache Hadoop部署、性能调优;熟悉Jetty，Thrift3.熟悉nagios,cacti,ganglia,zabbix,zenoss优先；4.对大数据和自动化运维开发有浓厚兴趣，熟悉Hadoop、HBase、Hive、Scribe、Flume、Storm等分布式相关技术优先。", "北京口袋时尚科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网 ,电子商务", "4.0"
"拉勾", "Hadoop", "Hadoop", "18000-36000", "大专", "深圳", "5-10年", "职位描述1.Java、Python中至少一门语言的5年以上的开发经验；2.熟悉运用MapReduce、HDFS、Hive、Hbase、Sqoop、storm、kafka、mongoDB、redis、elasticSearch中至少4种组件，并基于这4种以上组件的开发经验；3.熟练使用关系型数据库，3年以上shell编程经验；4. 大数据组件性能、存储优化经验丰富，3年以上从业经验。", "武汉佰钧成技术有限责任公司", "2000人以上", "成熟型(不需要融资)", "移动互联网,分类信息", "3.4"
"拉勾", "Hadoop", "Hadoop", "20000-40000", "本科", "北京", "1-3年", "职位描述岗位职责：1. 负责大数据Hadoop实战技术课程的授课；2. 负责参与大数据课程体系的建设和完善；3. 负责部分外部项目的实现和实施。任职资格：1. 有1-3年大数据开发的工作经验；2. 熟练掌握Java、Hadoop、Hive、HBase、Zookeeper、Spark、Storm的安装配置、系 统架构、核心算法与开发测试；3. 熟练掌握大数据处理技术的典型应用场景；4. 有跨国企业或知名企业工作经验的优先；5. 从事过Hadoop、Spark开发的优先；6. 有过大数据培训课程授课经验的优先；7. 有3年以上Java研发经验的优先。岗位要求：1、敬业、责任心强、热爱IT培训事业；2、计算机及相关专业毕业，本科以上学历，具有3年以上软件开发经验（开发经验丰富的可放宽学历要求）；3、综合素质好，有良好的沟通、表达能力、语言及文字水平佳；4、具有团队协作精神。", "光环国际管理咨询集团", "150-500人", "成长型(A轮)", "教育", "4.2"
"拉勾", "Hadoop", "Hadoop", "13000-20000", "本科", "上海", "不限", "职位描述Hadoop开发工程师负责编写分布式数据处理服务器端的程序代码，帮助开发企业SaaS服务平台、系统。对分布式数据处理有浓厚兴趣，对跟踪最新开源技术有心得。职位要求：有优秀的解决问题的能力，对分析和处理有挑战性的问题充满激情；有很强的学习能力，积极主动，能承担压力。有扎实的计算机基础，熟悉 Java / Scala 等编程语言；对 Spark / Hadoop / HBase / Kafka / ElasticSearch有了解。", "上海知助数据科技有限公司", "少于15人", "初创型(天使轮)", "数据服务,企业服务", "-"
"拉勾", "Hadoop", "Hadoop", "13000-25000", "本科", "北京", "1-3年", "职位描述工作内容：1、分布式海量数据处理2、hadoop等数据系统优化3、基础系统架构、模块研发4、公共基础库维护能力要求：1、熟悉或精通Java/Python/C++/PHP/Shell等一门以上语言2、熟悉DB、OS、Web开发等相关知识，对Linux相关的各类技术情有独钟3、具有良好的算法数据结构基础，在各类计算机相关竞赛中获奖者优先4、有大规模、高性能互联网网站系统相关的设计和开发经验者优5、具有良好的学习能力和成长潜力，渴望和团队一起快速成长", "多盟睿达科技（中国）有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,广告营销", "4.0"
"拉勾", "Hadoop", "Hadoop/Spark工程师", "25000-40000", "本科", "北京", "应届毕业生", "职位描述岗位职责：1. 参与基于Hadoop/Spark生态大数据系统的研发、实现海量数据的收集和分析；2. 关注开源技术动态, 能根据公司产品和业务特征不断提出改进建议和创新方案。 岗位要求：1. 熟练精通数据结构与算法，精通Hadoop/Spark，熟悉Hadoop生态圈(Storm,Kafka等), 有Hadoop/Spark开源经验者优先；2. 具有2年以上大数据系统开发或维护经验者优先；3. 具有良好的团队合作和沟通能力，熟悉软件开发流程，具有项目管理经验者优先；4. 具有良好的解决问题的能力，学习能力强，对新技术有热情；5.大学本科及以上学历，计算机或相关专业优先。", "云狸科技（北京）有限公司", "15-50人", "初创型(天使轮)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "大数据hadoop开发", "10000-20000", "本科", "上海", "3-5年", "职位描述1）职位要求：1、3-5年以上JAVA WEB编程经验。其中1年以上大数据开发相关经验2、熟练J2EE编程开发技术（JSP、JSTL、JDBC、JavaScript等相关技术）。3、熟练掌握Spring、Spring MVC、JPA或Hibernate等主流的开发框架。4、熟悉主流JavaScript，掌握jquery、bootstrap等（优先）5、能够熟练编写Shell/Perl/Python程序，了解Django框架6、熟悉cloudear-hue的部署和使用7、了解Docker的原理，掌握Docker等相关容器的实施8、有以下一种数据库的开发经验：oracle、mysql、PostGreSQL9、有能力对大规模分布式集群的CPU/内存总体情况、网络吞吐、I/O吞吐进行监控、测试、调优（优先）10、有Linux服务器的性能调优能力，大规模服务器的运维经验（优先）11、熟悉Hadoop/Spark，包括原理、架构、代码，具有相关研发经验，能够进行性能调优、功能扩展以及故障排除（优先）12、有较强的团队协作和沟通能力，具备较强的技术研究能力和攻关能力，善于学习新事物。13、工作责任心强，能承受一定的工作压力。2）岗位职责：1、全栈工程师，负责hadoop平台运维2、大规模集群管理工具的开发、部署和维护3、负责开放数据平台的研发工作", "上海都纳信息科技有限公司", "50-150人", "初创型(未融资)", "电子商务", "-"
"拉勾", "Hadoop", "Hadoop研发工程师", "6000-10000", "本科", "广州", "不限", "职位描述针对目前市场稀缺成熟Hadoop工程师状态，泰迪作为大数据人才培养的前沿者，将对有一定计算机语言基础且把大数据工程师作为职业发展规划的人才进行免费定向培养，且培训完成后还将进行人才输送。简而言之，只要符合要求，就可免费参与4个月的Hadoop大数据脱产培训！申请条件：具有计算机编程语言基础知识、JAVA编程语言基础者均可申请，需签定定向培养服务协议，并按企业要求签定培养服务协议。", "广州泰迪智能科技有限公司", "50-150人", "初创型(未融资)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop工程师（北京）", "15000-30000", "不限", "北京", "不限", "职位描述岗位职责：1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；4.基于MapReduce、Spark、Flume等的大数据开发；5.学习和研究大数据技术最新动向以满足产品、项目的需求。要求：1.计算机相关专业本科及以上；2.软件基础理论知识扎实，具有良好的数据结构、算法功底；3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；6.对新技术敏感，有一定独立分析，技术研究能力；7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；8.有个人开源项目或参与开源项目者优先；9.有代码洁癖和自发组织Code Review的开发者优先。", "上海宏路数据技术股份有限公司", "50-150人", "初创型(未融资)", "移动互联网", "4.3"
"拉勾", "Hadoop", "大数据开发（Hadoop）开发工程师", "18000-30000", "本科", "北京", "3-5年", "职位描述【职位描述】主要工作方向：1、负责公司大数据处理平台工具研发，为公司提供公共大数据的相关服务2、提供业务关键数据指标及运维指标的离线or实时分析服务，为监控平台及自动化运维平台提供数据及决策支持3、深入研究并负责持续优化hadoop、hbase、storm、elasticsearch、spark等平台的服务运营，支持特殊需求的定制开发4、负责开发优化数据采集、传输、落地存储等服务。【职位要求】1、大学本科（统招）及以上学历，相关经验2年以上；2、对Hadoop、HBase、Hive、Scribe、Flume、Storm、kafka等开源工具中至少有1-2个有深入理解，并有一定经验3、至少2年的java开发经验4、具备对mysql、redis其中之一的开发经验5、学习能力强、具有良好逻辑分析能力、文档编写、语言表达能力，有强烈的责任心及团队合作精神。", "北京口袋时尚科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网 ,电子商务", "4.0"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "大专", "北京", "3-5年", "职位描述岗位职责：1、负责公司的大数据处理研发设计工作，开发基于hdfs/hbase/hive的数据查询分析。2、负责公司数据库设计文档的撰写，大规模日志分析、统计、建模。3、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、精通java或c语言，两年以上海量数据分布式系统的开发经验；2、拥有实际Hadoop生态圈项目经验，熟悉Linux平台；3、拥有软件开发流程中的代码、配置、文档撰写规范意识、配置管理规范意识；4、本科及以上学历；", "北京领智恒通科技有限公司", "50-150人", "成长型(A轮)", "数据服务,信息安全", "-"
"拉勾", "Hadoop", "Hadoop", "25000-35000", "本科", "北京", "3-5年", "职位描述Sr. Software Engineer for InfrastructureResponsibilitiesBe responsible for an application's features/components development.Self motivated and can deliver work on time with high quality.Give feedback and provide continuous optimization on the features/components in charge by working with technical lead.Lead junior members of the team, coordinating within and outside of the team to complete complex product feature or infrastructure development on time with high quality.RequirementsSolid programming skills and strong experience in programming languages Java, C++. Go is a plus.Self-motivated, strong problem solving skills and quick learning on emerging technology.Knowledge of Linux kernel, such as thread scheduling, memory management, disk cache, etc.Deep understand and hands-on experience in popular big data platforms such as Hadoop, HBase, and Hive, etc. Presto and Spark is a plus.Hands-on experience in message queue, distributed memory cache, RPC framework, and distributed synchronization, etc. is a plus.Fluent in oral and written English.", "飞维美地信息技术（北京）有限公司", "150-500人", "上市公司", "企业服务,数据服务", "4.1"
"拉勾", "Hadoop", "架构师（Hadoop）", "25000-50000", "大专", "上海", "10年以上", "职位描述职位名称：Java架构师工作地点：上海大连需要一个日语的系统架构师。The software architect role is responsible for the software architecture, which includes the key technical decisions that constrain the overall design and implementation for the project.·The software architect has overall responsibility for driving the major technical decisions, expressed as the software architecture. This typically includes identifying and documenting the architecturally significant aspects of the system, including requirements, design, implementation, and deployment ""views"" of the system.·The architect is also responsible for providing rationale for these decisions, balancing the concerns of the various stakeholders, driving down technical risks, and ensuring that decisions are effectively communicated, validated, and adhered to.Requirements:·Intensive knowledge on severalJava platform technologies,such as JNDI, DOM/SAX, Reflection, JSP,Taglib,EJB, Annotation, AOP, DI, REST, workflow,etc.·Familiar with one/severalcommon frameworks/tools, such as Structs, Spring,Hibernate, iBatis, JSF jQuery,jBPM, JIRA, JUnit, JMeter, Grinder, Selenium,etc.·Familiar with one/severalcommonapplication servers,such as Tomcat, JBoss, GlassFish,WebSphere, WebLogic, etc.·Well understandingon severaldesign patterns, such as Singleton, Builder, Adapter,Facade, etc.·Experiences and solutions on all/specificpart of web system application, such as user interface/components, input validation(single/cross),data transfer, business processes, transition control, exception handling, log management, interactive message, security handling, sync/async processes,performance, cloud computing,etc. ·Experienced in both the problem domain, through a thorough understanding of the requirements, and the software engineering domain. If there is a team, these qualities can be spread across the team members, but at least one software architect must provide the global vision for the project;· Leadership in order to drive the technical effort across the various teams, and to make critical decisions under pressure and make those decisions stick. To be effective, the software architect and the project manager must work closely together, with the software architect leading the technical issues and the project manager leading the administrative issues. The software architect must have the authority to make technical decisions.;· Self-motivated and quick learner, be passionate on technology, able to work under pressure and stressful environment.", "大连益佳会计事务所", "50-150人", "成长型(不需要融资)", "企业服务,其他", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "8000-10000", "硕士", "北京", "不限", "职位描述职位要求:1.计算机、软件工程或者相关专业本科及以上学历,硕士优先2.有大型电子商务或ERP系统开发经验或软件设计相关实习经验者优先3.Java语言基础扎实，熟悉J2EE规范. 熟悉JavaScript, ExtJS, JQuery, JSP, Servlet,Spring, Struts2和Hibernate/iBatis等开发技术或开源框架4.熟悉Oracle/SQL Server/MySQL等至少一种主流数据库5.熟悉Hadoop/Hbase/Hive等技术，并有相关的项目经验优先6.具有良好的英文读写能力和基本英语会话能力,CET-6及以上优先7.学习成绩优良,有社团经验者优先", "北京新聚思信息技术有限公司", "500-2000人", "上市公司", "电子商务", "4.8"
"拉勾", "Hadoop", "Hadoop中高级大数据开发", "15000-30000", "不限", "北京", "5-10年", "职位描述岗位职责：1、负责公司的大数据处理研发设计工作，开发基于hdfs/hbase/hive的数据查询分析。2、负责公司数据库设计文档的撰写，大规模日志分析、统计、建模。3、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、精通java或c语言，两年以上海量数据分布式系统的开发经验；2、拥有实际Hadoop生态圈项目经验，熟悉Linux平台；3、拥有软件开发流程中的代码、配置、文档撰写规范意识、配置管理规范意识；4、本科及以上学历；", "北京阳普科技有限责任公司", "50-150人", "初创型(天使轮)", "移动互联网,社交网络", "-"
"拉勾", "Hadoop", "Hadoop开发可电话面试", "18000-35000", "本科", "北京", "1-3年", "职位描述工作职责：1.负责hadoop平台上的数据处理；2.使用spark、mapreduce进行数据处理职位要求：1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce2.对数据结构、算法有深刻理解3.精通Java、Python4.熟悉linux开发环境5.熟悉hadoop、hbase、spark的源码的优先6.对新技术充满激情，认真负责、有良好的沟通和学习能力7.计算机或数学相关专业本科及以上学历", "车好多旧机动车经纪(北京)有限公司", "2000人以上", "成长型(A轮)", "O2O", "4.1"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-25000", "不限", "北京", "1-3年", "职位描述岗位职责：负责风控、财务、清结算相关的大数据平台的调研、架构、设计、研发。任职要求：1、全日制统招本科及以上学历；2、熟悉linux和Windows的开发环境；3、熟悉Hadoop/Spark生态系统组件（HBase、Hive、Pig、ZooKeeper、Mahout等）的使用；4、熟悉分布式平台（Hadoop/Spark）工作原理与系统开发；5、有Hadoop/Spark调优能力者优先；6、有统计学知识，有海量数据处理、数据分析和挖掘经验者优先；7、有风险控制、财会相关工作经验者优先；8、对新技术有孜孜不倦的热情，具有良好的学习能力、团队协作能力和沟通能力；9、责任心强，善于思考，能独立分析和解决问题。", "乐富支付有限公司", "500-2000人", "成熟型(不需要融资)", "金融,移动互联网", "3.9"
"拉勾", "Hadoop", "Hadoop", "8000-16000", "本科", "上海", "1-3年", "职位描述1）3年到5年开发经验（硬性）2）精通java开发，并且有数据库开发经验（硬性）3）有高并发开发经验（非硬性）4）有Redis，HBASE开发经验尤佳。（非硬性）5）本科以上学历（硬性）6）接受学习新技能，主动性强，抗压能力强，团队协作意识强，能适应一定程度的加班(硬性)", "北京京宝融信息科技有限公司", "150-500人", "成长型(不需要融资)", "招聘", "3.0"
"拉勾", "Hadoop", "Hadoop开发工程师", "2000-3000", "大专", "上海", "应届毕业生", "职位描述工作内容:1、OLAP和报表开发；2、ETL流程设计、开发；3、hive,hbase的开发。任职资格:教育背景:◆通信、电子工程、自动化、计算机及其相关专业，专科以上学历。经验:◆1年以上数据仓库开发工作经验。技能技巧:◆参与过数据仓库的ETL开发，对数据仓库的设计有一定认识；◆熟悉linux/UNIX shell、熟练python或java编程；◆熟悉分布式数据处理,具有haoop、hive、hbase等数据库开发经验；◆精通SQL语句；态度:◆好学上进，耐心细致，有责任心；◆工作勤奋，善于思考问题；◆有时间观念，独立性强，具有团队合作精神。", "上海银基富力信息技术有限公司", "15-50人", "初创型(未融资)", "其他", "-"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "大专", "北京", "3-5年", "职位描述大数据高级开发职位要求：1、本科及以上学历，计算机相关专业，3年以上软件设计开发相关工作经验；2、深刻理解并熟练运用软件设计原则和设计模式，独立承担过大中型系统开发工作；3、熟悉流计算/Hadoop/Spark/NoSQL子系统相关技术和实现方法，有大数据项目实践经验；4、熟悉Hadoop、Spark等大数据平台开源软件5、熟练掌握SQL，理解数据库基本原理和调优策略6、熟悉Mongodb，Redis等非关系型数据库和内存数据库优先地铁8号线 西小口站", "北京成鑫盈通科技有限公司", "150-500人", "成长型(不需要融资)", "企业服务,电子商务", "-"
"拉勾", "Hadoop", "大数据工程师Hadoop", "6000-8000", "大专", "成都", "1-3年", "职位描述岗位职责：1、负责大数据平台的搭建和维护2、负责大数据平台下的数据仓库建设相关工作3、基于Hadoop集群相关程序的开发、测试等任职要求：1、大专以上学历，有1年及以上Hadoop大数据开发经验2、熟悉Hadoop MapReduce、Spark、Hbase和Hive等的程序开发3、熟练掌握Hadoop、Spark、Hbase、Hive和Sqoop等分布式框架的部署和原理4、熟悉Linux环境，利用Eclipse开发工具搭建相关开发环境5、具备良好的编程习惯、需求分析和文档写作能力6、有金融行业从业经验者优先7、有Maven开发经验者优先", "深圳普惠快捷金融服务有限公司", "2000人以上", "成熟型(不需要融资)", "金融,其他", "-"
"拉勾", "Hadoop", "\u200bHadoop高级工程师", "20000-30000", "大专", "深圳", "5-10年", "职位描述Hadoop高级工程师岗位要求：1. 5 年以上 Java编程经验，2年以上 Hadoop 相关工作经验，熟练掌握Hdfs、 MapReduce、Hbase 、Hive的设计和开发技能；有实际大数据项目的成功经验。2. 熟练掌握Storm、Spark streaming等大数据实时处理框架的一种，具备实时处理框架的设计和开发能力；3. 熟悉R、SAS等数据挖掘建模流程4. 掌握常用的数据挖掘模型，包括分类、聚类、回归分析、文本分析等，并有具体的实现经验；5.熟悉Lucene、Solr、Elasticsearch等搜索引擎框架中的一种；6.熟悉Linux开发环境；熟练掌握Python、Shell、Perl中的一种；7. 良好的团队精神及沟通表达能力；8. 有较好的沟通理解和表达能力，性格乐观，工作踏实，积极上进。", "西艾（广州）软件开发有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,企业服务", "2.6"
"拉勾", "Hadoop", "数据架构师（Hadoop）", "17000-27000", "本科", "杭州", "5-10年", "职位描述岗位描述：1、负责数据仓库设计，数据ETL 的设计、开发与性能优化。2、负责数据产品的设计、数据模型设计和开发工作，开发用户行为分析系统、推荐系统，为业务提供智能化数据支持。3、负责分析各决策层和业务分析人员在应用数据过程中提出的需求并进行产品化设计。4、平台的设计和开发，负责hadoop、storm、spark、yarn 等云计算平台的开发和优化。5、推动数据基础架构和数据处理体系的升级和优化，不断提升系统的稳定性和效率，为项目提供大数据底层平台的支持和保证。6、完成领导交办的其他工作。岗位要求：1、5 年以上工作经验，科及以上学历, 熟悉分布式系统概念、架构，了解操作系统、文件系统的原理和实现；互联网行业从业者优先。2、熟悉Hadoop，Hive，Hbase，Spark，Storm 等一种以上大数据处理工具和技术，有实际大数据处理经验。3、熟练掌握Java 编程语言，并熟悉Shell，Python 等一门以上脚本语言，并灵活运用到实际工作中及解决技术问题。4、有推荐系统/自然语言分析/机器学习/用户行为分析项目工作经验者优先。5、熟悉大规模系统的负载均衡、缓存、网络存储、网络安全、数据库高可用设计及性能评估机制。6、逻辑思维能力强，对数据敏感，有较强的学习能力和创新思维。7、具备良好的沟通能力和文字表达能力，有较强的团队协作能力。", "惟锐（杭州）数字科技有限公司", "150-500人", "成长型(A轮)", "移动互联网,信息安全", "4.4"
"拉勾", "Hadoop", "hadoop数据开发工程师", "15000-30000", "本科", "北京", "1-3年", "职位描述【职位描述】1.基于Hadoop平台进行MapReduce开发；2.负责口袋购物Hadoop集群的开发、调优和运维；3.进行业务日志分析，给产品部分提供数据支持。【职位要求】1.对分布式计算原理有较深的理解，熟悉MapReduce编程2.熟悉Hadoop集群管理及优化、熟悉Pig/Hive/Sqoop开发及优化3. 熟悉Linux环境和svn，awk，vim等工具4. 熟悉Python、PHP脚本者优先考虑", "北京口袋时尚科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网 ,电子商务", "4.0"
"拉勾", "Hadoop", "数据研发工程师（Hadoop）", "8000-16000", "本科", "杭州", "3-5年", "职位描述岗位职责：1、负责数据中心集群的搭建、管理、开发以及调优工作。2、负责Hadoop/spark 集群的搭建、管理、开发以及调优工作。3、负责数据仓库建模、数据处理及报表生成逻辑的处理。4、负责大数据领域新技术、新方案的研究及评估。5、完成领导交办的其他工作。岗位要求：1、计算机、数学、统计或相关专业本科及以上学历，三年以上软件开发工作经验，数据挖掘和BI 分析领域优先。2、精通使用JAVA，熟悉常用的java 类库以及框架，如Velocity，Spring，Hibernate，iBatis，OSGI 等，对SOA 的模式有较深的理解，对虚拟机. 以及Linux下的开发环境有较深厚的开发经验。3、熟练使用Python/Shell/Perl/R 语言等其中一种语言优先。4、熟悉熟悉数据挖掘和分析技术。5、至少熟练使用SPSS、SAS、MatLab 或其他一款数据分析和挖掘工具。6、熟悉关系型数据库如Oracle、mysql 等，熟练掌握Hive/SQL，熟悉Hadoop、spark技术框架，可以使用/Map-Reduce/MPI 分布式计算框架编程，有海量数据处理经验者优先。", "惟锐（杭州）数字科技有限公司", "150-500人", "成长型(A轮)", "移动互联网,信息安全", "4.4"
"拉勾", "Hadoop", "Hadoop开发工程师", "7000-14000", "本科", "西安", "3-5年", "职位描述招聘Hadoop开发工程师 三名薪资：7-14K公司：华扬联众数字技术股份有限公司西安分公司集团规模：1000+，技术团队40+地址：西安市高新路50号南洋国际8层工作职责：1、根据需求和总体设计完成详细设计、编写功能设计文档。2、进行大数据处理技术的攻关和研发工作。岗位要求：1、大学本科以上学历，计算机相关专业；三年以上软件开发工作经验。2、具有扎实的计算机基础理论知识，了解Internet基本协议（如TCP/IP、HTTP等）。3、掌握Linux/Unix环境下的JAVA编程，熟练使用Shell/Perl/Python等脚本语言和工具。4、熟悉hadoop工作原理，具备Mapreduce、Pig、hive、Hbase开发经验。5、工作认真、负责，积极主动，强烈的上进心和求知欲，善于学习新事物。6、具有互联网产品研发经验者优先考虑。关于团队：华扬联众西安分公司是集团的技术研发中心，总部在北京；主要研发数字广告等相关的技术产品，产品用户覆盖至全国;多条产品线缺开发工程师；您关心的：双休;五险一金、年底双薪；每年一次调薪；年度旅游、各种节假日+圣诞节放假；十天带薪年假、七天带薪病假；结婚津贴、baby津贴、定时电影票等等；每月一次公司内部分享培训；", "华扬联众数字技术股份有限公司西安分公司", "2000人以上", "成熟型(不需要融资)", "数据服务,文化娱乐", "4.8"
"拉勾", "Hadoop", "hadoop开发工程师", "15000-25000", "大专", "北京", "3-5年", "职位描述【岗位职责】1.负责大数据平台的研发工作，平台主要涉及如下研发点： a.数据收集接入分发层 b.数据计算层（离线处理、实时流处理、实时交互处理） c.数据存储服务（DB集群、Nosql集群、文件存储） d.数据访问服务（统一透明的中间件访问服务）2.基于大数据平台，为公司业务提供分布式计算和存储解决方案并提供平台级服务【岗位要求】1.本科及以上学历，计算机相关专业，三年或以上相关工作经验2.具有良好的分析和解决问题能力，对攻关疑难问题具有浓厚兴趣3.良好的团队合作精神，沟通能力、学习能力4.具有丰富的Java开发经验，对Java I/O和多线程技术有深入研究5.熟悉Yarn,Hadoop,HBase,Spark,Storm,Flume,kafka等开源技术，至少精通其中一项6.掌握Shell或Python脚本7.有大数据平台建设经验者优先录用", "北京益商慧评网络科技有限公司", "500-2000人", "成长型(B轮)", "旅游,数据服务", "3.4"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "武汉", "3-5年", "职位描述1、文档的自动阅读，文本的自动提取2、大规模机器学习3、大数据数据库管理4、基于大数据的资讯推送、资产配置、风险控制岗位要求：1、熟悉Hadoop，mapreduce等相关技术，特别是熟悉SPARK。2、熟悉linux系统3、熟练掌握c/c++/java中的一种或多种4、懂得python和scala语言5、熟练掌握机器学习和数据挖掘的各种算法以及实现6、了解分布式处理的相关知识", "优品财富管理有限公司", "500-2000人", "初创型(未融资)", "金融", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "20000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责公司的大数据处理框架的研发设计工作；2、基于Hadoop、Hive/Pig、Hbase开发；3、负责Hadoop集群的开发、优化、维护；4、根据业务需要为数据仓库的实现提供支持。任职要求：1、熟练掌握Hadoop、Hive、Hbase等分布式计算框架；2、熟悉JAVA编程语言，熟悉面向对象和设计模式，熟悉Linux平台；3、深度掌握hadoop、hbase等分布式数据存储和分布式计算平台原理，具有相关系统的调优、运维、开发经验；4、具备责任心和良好的团队协作精神。", "数据堂（北京）科技股份有限公司", "150-500人", "成长型(B轮)", "数据服务,分类信息", "3.6"
"拉勾", "Hadoop", "数据挖掘hadoop", "15000-25000", "本科", "北京", "1-3年", "职位描述工作职责:1、负责Hadoop等数据平台开发建设2、负责大数据方向技术跟踪、研究3、参与个性化推荐系统的研发和改进任职资格：1、精通JAVA或者C/C++；2、了解Hadoop原理，对Hbase、MapReduce、Hive 等有深入理解，2年以上Hadoop经验；3、熟悉Linux操作系统，熟悉脚本编程(Shell/Python/Perl其中一种）；4、熟悉Storm、Spark等实时统计技术有相关实战经验者优先；5、有个性化推荐相关工作经验优先；", "百度移信网络技术（北京）有限公司", "2000人以上", "上市公司", "移动互联网", "4.2"
"拉勾", "Hadoop", "Hadoop工程师", "15000-20000", "本科", "上海", "3-5年", "职位描述岗位职责：- 负责实时日志、大数据系统架构的设计与实现- 通过持续探索前沿技术，推动业务的快速发展和高效迭代任职要求：- 2年以上开发经验- 熟练掌握Linux环境下的C/C++/PYTHON/Bash/Go/Java等至少1种语言- 熟悉主流的大数据产品（Hadoop、Spark、Flume等）和数据分析技术（机器学习)并具有相关项目经验- 具备强烈的求知欲，对攻克疑难问题有强烈的兴趣- 具备良好的全局观以及系统思维能力", "金华媒迪雅网络股份有限公司", "15-50人", "初创型(不需要融资)", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "20000-30000", "不限", "深圳", "5-10年", "职位描述岗位职责:1. 7年以上工作经验，其中4年以上hadoop开发经验 2. 具备一定的开发设计能力，精通Java语言， 熟悉shell、python或其他脚本语言中的一种； 3.熟练掌握hadoop的相关组件，尤其是Hbase、Mapreduce、Hdfs，以及SolrCloud； 4. 熟悉主流开源工具（mongodb，redis，elasticsearch，kafka等）功能和特性，有一个或多个工具开发及调优经验优先； 5. 熟悉Linux操作系统常用命令，对sed,grep,awk,vi等工具命令有了解，有shell脚本开发经验优先。 6. 具有较强的沟通协调、团队合作和抗压能力，学习能力强，有互联网行业经验优先。", "西艾（广州）软件开发有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,企业服务", "2.6"
"拉勾", "Hadoop", "Hadoop", "10000-18000", "大专", "深圳", "3-5年", "职位描述1、两年以上数据开发相关工作经验，一年实际hadoop开发经验，对Hive，sqoop开发语言熟练掌握；2、熟悉大数据平台后台脚本开发，熟悉oracle、mysql后台开发;3、熟练掌握Linux操作系统基本操作；4、.能够按照开发规范，标准、规范、严格地进行项目编码开发；5、 在按照需求完成编码开发工作的前提下，能通过大数据量压力测试；6、计算机相关专业，大专（含）以上学历；具备良好的学习能力；拥有良好的工作态度和职业道德，能承受较大的工作压力，能适应加班；表达沟通能力强，容易相处。", "亿达信息技术有限公司深圳分公司", "2000人以上", "上市公司", "移动互联网", "4.7"
"拉勾", "Hadoop", "Hadoop（大数据开发工程师）", "15000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责公司的大数据处理框架的研发设计工作；2、负责公司产品研发过程中的数据库设计文档的撰写；3、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；2、精通JAVA编程语言，精通面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；3、拥有实际的Hadoop的项目经验；4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。", "北京国双科技有限公司", "500-2000人", "上市公司", "数据服务", "4.0"
"拉勾", "Hadoop", "Hadoop大数据开发工程师（规则引擎 上海）", "10000-20000", "本科", "上海", "3-5年", "职位描述1、熟悉java的多线程、反射和序列化等;2、了解并使用过Solr、HDFS、Mapreduce、Hive、HBase、Zookeeper等大数据组件,熟悉其原理,并能够解决其中的问题,并对其进行优化;3、熟悉sql;4、熟悉Linux/Unix系统,了解python、shell等脚本语言;5、拥有研究新技术和解决问题的热情。6、有金融项目相关经验者优先，熟悉elasticsearch者优先，3年以上大数据开发经验者优先。一经录用，待遇从优", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "企业服务,金融", "3.8"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "北京", "3-5年", "职位描述任职要求精通Hivesql，有较丰富的Hivesql性能调优经验3年以上数据仓库开发经验，互联网/电商行业优先；了解数据仓库建设思路，有数据仓库建设项目经验；至少熟练使用Shell、Python、Perl等脚本语言之一；工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧岗位职责：负责京东流量数据模型设计与开发能够完成流量数据产品对应后台模型设计与开发对接京东业务部门进行流量数据需求分析及支撑", "北京京东尚科信息技术有限公司", "2000人以上", "上市公司", "电子商务", "4.1"
"拉勾", "Hadoop", "大数据开发工程师（hadoop方向）", "20000-30000", "大专", "深圳", "5-10年", "职位描述具有五年以上工作经验；具备一定的开发设计能力，精通Java语言， 熟悉shell、python或其他脚本语言中的一种；熟hadoop,hive,hbase,storm,lucene,elasticsearch,zookeeper,spark至少三个以上，有排错和调优经验优先；熟悉主流开源工具（mongodb，redis，elasticsearch，kafka等）功能和特性，有一个或多个工具开发及调优经验优先； 熟悉Linux操作系统常用命令，对sed,grep,awk,vi等工具命令有了解，有shell脚本开发经验优先。具有较强的沟通协调、团队合作和抗压能力，学习能力强，有互联网行业经验优先。", "日立咨询（中国）有限公司", "150-500人", "成长型(不需要融资)", "电子商务,企业服务", "1.8"
"拉勾", "Hadoop", "Hadoop（大数据工程师）", "20000-30000", "本科", "北京", "不限", "职位描述岗位职责：1、负责公司的大数据处理框架的研发设计工作；2、负责公司产品研发过程中的数据库设计文档的撰写；3、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；2、精通JAVA编程语言，精通面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；3、拥有实际的Hadoop的项目经验；4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。5、本科及以上学历", "百度在线网络技术（北京）有限公司", "2000人以上", "上市公司", "移动互联网,数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师H0038", "15000-30000", "本科", "北京", "3-5年", "职位描述【职位描述】1、 基于Hadoop平台进行MapReduce开发；2、 负责口袋购物Hadoop集群的开发、调优和运维；3、 进行业务日志分析，给产品部分提供数据支持。【职位要求】1、 对分布式计算原理有较深的理解，熟悉MapReduce编程2、 熟悉Hadoop集群管理及优化、熟悉Pig/Hive/Sqoop开发及优化3、 熟悉Linux环境和svn，awk，vim等工具4、 熟悉Python、PHP脚本者优先考虑", "北京口袋时尚科技有限公司", "500-2000人", "成熟型(C轮)", "移动互联网 ,电子商务", "4.0"
"拉勾", "Hadoop", "Hadoop高级开发工程师", "15000-25000", "本科", "北京", "1-3年", "职位描述岗位职责：1、负责公司的大数据处理框架的研发设计工作；2、基于Hadoop、Hive/Pig、Hbase开发；3、负责Hadoop集群的开发、优化、维护；4、根据业务需要为数据仓库的实现提供支持。任职要求：1、熟练掌握Hadoop、Hive、Hbase等分布式计算框架；2、熟悉JAVA编程语言，熟悉面向对象和设计模式，熟悉Linux平台；3、深度掌握hadoop、hbase等分布式数据存储和分布式计算平台原理，具有相关系统的调优、运维、开发经验；4、具备责任心和良好的团队协作精神。", "数据堂（北京）科技股份有限公司", "150-500人", "成长型(B轮)", "数据服务,分类信息", "3.6"
"拉勾", "Hadoop", "Hadoop初级工程师", "8000-16000", "本科", "北京", "1-3年", "职位描述工作职责：1、参与软件设计、编码开发、测试、文档编写等工作；2、具有一定沟通能力，能与客户进行需求方面的交流；3、搭建大数据相关系统开发环境，完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具程序代码的实现；4、完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具的基础运维工作，完成上述工具的常见故障排除和修复工作；职位要求：1、全国统招全日制高校计算机软件及相关专业本科学历及以上；2、一年以上大数据相关系统开发实际工作经验，具有大数据应用系统开发的经历；3、具备软件设计、编码开发测试、文档编写的能力；4、熟悉Hadoop、Hive、Hbase、Storm、Spark等技术框架中的两种以上;熟悉java、scala、sql等相关技术中的一种以上；5、熟练使用Hadoop、Hive、Hbase、Storm、Spark等技术中的两种以上进行大数据应用开发；6、了解主流应用服务器，熟悉主流Linux操作系统，精通shell；7、了解Linux系统运维，了解Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维；8、具备良好的自学能力，良好的英文文档阅读能力；9、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；10、责任心强，工作踏实，团队协作精神，能适应严格项目管理；11、能适应出差工作；12、具备良好的沟通能力；13、具备电信行业、互联网行业工作经验者优先考虑；", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop云计算开发工程师", "12000-18000", "本科", "珠海", "1-3年", "职位描述1、本科或研究生毕业，计算机，通信或相关专业，有2年以上的工作经验； 2、熟练Java程序开发和面向对象的编程思想，能使用eclipse开发工具进行项目开发； 3、在大数据方面有过2年以上的经验，熟练掌握Hadoop及相关的组件4、熟练掌握关系型、非关系型的数据库，熟练掌握并使用Oracle、SQLServe、Hbase、Hive等数据库。5、有较强的自学能力，对新技术能够很快上手并应用到项目中。6、有良好的沟通能力，工作细致，能承受工作压力，踏实肯干，富有团队精神", "北京航天数据股份有限公司", "150-500人", "成长型(不需要融资)", "信息安全,数据服务", "-"
"拉勾", "Hadoop", "Hadoop、Spark大数据工程师", "10000-20000", "本科", "深圳", "3-5年", "职位描述岗位职责： 1. 对大数据商机挖掘产品、智能招聘产品数据进行采集、处理、分析、展示等；2. 结合金蝶大数据业务，基于Spark实现分布式实时数据存储及挖掘算法；3. 关注大数据及互联网行业的技术发展趋势，评估和引进外部技术与解决方案，保持系统技术架构能够满足未来业务发展的需要。岗位要求：1. 年龄在35岁以下，拥有本科以上学位，计算机、应用数学相关专业；2. 三年以上大数据平台、数据仓库、算法挖掘、机器学习、推荐系统等相关从业经验；3. 熟悉关系型及NoSQL数据仓库和数据集市开发设计、ETL流程调度等；4. 熟悉Cassandra、HBase、MongoDB、Redis、ElasticSearch等主流数据库；5. 熟悉Hadoop及其生态圈相关组件，比如MapReduce、HDFS、Hive、Impala、Spark等。6. 熟悉Storm/Kafka等实时处理框架。素质要求：1. 较强的时间管理能力；2. 较强的沟通能力。优先条件：1. 在大数据相关开源社区有一定活跃度或影响力者优先；2. 有基于分布式计算技术（如Hadoop、Spark等）的大型企业级数据仓库的技术架构设计、数据架构设计成功经验者优先；3. 有用户画像、用户识别拉通等项目经验，有基于大数据的数据仓库分层分主题建模经验，有基于消费者用户行为数据挖掘经验尤佳。", "金蝶软件（中国）有限公司", "2000人以上", "上市公司", "移动互联网,电子商务", "4.1"
"拉勾", "Hadoop", "Hadoop（BI方向）", "13000-25000", "本科", "深圳", "3-5年", "职位描述1、了解Hadoop 2.0以上版本体系结构、各个模块的功能，对Hadoop生态圈有了解，具有源码级开发经验；2、2年以上hive编程经验3、较强的数据库及SQL能力，熟练使用MYSQL等开源数据库4、熟悉HDFS、MR、YARN、Spark、Storm、Hbase，SQOOP，Zookeeper、ETL中两种或两种以上开源软件，有实际项目开发经验。5、有上进心，较强沟通协调能力，良好的团队合作精神", "亿达新信息有限公司深圳分公司", "2000人以上", "上市公司", "移动互联网,招聘", "5.0"
"拉勾", "Hadoop", "Hadoop", "10000-16000", "不限", "深圳", "不限", "职位描述2年以上数据挖掘/数学建模工作经验，具有统计学理论基础，熟练使用HADOOP、SAS、Spark", "深圳市法本信息技术有限公司", "2000人以上", "上市公司", "企业服务", "3.8"
"拉勾", "Hadoop", "Hadoop运维工程师", "12000-24000", "本科", "上海", "1-3年", "职位描述岗位职责：1. 负责日常Hadoop系统的监控2. 负责整个Hadoop生态圈的产品研究和应用,如spark3. 负责基于S3(基于Riak-CS)系统的监控为运维,以及其他S3兼容性存储的研究4. 负责公司其他nosql数据库的运维和支持,如Mongodb任职要求：1. 有Hadoop运维经验,至少1年2. 熟悉Hadoop生产圈的产品和应用,并且有先关的coding经验,如hive,python3. 有python,shell等编程经验更佳4. 有主动学习能力,乐于沟通和分享.", "通联数据股份公司", "150-500人", "成长型(不需要融资)", "金融", "4.5"
"拉勾", "Hadoop", "Hadoop", "20000-40000", "本科", "北京", "5-10年", "职位描述岗位职责:1.互联网金融大数据平台、数据产品、数据服务开发。2.基于大数据的数据仓库架构设计和开发。3.指导和培训新人完成项目内的开发计划。任职资格:1、计算机相关专业本科及以上学历，五年以上JavaWeb应用软件开发经验；2、精通Servlet、Spring、Hibernate、iBatis开发，对虚拟机及Linux下的开发环境有较深厚的开发经验；3、熟练MySQL，对数据库有较强的设计能力，同时熟悉大数据相关技术；4、熟悉JavaScript、html、css等web前端常用开发技术；5、熟练使用git,熟悉Maven，熟悉Tomcat等应用服务器，熟悉高并发处下的性能优化；6、熟悉网络编程，具有设计和开发对外API接口经验和能力；7、具有良好的沟通，团队协作、计划和创新的能力8、读过开源代码并有体会者优先考虑；9、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Storm、Kafka、Flume等类框架技术，大数据产品开发、报表平台研发、数据仓库建设经验者优先。", "恒安嘉新（北京）科技有限公司", "150-500人", "成熟型(C轮)", "信息安全", "4.0"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "成都", "不限", "职位描述岗位职责：1、负责大数据相关技术研究，解决海量数据不断增长面临的挑战；2、负责海量数据的处理、分析、挖掘和存储；3、大数据挖掘计算平台集群管理、部署、优化、排错；4、大数据分析项目的软件开发、维护、架构设计，文档编写等工作；任职要求：1、计算机相关专业本科及以上学历；2、有扎实的Java语言基础，熟悉JVM运行机制和内存管理，熟悉Scala语言者为佳；3、熟悉Hadoop 2.0以上版本体系结构、各个模块的功能，对Hadoop生态圈有较全面了解，同时具有源码级开发经验；4、对Hive、HBase、Map/Reduce、Spark有深入了解，能熟练编写Map/Reduce程序和Spark程序；5、熟悉Hadoop运行监控及调优技术；6、具备机器学习算法理论基础，如分类、聚类、推荐、关联规则，具备相关项目经验为佳；7、有互联网公司或海量数据处理工作经验，数据分析和挖掘经验者优先。", "成都博云科技有限公司", "150-500人", "上市公司", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop开发工程师（高级）", "15000-30000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责公司的大数据处理框架的研发设计工作；2、负责公司产品研发过程中的数据库设计文档的撰写；3、参与小组的产品设计讨论，共同讨论和设计产品。任职要求：1、3年以上工作经验，熟悉Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；2、熟悉JAVA编程语言，熟悉面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；3、拥有实际的Hadoop的项目经验；4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。", "北京国双科技有限公司", "500-2000人", "上市公司", "数据服务", "4.0"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "上海", "1-3年", "职位描述大数据开发工程师工作经验：本科学历，2年以上的实际大数据项目开发工作经验者优先;岗位职责：1、HADOOP系统安装并监控、维护、优化2、HADOOP系统调度开发、维护3、配合上级领导交办的其他相关事项任职资格：1、使用Hadoop/spark、Hbase、Hive等进行大数据存储、处理和分析；2、搭建Hadoop运行环境，熟悉HADOOP的配置以及参数调优；3、具有独立解决hadoop问题的能力；4、熟练搭建和维护Hadoop、HBase等Hadoop生态系统组件可视化管理。5、热爱探索和钻研，参与过开源软件开发或者给某个开源项目提过BUG者优先6、有Shell、PHP、Python语言开发经验优先7、良好的团队协作及沟通能力。", "上海威志信息科技有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,电子商务", "1.0"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "大专", "上海", "3-5年", "职位描述职位：大数据/Hadoop讲师职位描述：1、能够在教学总监的指导下独立研发符合市场需求的课程体系2、按照课程体系、教学大纲高质量完成日常网络授课或线下授课3、积极参与部门内训，保持技术先进性，学习能力强，对新技术敏感且保持强烈兴趣4、配合教学总监完成相关的教学资料（实训大纲、教学PPT、教学用书、教学案例等）的研发工作任职要求：1.本科及以上学历，计算机相关专业。2. 3年以上开发经验，熟悉Hadoop/HBase/Amazon S3等大数据系统，有大数据平台或开发经验者优先。3.熟悉Linux操作系统，熟悉Java，熟练使用Shell/Perl/Python/Ruby中至少一种语言。4.具有较强的学习能力、逻辑分析能力、问题排查能力。5.具有较强的工作主动性，工作认真、负责、细致、敬业。6.有钻研新技术的热情和能力，善于交流和表达，富有团队精神，具有一定的管理组织能力。7.面对挫折时保持情绪的稳定，在比较艰苦的情况下或巨大的压力下坚持工作。8、有过培训课程授课经验（专兼职），能按要求自行制作课件者优先考虑。", "贵州宽待酒业有限公司", "150-500人", "初创型(天使轮)", "其他,招聘", "-"
"拉勾", "Hadoop", "Hadoop课程讲师", "20000-30000", "本科", "上海", "1-3年", "职位描述职责描述1、能够在教学总监的指导下独立研发符合市场需求的课程体系2、按照课程体系、教学大纲高质量完成日常网络授课或线下录课任务；3、积极参与部门内训，保持技术先进性，学习能力强，对新技术敏感且保持强烈兴趣4 、配合教学总监完成相关的教学资料（实训大纲、教学 PPT 、教学用书、教学案例等）的研发工作职位需求1. 本科及以上学历，计算机相关专业。2. 3年以上开发经验，熟悉Hadoop/HBase/Amazon S3等大数据系统，有大数据平台或开发经验者优先。3. 熟悉Linux操作系统，熟悉Java，熟练使用Shell/Perl/Python/Ruby中至少一种语言。4. 具有较强的学习能力、逻辑分析能力、问题排查能力。5. 具有较强的工作主动性，工作认真、负责、细致、敬业。6. 有钻研新技术的热情和能力，善于交流和表达，富有团队精神，具有一定的管理组织能力。7. 面对挫折时保持情绪的稳定，在比较艰苦的情况下或巨大的压力下坚持工作。8、有过培训课程授课经验（专兼职），能按要求自行制作课件者优先考虑。", "上海育创网络科技有限公司", "150-500人", "成长型(B轮)", "教育,数据服务", "4.0"
"拉勾", "Hadoop", "hadoop开发工程师", "12000-15000", "本科", "杭州", "1-3年", "职位描述研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等任职要求：1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳3、 熟悉mysql数据库，并具有一定的SQL功底；4、 熟悉python，scala等语言更佳。5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情", "浙江每日互动网络科技股份有限公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.3"
"拉勾", "Hadoop", "Hadoop（Spark）研发工程师", "6000-12000", "本科", "北京", "1-3年", "职位描述  1、负责Spark生态圈新兴技术的研究和探讨，具备将技术研究变成项目推动力的能力，指导项目进行技术应用   2、负责项目中Spark日常技术支持，解决项目中Spark的日常突发异常  3、负责项目中特殊业务场景Spark程序研发、Spark-sql应用程序研发、Spark-streaming流式处理程序研发、SparkR程序研发、Spark-MLLib程序研发   4、负责Scala、Spark-sql、JAVA、R等语言的在项目应用中的实施和应用   5、负责商业智能（BI）数据仓库的落地和实施  6、学历要求：一本，计算机及相关专业", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师（01）", "12000-15000", "本科", "杭州", "1-3年", "职位描述岗位职责：研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等任职要求：1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳3、 熟悉mysql数据库，并具有一定的SQL功底；4、 熟悉python，scala等语言更佳。5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情", "浙江每日互动网络科技股份有限公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.3"
"拉勾", "Hadoop", "大数据平台开发工程师（hadoop）", "15000-30000", "本科", "深圳", "3-5年", "职位描述1,精通Java开发，3年以上Java开发经验2,精通Eclipse开发环境，熟悉Oracle、Mysql等数据库；3,了解大数据处理及分布式管理前沿技术，至少2年的Hadoop实际开发经验或者分布式平台开发经验。4、熟悉linux系统，有shell/python等语言开发经验优先5，责任心强，工作主动高效；有良好的团队合作精神精神；对于技术有钻研精神。6，较强的英文阅读能力7. 有Hortonworks 或 Cloudera 认证优先", "深圳市彩讯科技有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,生活服务", "3.8"
"拉勾", "Hadoop", "Hadoop大数据计算平台高级运维工程师", "20000-40000", "本科", "北京", "3-5年", "职位描述工作职责1.负责公司大数据业务集群的运维工作（Hadoop/Hbase/Hive/Presto/Yarn/Spark等）确保高可用；2.负责集群容量规划、扩容及性能优化；3.设计实现大规模分布式集群的运维、监控和管理平台；4.参与/主导业务架构设计，在设计阶段给出可运维性改进建议；5.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。职位要求1.本科及以上学历，有3年以上大数据或数据仓库运维经验；2.熟悉Hadoop/Hbase/Hive/Zookeeper/Spark/Impala等开源项目，有patch源代码经验者优先；3.良好的客户服务意识，强烈的责任心和使命感，执行力强，富有团队合作精神；4.熟悉Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；5.能维护Hadoop源码，有Hadoop 源代码BUG修复或者源代码优化经验者优先", "百度外卖", "500-2000人", "成长型(B轮)", "O2O,生活服务", "4.1"
"拉勾", "Hadoop", "Hadoop", "13000-25000", "本科", "杭州", "3-5年", "职位描述岗位职责： 1. 负责大数据处理平台的架构和开发，并为各项目组提供大数据分析技术支撑； 2. 负责基于该平台的大数据业务的设计与开发;任职要求：1. 要求本科及以上学历，Java基础扎实，深入了解成熟Java开源框架，如spring,hibernate等；2. 具有很强数据库设计经验和SQL优化功底；3. 具备良好的面向对象编程经验，深入理解OO、AOP思想，具有很强的分析设计能力，熟悉常用设计模式；4. 具有Hadoop、HBase等相关项目实践，有独立系统的架构设计经验；具备海量数据处理经验优先", "浙江百世技术有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网,O2O", "4.3"
"拉勾", "Hadoop", "高级Hadoop集成工程师", "10000-15000", "本科", "北京", "3-5年", "职位描述岗位职责：1.负责大数据平台的搭建和研发工作；2.管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；3.负责HDFS/hive/HBase的功能、性能和开发，解决并实现业务需求；4.协助建立数据模型，利用脚本、语言等工具实现数据挖掘、优化及统计功能；5.负责数据的传递、清洗、转换和计算（实时统计、分析等）的设计和开发；6.理解系统的业务需求，制定系统的整体技术框架、业务框架和系统架构。 任职要求：1.熟悉linux操作,至少会一种脚本语言(如shell,python)，熟悉scala者优先考虑，2.熟悉hdfs/mapreduce/yarn/hive/flume/storm/hbase/Mahout/spark等分布式开源项目中的一种或多种，有相关开发经验，并能够独立安装部署系统，能独立分析解决集群的运行故障；3.熟练使用Java语言、熟悉JSP、Servlet、Hibernate、Spring、Ibatis等技术，熟悉MVC开发模式，有一定javaEE开发经验者优先；4.熟悉大数据相关开源项目，了解主流大数据开源技术，有流处理开发经验者优先考虑5.对大数据技术有钻研热情，具备高度的责任心及团结协作精神，善于沟通交流。6.可以短期出差；", "北京亚信数据有限公司", "2000人以上", "成熟型(D轮及以上)", "企业服务,数据服务", "4.2"
"拉勾", "Hadoop", "Hadoop", "15000-20000", "本科", "上海", "1-3年", "职位描述工作职责：1、负责Hadoop集群相关的开发、调优、监控等工作；2、负责Hbase、Spark项目开发、实施工作；3、负责数据平台的基础架构设计和优化工作。岗位要求:1.2年及以上大数据流程架构经验，熟练Hbase/Hive/Hadoop或等主流分布式开发平台；2.熟悉Linux/Unix平台上JAVA编程3.熟练掌握 HiveSQL/Mysql/SQL Server4.对sqoop、hbase，spark有一定了解;5.优秀的分析问题和解决问题的能力，善于学习新的知识，动手能力强，有进取心", "上海音达科技集团有限公司", "500-2000人", "初创型(未融资)", "移动互联网", "4.7"
"拉勾", "Hadoop", "Hadoop工程师", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位职责:1.负责数据平台及hadoop集群稳定性保障;2. 支持相关部门在数据应用上的各类技术问题;3. 负责集群的版本升级、系统优化、故障处理等工作。任职资格：1、熟悉Hadoop、Hbase、Hive，两年以上Hadoop开发经验；2、理解MapReduce计算框架的思想，熟悉分布式计算模型或有高效索引技术经验者优先；3、精通JAVA语言，熟悉J2EE相关技术；4、至少熟练使用Shell、Python、Perl等脚本语言之一；5、热爱技术，工作认真、严谨，有团队精神", "北京中关村融汇金融信息服务有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,金融", "4.8"
"拉勾", "Hadoop", "hadoop运维工程师", "15000-20000", "本科", "南京", "1-3年", "职位描述岗位职责：1 . 负责搭建大数据平台，能根据实际需求对平台进行优化配置，了解mapreduce,hive,hbase,spark等原理。2. 负责搭建hadoop定时任务管理平台方便研发创建mapreduce定时任务，并对任务进行监控报警3. 负责集群容量规划、扩容及性能优化，持续跟进集群的变化及新特性;4. 深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向5. 负责线上日志收集入hadoop任职资格：1. 有Hadoop生态系统的运维经验，了解Hadoop、Storm、Spark、Flume、Kafka这些组件的原理。熟练的进行运维操作2. 具备Java开发能力，对Hadoop源码有研究，具备部署、实施、维护hadoop 及相关组件的能力；3. 熟悉服务器监控、日志分析，熟悉运维自动化，熟悉集群和高可用技术并具备生产环境实施和维护管理的经验；4.强烈的主动性与工作责任心，对所负责工作有owner意识，并能自我驱动不断成长。", "南京途牛科技有限公司", "2000人以上", "上市公司", "电子商务,旅游", "3.9"
"拉勾", "Hadoop", "高级Hadoop大数据运维", "10000-20000", "本科", "上海", "5-10年", "职位描述薪资信息仅供发布职位，具体可以电话聊。职责管理大型Hadoop集群环境，处理所有Hadoop环境构造，包括设计，容量规划，集群建立，性能调优和后续监控为企业级系统软件包括容量模型评估并推荐系统软件和硬件致力于存储服务不断扩大的架构的可靠性，性能，易管理型和价格与 IT和开发团队中的核心支持人员合作完成自动化部署和基础设施的运维。用Puppet或其他自动化工具管理，部署和安装基础设施与IT运营团队合作改善产品容量：测试，kernel问题，兼容性和定制化软件新版本的部署识别硬件和软件的技术问题，存储或相关系统的故障创建利用率和性能的指标和措施规划和部署新的/升级的硬件和软件发布，还有存储基础设施 负责监控Linux社区和给团队汇报重要的变化/扩展能够与全球团队合作，互动和对话研究和推荐创新自动化管理系统任务的方法，识别资源利用的方法，简化远程/全球技术问题随时回应系统报警及其他相关工作要求5年的Linux 经验1年Hadoop（HDFS & MapReduce）相关经验深入理解Hadoop设计原理，集群连通性，安全和影响大规模系统性能的因素深刻理解自动化工具（Puppet, chef, ansible)熟练至少一种技术：Python，Perl，ruby或Bash有远程监控和用Nagios，ELK处理问题的经验能够用Chef, Puppet, Ansible or a shell创建自动化良好的合作和沟通能力，能跨团队合作优先录用条件擅长书面沟通和书写文档有安全，性能和灾难恢复的知识和最佳实践经验流利的英语沟通和书写文档的能力有复杂网络基础设施包括防火墙，VLANs和负载平衡器的经验AWS和Google计算经验优先考虑性能调优，容量规划和承受负载经验优先考虑有Google应用经验", "每锐软件(上海)有限公司", "500-2000人", "上市公司", "其他", "-"
"拉勾", "Hadoop", "Hadoop/Spark大数据平台实施工程师", "10000-20000", "本科", "北京", "1-3年", "职位描述工作职责：参与面向企业客户的大数据平台项目规划和实施负责在客户现场部署、调试、测试hadoop/spark等大数据平台软件解决现场实时过程中遇到的问题职位要求：1. 熟悉hadoop/yarn/spark/hive/storm/hbase/kafka/flume/scribe/es/ambari等大数据平台，能够进行日常运维与部署，能够独立处理基本问题，具有大规模运维部署经验优先。2. 熟悉RedHat/Centos Linux操作系统，具备shell，Python脚本能力，熟悉java，php优先。3. 具备项目管理能力，有较好的沟通能力，与研发和客户沟通，跟踪项目进度，保障项目交付质量与进度。4. 能够承担较大工作强度与压力，责任心强", "奇虎360科技有限公司", "50-150人", "上市公司", "移动互联网,游戏", "4.3"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "广州", "1-3年", "职位描述职位要求 参与大数据软件产品的需求分析、概要设计、编码、测试、部署上线等工作负责主要功能和核心代码的编写负责大数据项目的管理及监控 负责对现有大数据框架进行优化负责对大数据的周边项目进行对接整合基于大数据平台进行二次开发对关系型数据库和大数据平台进行数据迁移。职位职责 1~3年工作经验，有丰富项目开发经验，掌握java等主流编程语言。熟悉hadoop、Hbase工作原理，1年以上hadoop/Hbase实际项目经验，熟悉分布式计算实施过程中的各种问题；熟悉Zookeeper、Oozie、Storm、Redis等，有Hadoop运维经验者优先。熟悉Linux/Unix系统，至少熟悉perl/shell/python中的一种脚本语言具有较强的沟通能力，工作协作能力，学习能力，执行力，组织能力。计算机相关专业，熟悉电信行业业务，有BSS/OSS项目开发经验。工作态度积极主动，有一定的抗压能力,善于与他人合作，良好的团队合作意识 ，具备一定的协同管理能力。", "上海新炬网络技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "大专", "北京", "3-5年", "职位描述岗位职责1.负责各个产品线数据的整理和业务分析，建立相关的统计模型，对用户行为等数据进行精细化分析，挖掘潜在的价值；2.日志格式的设计，统计埋点的规划,开展埋点系统建设；3.BI数据仓库的建设和优化并解决，开展多维数据分析；4.负责数据处理ETL流程的优化；5.负责数据相关常用系统、工具的开发；任职条件1.有三年以上程序开发、数据开发等相关工作经验；2.良好的计算机编程基础，能熟练使用SQL、java、javascript优先；3.有数据仓库建模、ETL处理等相关经验；4.熟悉mysql等关系型数据库，了解hadoop、hive等大数据相关平台工具，了解MapReduce；5.有较强的问题解决能力以及学习能力，对技术保持热情.", "五矿电子商务有限公司", "150-500人", "成长型(不需要融资)", "移动互联网", "4.8"
"拉勾", "Hadoop", "高级Hadoop开发工程师", "20000-30000", "本科", "北京", "1-3年", "职位描述工作内容：保证HADOOP系统的稳定可靠运行；设计集群化监控提前预知可用性风险并自动发现风险点；不断调优存储方案，提升吞吐并降低成本；致力于先进、标准化，便利的工具的开发及优化；分布式计算系统，大数据和机器学习系统研发；将BI项目的模型算法应用于生产；职位要求：1. 大学本科以上学历，计算机或相关专业；2. 2年以上Java开发经验，深刻理解OOA/OOD/OOP编程思想,熟练掌握多种常用的设计模式3. 熟悉linux操作系统, 至少能使用bash python php任一种加分项：对大数据、机器学习、人工智能方向感兴趣对Hadoop、Spark 生态系统组件（MR、HBase、Hive、ZooKeeper、Spark SQL、Spark Mlib等）较为了解，有相关大数据架构经验敏锐的洞察系统性能瓶颈，并能对io、网络、任务调度中一个或多个方面的性能调优提供github id, apache JIRA id者优先", "乐元素游戏", "500-2000人", "成熟型(D轮及以上)", "游戏", "4.2"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "大专", "北京", "3-5年", "职位描述岗位职责：1. 协助建立和维护公司大数据存储及管理的技术基准，参与规划大数据平台硬件和软件结构；2. 负责协助编制、优化大数据平台管理、运维流程及规范；3. 独立负责某细分专业领域或研发流程环节的研究工作，独立解决常规性技术问题；4. 参与大规模数据的业务分析、采集处理、分布存储、应用、安全等解决方案的设计、开发与优化；5. 参与大数据平台的日常管理及运维；6. 负责相关大数据存储及应用技术的具体开发；7. 开展大数据存储及应用技术的应用培训和客户服务；8. 协同数据架构师进行大数据存储、安全及应用架构最新技术的跟踪调研、分析。任职要求：1.本科以上学历，计算机、电子、数学等相关专业；2.三年以上相关专业工作经验，2年以上大数据建设及应用相关职位工作经验；3.了解数据库相关理论知识，对关系型数据库、数据仓库、分布式数据库等有一定了解，具有一定的数据库设计及管理经验；4.熟悉与数据架构设计相关的数据存储、性能调优、负载均衡、容错、安全等相关知识，具有实际大数据存储和应用的设计及开发经验，能够解决项目过程中的技术难题；5.熟悉Hadoop分布式系统架构，了解分布式文件存储，了解Hive、HBASE、Zookeeper、Chukwa、Storm、Spark、Sqoop等原理且具有实际安装、配置、调优、管理及应用开发经验；6.熟悉至少一种主流数据库系统（如Oracle/Mysql/ PostgreSQL/MongoDB等）的安装、配置、调优、维护及管理，精通Sql语言；7.具有NoSQL、Key-Value 存储设计、开发及实施经验、数据分析及BI展示应用设计及实施经验优先；8.具有较强的学习能力、自我管理能力、较强的文档编写能力、抗压能力强；9.有互联网、电子商务或相近行业工作经验者优先。", "北京东润环能科技股份有限公司", "150-500人", "上市公司", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop高级工程师", "12000-24000", "本科", "北京", "3-5年", "职位描述工作职责：1、 参与大数据相关系统的需求调研和需求分析，撰写相关技术文档；2、项目概要设计、详细设计、开发计划等的编制并实施；3、具有一定沟通能力，能与客户进行需求方面的交流；4、搭建大数据相关系统开发环境，完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具程序代码的实现；5、完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维工作，完成上述工具的故障排除、修复工作；职位要求：1、全国统招全日制高校计算机软件及相关专业本科学历及以上；2、两年以上大数据相关系统开发实际工作经验，具有一定的系统架构设计能力，且至少参加3个以上中等开发项目的经历；3、具备系统建设期间需求调研、需求分析、技术文档编写的能力；具备系统概要设计、详细设计、开发计划等文档的编制能力；4、熟悉Hadoop、Hive、Hbase、Storm、Spark等技术框架;熟悉java、scala、sql等相关技术；5、熟练使用Hadoop、Hive、Hbase、Storm、Spark等进行大数据应用开发；6、熟悉主流应用服务器，熟悉主流Linux操作系统，精通shell；7、熟悉Linux系统运维，Hadoop、Hive、Hbase、Storm、Spark等大数据工具运维；8、具备良好的自学能力，良好的英文文档阅读能力；9、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；10、责任心强，工作踏实，团队协作精神，能适应严格项目管理；11、能适应短期出差工作；12、具备良好的沟通能力；13、具备电信行业、互联网行业工作经验者优先考虑；", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "12000-15000", "本科", "杭州", "1-3年", "职位描述岗位职责：研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等任职要求：1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳3、 熟悉mysql数据库，并具有一定的SQL功底；4、 熟悉python，scala等语言更佳。5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情", "浙江每日互动网络科技股份有限公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.3"
"拉勾", "Hadoop", "Hadoop/大数据开发", "6000-12000", "本科", "南宁", "1-3年", "职位描述工作地点：广西南宁岗位职责：1.负责搭建大数据平台，能根据实际需求对平台进行优化配置，了解mapreduce,hive,hbase,spark等原理。2.负责搭建hadoop定时任务管理平台方便研发创建mapreduce定时任务，并对任务进行监控报警3.负责集群容量规划、扩容及性能优化，持续跟进cldouera的变化及新特性;4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。任职资格：1.有Hadoop生态系统的运维经验，了解Hadoop、Storm、Spark、Flume、Kafka这些组件的原理。熟练的进行运维操作2.具备Java开发能力，对Hadoop源码有研究，具备部署、实施、维护hadoop 及相关组件的能力；3.熟悉服务器监控、日志分析，熟悉运维自动化，熟悉集群和高可用技术并具备生产环境实施和维护管理的经验；4.熟练使用CM界面进行运维监控和优化调整。5.了解impala、hbase、hive等运行原理。6.有团队合作精神，工作主动、责任心强，善于沟通。", "亿阳信通股份有限公司北京分公司", "2000人以上", "上市公司", "移动互联网,数据服务", "4.4"
"拉勾", "Hadoop", "Hadoop", "15000-30000", "本科", "北京", "1-3年", "职位描述岗位职责：                1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；4.基于MapReduce、Spark、Flume等的大数据开发；5.学习和研究大数据技术最新动向以满足产品、项目的需求。要求：1.计算机相关专业本科及以上；2.软件基础理论知识扎实，具有良好的数据结构、算法功底；3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；6.对新技术敏感，有一定独立分析，技术研究能力；7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具Git/SVN/Mercurial；", "上海宏路数据技术股份有限公司", "50-150人", "初创型(未融资)", "移动互联网", "4.3"
"拉勾", "Hadoop", "高级Hadoop开发工程师", "13000-26000", "本科", "北京", "3-5年", "职位描述任职要求： 1、全日制重点本科及以上学历，硕士两年以上的工作经验，本科三年以上相关经验。 2、熟练掌握JAVAWEB开发技术（HTML/CSS/JAVASCRIPT等），了解较前沿的WEB技术（如HTML5等） 3、对Hadoop（HDFS/YARN等）组件有一定的了解，对大数据技术有浓厚兴趣，有Hadoop使用经验者优先考虑 4、良好的沟通协作能力，能阅读一般的英文技术文章。  主要职责： 1、 基于Hadoop进行大数据平台开发与维护 2、 参与和用户的沟通、交流等工作。关于公司北京泰尔英福网络科技有限责任公司(简称泰尔英福或Teleinfo)是由中国信息通信研究院（工业和信息化部电信研究院）于2012年设立的全资控股公司。作为研究院在互联网领域的成果转化平台，泰尔英福致力于成为具备核心竞争力的新型互联网企业，目前开站的业务包括域名服务、基础网络安全服务和利用基础数据提供的数据分析发布服务。中国信息通信研究院为中国工业和信息化部直属科研事业单位，是中国在信息通信领域(ICT)最重要的支撑单位以及工业和信息化部综合政策领域主要依托单位。 愿景：领先的互联网关键服务提供商 使命：让互联网更可靠、更智能 价值观：诚信求是、开放创新我们提供 具有市场竞争力的薪酬水平 国企范儿的福利计划 初创团队的无极限工作空间特别补贴：  公司提供班车、免费用餐、车补/餐补、供暖补贴等", "北京泰尔英福网络科技有限责任公司", "15-50人", "初创型(不需要融资)", "移动互联网,企业服务", "4.4"
"拉勾", "Hadoop", "Hadoop", "10000-18000", "本科", "武汉", "3-5年", "职位描述岗位职责：1、负责指定功能模块的设计、开发与测试；2、负责Hadoop开发、测试和生产环境的搭建，维护hadoop集群并进行必要的troubleshooting，保障系统正常运行；任职资格的具体描述：1、计算机相关专业，本科及以上学历；2、两年以上开发经验2年以上Hadoop开发经验；3、熟悉分布式算法设计，熟悉数据挖掘和机器学习等技术，对海量数据的分析处理、挖掘和分布式存储有丰富经验；4、精通Hadoop各个模块功能及配置，对HDFS、HBASE、MR和Spark有深入了解；6、会mysql，oracle者优先，有集群数据库开发使用经验者优先，有互联网金融、P2P、电子商务等行业背景者优先；", "百纳（武汉）信息技术有限公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.7"
"拉勾", "Hadoop", "Hadoop（上海）", "17000-25000", "本科", "上海", "3-5年", "职位描述大数据研发工程师（senior）： 一名工作职责：1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；3、完成各种面向业务目标的数据分析模型的定义和应用开发；4、开发具有数据分析、数据挖掘能力的创新型产品；岗位要求：1、计算机相关专业，本科及以上学历，3~4年以上Hadoop相关开发经验；2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；4、熟悉Linux/Unix平台上的开发环境；5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；优先考虑：1、具有百度、腾讯、阿里等知名互联网公司经验者优先", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop", "12000-24000", "本科", "上海", "1-3年", "职位描述工作职责：1. 理解和分析业务需求，确定系统平台的技术架构设计和技术路线；  2. 带领团队完成各种面向业务目标的数据分析模型的定义和应用开发；3. 把握总体技术方向，对开发和技术选型及具体实施等问题进行指导和把关；4. 数据仓库基础平台（基于Hadoop）的规划和建设等技术工作。5. 解决数据平台和工程师工作中遇到的技术问题。6. 与数据/业务系统分析师紧密合作，能同时从业务和技术的角度对平台进行完善。任职要求：1. 计算机及相关专业本科及以上学历；2. 精通JAVA编程语言，熟悉面向对象和设计模式，熟悉Linux平台；3. 3年以上基于Hadoop的海量数据的ETL开发经验，熟悉主流的分布式开源大数据产品包括Hadoop、Hive、Tez、Hbase等并有企业级大数据平台设计或开发经验；4. 有自主开发基于hadoop企业级ETL平台经验；5. 较强的沟通能力及团队合作精神，对技术富有钻研精神，认真、踏实，责任心强。", "平安好房（上海）电子商务有限公司", "500-2000人", "上市公司", "电子商务", "4.2"
"拉勾", "Hadoop", "Hadoop工程师", "8000-12000", "本科", "北京", "1-3年", "职位描述岗位职责1、基于hadoop、hive等构建数据分析平台，进行数据平台架构设计、开发分布式计算业务；2、应用大数据、数据挖掘、分析建模等技术，对海量数据进行挖掘，发现其潜在的关联规则；3、撰写脚本实现大数据平台上的自动化数据分析；4、设计和开发与云计算、云存储、分布式数据库、大数据挖掘相关的前后端软件5、熟悉云计算、云存储、分布式数据库、数据挖掘平台的部署和优化任职资格1、计算机专业、数学、统计学本科及以上学历；2、具备深厚的统计学、数学、数据挖掘理论基础和相关项目经验，参与过完整的数据采集、整理、分析和建模工作；3、具有海量数据下机器学习和算法实施相关工作经验，熟悉hadoopyarn、map-reduce、hive等；4、具有linux平台下java/c++开发经验，熟练使用shell或python脚本语言；5、具有移动安全领域工作经验者优先；6、熟悉Scala语言，具有Spark内存计算研发经验者优先；7、吃苦耐劳，具备良好的抗压性、良好的学习能力和团队协作能力。", "北京东方金信科技有限公司", "50-150人", "成长型(A轮)", "金融,数据服务", "-"
"拉勾", "Hadoop", "Hadoop大数据开发工程师", "8000-16000", "不限", "武汉", "3-5年", "职位描述职位描述：1、结合公司大数据分析平台的规划，搭建以hadoop技术体系为核心的集群环境。2、结合业务的实际数据情况，设计、开发基于hdfs/hbase/hive的数据查询分析3、大规模数据分析、统计和建模。4、参与产品和项目需求分析，进行系统的功能定义，程序设计。5、负责编写各阶段的产品和项目的技术设计文档。任职要求：1、精通java语言，两年以上海量数据分布式系统的开发经验；2、熟悉hadoop框架，熟练应用map-reduce；3、熟悉Java、Shell，可以熟练使用Linux操作系统，了解Linux集群技术者优先；4、热爱技术，有创业激情，有良好的自我管理能力；5、具有较强的团队意识与良好的沟通能力，高度的责任感，对工作积极严谨，勇于承担压力，较强的学习能力以及快速解决问题的能力。", "湖北地信科技集团股份有限公司", "50-150人", "初创型(未融资)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop大数据工程师", "8000-16000", "本科", "广州", "1-3年", "职位描述岗位职责：1.深入研究Spark、Hadoop及其他大数据处理技术；2.执行大数据平台研发计划；3.处理现行产品平台中的问题。岗位要求：1.1年以上Spark、Hadoop项目相关工作经验；2.了解大数据生态环境中的多项技术：HDFS/ElasticSearch等；3.了解脚本编程(Shell / Python / Perl其中一种）；4.良好的文档习惯、标准化的代码编写习惯；5.良好的需求理解能力、测试习惯、学习和总结的能力。", "精诚瑞宝计算机系统有限公司", "2000人以上", "上市公司", "数据服务,信息安全", "4.8"
"拉勾", "Hadoop", "高级Hadoop开发工程师", "20000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责大数据平台架构规划与设计及核心功能开发2、负责互联网电视业务相关数据统计职位要求：1、4年以上大数据开发经验2、熟悉hadoop/spark生态系统各功能组件，有实际调优经验3、熟悉数据仓库设计理念，具备实践经验4、具备分布式通信/存储系统开发经验者优先", "北京优朋普乐科技有限公司", "500-2000人", "成长型(B轮)", "文化娱乐", "4.2"
"拉勾", "Hadoop", "Hadoop高级研发工程师", "15000-30000", "本科", "北京", "3-5年", "职位描述美团崇尚用数据说话，自上线起数据平台团队一直在不断完善公司级的统一数据平台。 数据平台基于Hadoop构建，目前每天执行近2万次计算流程，负责每天数百GB的数据存储、分析和实时计算，有2000多个业务指标，为十几个业务线、各层级的团队管理和产品运营，提供大量的数据决策支持。 随着美团以每年超过3倍的速度成长，数据规模带来的存储和计算压力，是我们面临的最大挑战。 现在我们开始组建负责 Hadoop 性能的技术专家团队，需要对 Hadoop/Hive 性能优化方面具有丰富经验的人才加入。这个团队负责设计和构建10倍于目前数据量的数据平台，提供稳定高效的大规模数据存储、计算接口，并确保在数据量快 速增长的同时，每天凌晨重要的数据计算任务按时高效的完成。  工作职责 1.HDFS/MapReduce/Hive/HBase的性能改进、功能扩展、故障分析； 2.不断解决规模增长带来的技术和业务问题，确保 Hadoop 数据平台每天上午8点完成重要数据的计算。任职资格:1.对技术有着永无止境的追求，自认为是技术Geek，具备很强的问题解决能力； 2.熟悉Hadoop、Hive、HBase、MySQL等开源项目，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解，有patch源代码经验者优先； 3.1年以上 Hadoop/Hive 生产环境工作经验； 4.有团队管理经验者优先。", "北京三快在线科技有限公司", "2000人以上", "成熟型(D轮及以上)", "移动互联网,O2O", "3.7"
"拉勾", "Hadoop", "hadoop工程师", "13000-25000", "大专", "上海", "3-5年", "职位描述岗位职责：1. 负责计算全国云仓库存分布，计算市内配送路线；2. 通过对现有数据的分析预测订单分布，分析生鲜订单市场喜好；3. 参与数据抽取、加载、转换和脚本开发；4. 负责BI展现的开发；5. 使用Hadoop, Hive等对海量日志进行统计分析任职要求：1、有大数据处理、数据分析、数据平台搭建等相关工作经验优先。2、掌握数学、统计学和计算机相关知识。3、掌握Excel，R，SAS等至少一种数据分析工具，具有良好的分析报告撰写能力。4、熟悉MongoDB, MySQL, Oracle等至少一种数据库及查询语言。5、熟悉脚本语言、数据建模或拥有海量数据处理和挖掘经验者优先。6、优秀的团队合作精神、诚实、勤奋、严谨，能够积极创新，乐于沟通，负责敬业。", "上海久耶供应链管理有限公司", "150-500人", "成长型(B轮)", "电子商务,数据服务", "3.7"
"拉勾", "Hadoop", "Hadoop", "15000-22000", "本科", "深圳", "3-5年", "职位描述岗位职责：1、进行大数据平台应用的需求评估、开发2、参与大数据平台应用开发规范的制定和完善3、预研新型的大数据平台技术1、应聘者简历内容2、重点关注应聘者过往经验中JAVA项目开发经历，SPARK使用情况、ES（luceue）/kafka的了解及使用情况、git/maven等工具的了解及使用情况。岗位要求:1、本科以上学历，211或985院校优先；2、具有2年以上JAVA相关工作经验，面向对象编程，其中1年以上的hadoop平台项目开发经验；3、以下条件符合其一：\uf081熟悉 hadoop/spark 生态组件及工作原理，熟练掌握JAVA语言，shell或python脚本；\uf082了解Hadoop、spark基本原理，熟练掌握 HIVE、spark-sql 的开发调优技能，熟悉数据库相关知识，熟练掌握SQL、shell脚本4、熟悉git、maven等项目协同管理工具；5、有强烈的责任心和事业心，积极乐观认真细致，团队协作意识强，具有亲和力并能够承受一定的工作压力、富有工作激情；", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "金融", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "本科", "北京", "1-3年", "职位描述工作职责：1.负责与局方沟通需求，分配开发人员，带领开发人员进行程序开发；2.负责程序关键代码编写工作；2.负责ETL数据处理过程的设计；3.负责shell脚本架构设计；4.负责Hive-sql,spark-sql,hbase，sqoop等的数据模型设计工作。职位要求：1、计算机或应用数据相关专业或参加过计算机社会培训；2、有管理经验或带队经验，具备良好的沟通能力；3、精通至少一种关系型数据库开发或NOSQL开发，并使用过内存数据库；4、熟练JAVA或python开发语言的一种，可以设计程序架构；5、熟练在linux上配置Nginx、lua和shell的设计和开发；6、具备快速学习能力，思路清晰，善于思考；7、工作严谨细致、责任心强；勤奋踏实，善于思考问题；有良好的团队合作观念；8、具备linux上lua语言开发经验、LOGSTASH、KIBANA4、ZOOKEEPER、CODIS、rabbitmq使用经验优先；9、有电信行业经验者优先；", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "12000-15000", "本科", "杭州", "1-3年", "职位描述主要职责：研究并开发基于Hadoop, hive, hbase, spark的海量（TB级）数据处理分析程序，使用java，python等开发数据服务接口等任职要求：1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉***2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究***3、 熟悉mysql数据库，并具有一定的SQL功底；4、 熟悉python，scala等语言更佳。5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情", "浙江每日互动网络科技股份有限公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.3"
"拉勾", "Hadoop", "Hadoop（北京）", "14000-26000", "本科", "北京", "1-3年", "职位描述大数据研发工程师（senior）：工作职责：1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；3、完成各种面向业务目标的数据分析模型的定义和应用开发；4、开发具有数据分析、数据挖掘能力的创新型产品；岗位要求：1、计算机相关专业，本科及以上学历，3~4年以上Hadoop相关开发经验；2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；4、熟悉Linux/Unix平台上的开发环境；5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；优先考虑：1、具有百度、腾讯、阿里等知名互联网公司经验者优先", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop架构师", "15000-30000", "本科", "上海", "3-5年", "职位描述职位描述：1. 理解和分析业务需求，确定系统平台的技术架构设计和技术路线；2. 带领团队完成各种面向业务目标的数据分析模型的定义和应用开发；3. 把握总体技术方向，对开发和技术选型及具体实施等问题进行指导和把关； 4. 数据仓库基础平台（基于Hadoop）的规划和建设等技术工作。5. 解决数据平台和工程师工作中遇到的技术问题。6. 与数据/业务系统分析师紧密合作，能同时从业务和技术的角度对平台进行完善。职位要求：1. 计算机及相关专业本科及以上学历；2. 精通Java、Python、Scala等语言；3. 5年以上针对海量数据的ETL开发经验，熟悉主流的分布式开源大数据产品包括Hadoop、Hive、Tez、Hbase、Storm、Spark等并有企业级大数据平台设计或开发经验；4. 有构建基于Hadoop的ETL管理调度平台5. 具有大规模的集群开发和管理能力，支持海量数据的秒级别的查询架构设计；6. 较强的沟通能力及团队合作精神，对技术富有钻研精神，认真、踏实，责任心强。", "平安好房（上海）电子商务有限公司", "500-2000人", "上市公司", "电子商务", "4.2"
"拉勾", "Hadoop", "Hadoop工程师", "30000-50000", "本科", "北京", "3-5年", "职位描述岗位职责：1.负责数据平台的架构分析和设计，发现和解决存在的技术问题；2.主持和参与系统逻辑模型和物理模型设计并实现原型；3.全面把握总体设计和重要技术决策，具体的设计和开发工作，以及关键技术的攻关。任职要求：1.计算机相关专业本科或以上学历，3年以上分布式系统或者应用系统架构分析、设计、数据挖掘经验。在高性能开发或调优方面有实际经验；2.具备良好的识别和设计通用框架及模块的能力；3.具备优秀的数据挖掘、数据策略优化经验4.具有高度的抽象设计能力，思路清晰，善于思考，能独立分析和解决问题，责任心强，有良好的沟通能力，能协调多方资源完成共同目标。 激情、愿意分享，自我驱动能力强，良好的结果导向和抗压能力；5.必须在以下技术领域有一项或多项经验：A: 大型分布式系统，高并发，高可用性系统；B: 分布式存储经验；C: 高性能缓存；D: 大规模机器学习或者数据挖掘经验", "北京因果树网络科技有限公司", "50-150人", "成长型(B轮)", "金融", "3.2"
"拉勾", "Hadoop", "hadoop数据工程师（超级手机方向）", "15000-25000", "本科", "北京", "3-5年", "职位描述岗位职责：1.参与超级手机运营方案制定，推动相关技术实现 —— 定义指标、埋点、进行BI 分析 、 以及报表展示等。2.对超级手机运营各相关活动进行数据保障  —— 定义受众，过程检测，结果评估等。岗位要求：重点大学毕业（211）1、2年以上从事BI分析工作，一年以上hadoop使用经验；2、数据相关领域专业毕业，具有数学和统计背景优先（建模，统计，分析，数学）3、对数据仓库、数据挖掘等知识体系有一定认识优先；4、熟悉大数据基础架构，能熟练使用hadoop,hive，spark等系统优先5、熟悉Hadoop，Map/Reduce，spark工作机制，掌握R，Python等数据分析技术优先6、熟悉可视化技术，如python's pandas numpy SciPy matplotlib 等分析和可视化工具优先", "乐视网信息技术（北京）股份有限公司", "2000人以上", "上市公司", "移动互联网", "4.0"
"拉勾", "Hadoop", "Hadoop工程师", "15000-25000", "本科", "上海", "3-5年", "职位描述岗位职责：1、大规模Hadoop集群部署、管理和日常运维；2、基于Hadoop各种开发工具和框架实施数据采集、分析和报表；3、Hadoop集群的数据接口开发。任职要求：1、基础扎实，熟悉数据结构和算法；2、熟悉Linux操作系统3、熟悉Java、Python、Scala、Shell语言，较强的独立开发能力，具备良好的代码风格；4、具备3年以上Java开发经验以及1年以上hadoop开发经验。5、有独立分析和解决问题的能力；6、有较强的学习能力，能够迅速掌握新技能；7、能够承担一定工作压力，具备创新思维、具备团队协作精神。公司福利：薪资+年度奖+绩效奖金+差旅补贴+5险一金+年度旅游+定期的team building+丰富的员工关怀+生日关怀+带薪休假+带薪病假+年度健康体检", "上海派拉软件股份有限公司", "50-150人", "上市公司", "数据服务", "4.4"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "北京", "3-5年", "职位描述岗位描述：  参与基于hadoop的数据计算平台建设，支持精准广告投放所需的大规模数据计算需求  大数据应用相关解决方案的设计，以及相关软件应用技术疑难问题的研究工作工作地点：北京岗位要求  计算机相关专业，本科及以上学历，3年以上Hadoop相关开发/维护经验：  熟悉Hadoop/HBase/Spark相关系统的搭建和管理，掌握原理和使用方法  善于发现系统的性能瓶颈、设计缺陷，提出改进方案并进行实施；  思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；", "悠易互通（北京）广告有限公司", "150-500人", "成熟型(C轮)", "广告营销", "4.3"
"拉勾", "Hadoop", "数据分析工程师（Hadoop、HIVE）", "9000-11000", "本科", "深圳", "1-3年", "职位描述岗位职责：互联网业务的数据报表开发及维护、数据分析岗位要求：负责互联网产品的运营数据分析体系搭建和维护；岗位要求:本科及以上学历；熟悉Oracle、MySQL等数据库；熟悉至少一种脚本语言，能独立完成相关的数据处理工作；良好的沟通交流、团队合作精神及项目管理能力；具备hadoop+hive使用经验者，具备海量数据经验者优先。", "北京通力互联技术服务有限公司", "2000人以上", "成熟型(不需要融资)", "电子商务,企业服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "成都", "3-5年", "职位描述统考本科毕业有银行大数据开发项目经验优先3. 熟悉操作hadoop,hive等", "上海华腾软件系统有限公司", "2000人以上", "上市公司", "金融", "3.9"
"拉勾", "Hadoop", "高级hadoop工程师", "15000-30000", "大专", "珠海", "3-5年", "职位描述岗位职责：1. 参与数据基础平台部署、维护、优化2. 海量数据处理平台的规划，选型，设计与开发任职要求：3. 有大中型Hadoop项 目设计开发经验4. 有大中型企业级应用的设计开发经验；5. 熟 悉Hadoop开 源项目，有Hadoop应 用开发的经验6. 熟悉HDFS、Yarn,Zookeeper技术7. 熟悉MapReduce,Hive, Pig等分布式计算技术8. 熟悉HBase, HCatalog, HQL, Flume, sqoop等 技术9. 熟悉 Java 编写语言10. 熟悉Oracle或MySQL数据库11. 熟悉 Spark, Storm, solr, Ambari等技术优先12. 个人思维严谨，有钻研精神，良好的团队协作和沟通能力。13. 大专以及以上学历，数学或计算机相关专业", "珠海杨氏科技有限公司", "15-50人", "初创型(未融资)", "企业服务", "5.0"
"拉勾", "Hadoop", "Hadoop", "15000-20000", "本科", "上海", "3-5年", "职位描述岗位职责：1、参与基于hadoop(CDH5)大数据系统平台核心模块设计、开发；2、参与海量数据处理，业务数据体系的数据统计、分析及数据建模；3、对有助于提升集群处理能力、高可用性、高扩展性的各种解决方案进行跟踪和落实；4、负责数据仓库的ETL项目，进行项目需求和设计分析，制定测试计划，制定测试方案；岗位要求：1、具备2年以上数据平台建设经验，了解数据平台建设过程中的挑战与问题，有系统化解决问题的成功案例，有海量数据建模实践经验优先；2、具备大数据处理Hadoop/MapReduce及Hive、Spark、Hbase等实际项目经验；3、对数据敏感、对新技术敏感，有一定技术研究能力4、熟练掌握java/shell/python编程语言，了解常用代码版本控制工具的使用；5、良好的SQL语句功底，熟练使用主流SQL/NOSQL数据库；", "上海卓易科技股份有限公司", "500-2000人", "上市公司", "移动互联网", "4.0"
"拉勾", "Hadoop", "Hadoop开发", "15000-30000", "本科", "上海", "3-5年", "职位描述岗位职责： 1、负责分布式数据平台建设、数据应用开发 2、分布式平台应用开发（Hadoop/Hive/Spark/ElasticSearch） 3、开发数据统计及挖掘系统，各类统计及挖掘程序的开发 4、系统的性能分析与系统优化岗位要求： 1、良好的编程开发能力，精通Java开发语言 2、精通Hadoop2.0框架，熟悉分布式系统部署、开发、测试、维护过程与方法 3、Hive、ZooKeeper、Hbase、Spark、ElasticSearch、kafka、flume等分布式开源软件实际开发和应用经验者优先 4、熟练掌握Linux常规命令与工具，熟悉shell脚本语言 5、熟悉数据分析和数据挖掘等技术，具备对常用挖掘算法的使用能力者优先 6、对新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神", "数数信息科技（上海）有限公司", "15-50人", "成长型(A轮)", "游戏,数据服务", "3.6"
"拉勾", "Hadoop", "Hadoop/spark开发工程师", "20000-30000", "本科", "南京", "1-3年", "职位描述岗位职责:1. 负责日志数据的清洗、分析工作以及入库工作;2. 负责Hadoop集群日常维护；3. 负责MapReduce程序的开发，Hive脚本的编写；任职资格:1、计算机相关专业本科学历； 2、熟练掌握HADOOP平台hive、HBASE开发技能3、熟悉任何一种开发语言(java、python、c++等均可)4、有大数据开发处理经验者优先。", "南京航空航天大学", "2000人以上", "成熟型(不需要融资)", "移动互联网,O2O", "5.0"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "大专", "北京", "3-5年", "职位描述岗位职责：负责银行大数据（积分系统）开发任职要求：1.专科以上学历2.3年及以上工作经验，其中有超过2年的大数据相关工作经验。3.对于hadoop，HIVE，MR等大数据常用技术掌握熟练。4.有过中信管理信息类系统工作经验者优先。5.了解中兴大数据平台者优先。", "北京宇信科技集团股份有限公司", "2000人以上", "初创型(未融资)", "金融", "3.3"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "本科", "北京", "3-5年", "职位描述工作职责：1、负责大数据平台的建设；2、负责大数据平台应用开发。职位要求：1、计算机及相关专业本科以上，3~4年Java开发经验；2、熟练使用spring，mybatis框架，并了解框架原理；3、了解或使用过常用设计模式，熟悉多线程编程；4、熟悉HTTP，WEB 服务，Socket等技术，有编程经验；5、具备强烈的进取心、学习能力及团队合作精神；6、有Hadoop、Storm、Spark大数据应用开发者优先。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "15000-21000", "本科", "北京", "1-3年", "职位描述工作职责：1、负责大数据应用现场定制方案的设计与实施；2、负责基于HIVE平台的数据治理和报表加工；3、根据需要在客户现场长期办公岗位要求：1、计算机相关专业，本科及以上学历，2、如果有Hadoop相关测试或者部署、运维经验最好，3、熟悉Linux/Unix平台上的开发环境；4、踏实努力，认真负责，做事仔细", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "hadoop开发工程师", "15000-25000", "本科", "北京", "1-3年", "职位描述工作职责：1. 基于mysql业务数据及海量日志数据，实现业务关键指标的统计功能。2. 深度分析用户的人口统计学信息和行为规律，并做产品化研究和开发,如推荐引擎。3. 参与海量数据业务的架构设计和大数据平台集群开发4. 保障和提升海量数据运营系统的性能和稳定性职位要求：1. 2以上大数据开发工作经验，拥有TB以上级别数据处理分析经验。2. 至少精通以下主流语言中的1门：Java/Python/Go/Scala等3. 精通hadoop/yarn/zookeeper/kafka/hive/flume/storm/pig/spark等大数据生态圈任意一个开源项目，有源码经验优先考虑。4. 至少精通以下主流分布式存储系统中的1种:\u3000redis/cassandra/mongodb/hbase5. 掌握多线程及高性能的设计与编码及性能调优, 掌握 JVM 性能优化。6. 关注大数据生态圈和活跃开源论坛社区，有开源代码贡献者优先考虑。", "乐视网信息技术（北京）股份有限公司", "2000人以上", "上市公司", "移动互联网", "4.0"
"拉勾", "Hadoop", "hadoop实习生", "4000-5000", "硕士", "北京", "不限", "职位描述职位职责：1.参与DMP和内容生成平台的开发工作2.大数据分布式系统的算法实现和算法优化职位要求：1.熟练掌握Java,Scala,Python,R其中至少一种语言；2.熟练掌握机器学习算法，包括：逻辑回归，KMeans，支持向量机等常用算法或精通Hadoop和Spark，有分布式平台上机器学习算法实施经验优先考虑；3.良好的编程功底，有一定算法基础；计算机相关专业在读硕士生，能持续实习至少半年时间。", "三人行广告有限公司北京分公司", "150-500人", "成长型(不需要融资)", "企业服务,广告营销", "4.5"
"拉勾", "Hadoop", "Hadoop-基础平台架构师", "50000-100000", "本科", "北京", "10年以上", "职位描述1，有超大规模集群全流程建设经验，并且对集群运营调优有丰富经验2，精通业界流行的分布式存储系统，和各种计算框架3，对网络拓扑，操作系统内核有深入了解4，在业界有成熟产品者优先 ", "京东－大数据部", "2000人以上", "上市公司", "电子商务,数据服务", "4.1"
"拉勾", "Hadoop", "大数据平台高级运维工程师（Spark/Hadoop/Storm/HDFS等）", "15000-30000", "不限", "北京", "不限", "职位描述奇虎360公司IT架构架构中心系统部直招职责：1. 负责几万台服务器规模的大数据平台Hadoop/HBase/Spark/Storm等运维及优化工作2. 研究业界最新的大数据技术，负责大数据运维工具、系统的设计与开发3. 支撑360安全、搜索、广告、推荐、智能硬件等大数据业务要求：1. 熟悉Linux操作系统，熟练使用各种常用命令2. 良好的Shell/Perl/Python/PHP至少一种脚本编程能力3. 有Hadoop/HBase/Spark/Storm等大数据平台运维经验优先4. 良好的团队合作及沟通能力，较强的责任心", "奇虎360科技有限公司", "50-150人", "上市公司", "移动互联网,游戏", "4.3"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "本科", "杭州", "1-3年", "职位描述•搭建和部署hadoop集群；•利用大数据平台实现对数据的分析和处理；•负责大数据平台的性能参数调整和优化；•良好的数据敏感度，能从海量数据提炼核心结果•使用Hadoop进行MapReduce或Storm等开发•根据业务需求，编制各类分析图表、撰写项目分析文档和分析报告•进行技术设计和项目实施", "杭州信雅达数码科技有限公司", "150-500人", "上市公司", "金融,移动互联网", "5.0"
"拉勾", "Hadoop", "Hadoop 工程师", "10000-20000", "本科", "深圳", "3-5年", "职位描述岗位描述：根据集团数据业务需求，建设百丽集团数据中心。对Hadoop生态技术进行扩展和定制开发，跟进社区动向。基于HDFS和HBase构建统一存储平台，同时支持NoSQL、SQL、消息队列等多种存储模型。对接物流、零售、会员等上游系统，实现数据集成，产出全量、增量和实时数据。基于YARN、Spark构建统一计算平台，同时支持批处理、流式处理、迭代处理等多种计算模型。岗位要求：1、本科以上学历，3年以上工作经验；2、精通Java及Shell/Python/Scala等任一一种脚本语言；3、熟悉Linux/Unix系统，有丰富的Linux/Unix平台后台开发经验；4、熟悉常见网络通讯协议，精通相关IO机制；5、熟悉大数据量的分布式处理、分布式实时计算和分布式存储模型；6、熟悉Hadoop体系结构、对Hadoop生态系统有较全面了解，同时具有相关开发能力；7、熟悉Hadoop/HDFS/HBase/Hive/YARN/Spark/MapReduce/Pig/Impala/Storm等开源相关技术；8、熟悉MySQL、NoSQL（Redis, Mongodb, HBase）、Oracle及有集群数据库开发经验者优先；9、有电商、零售、物流、移动应用背景者优先，有数据中心/数据仓库其它相关(如ETL、运维、算法)经验者，也欢迎直接投递简历", "云盛海宏信息技术（深圳）有限公司", "150-500人", "成长型(不需要融资)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "南京", "1-3年", "职位描述1、计算机相关专业大专或以上学历。1年以上DELPHI软件开发经验；2、熟练掌握DELPHI；3、熟悉Oracle数据库，熟练Oracle PL/SQL操作，能够编写SQL语句、视图等；4、具有良好的沟通能力和团队协助精神，学习能力强，对工作充满热情，责任心强，能够承受工作压力；5、熟悉教育行业或有相关开发经验者优先；6、一经录用，待遇从优。", "北京科瑞哲数据系统有限公司", "50-150人", "成长型(不需要融资)", "数据服务", "5.0"
"拉勾", "Hadoop", "大数据平台工程师 hadoop", "18000-25000", "本科", "深圳", "5-10年", "职位描述职位说明：1.负责搭建大数据平台，能根据实际需求对平台进行优化配置，保障各核心服务运行的稳定、通过技术优化提升数据产品的质量和响应速度；2.开发各种Hadoop&HBase大数据自动化运维与监控工具,建设基于大数据的运维监控体系;3.负责集群容量规划、扩容及性能优化，持续跟进hadoop的变化及新特性;4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向任职要求1.三年以上系统运维或大数据运维工作经验，有大型互联网公司工作经验者优先；2.有Hadoop生态系统的运维经验，了解Hadoop、Storm、Spark、Flume、Kafka这些组件的原理，能部署并进行性能调优；2.具备Java开发能力，对Hadoop源码有研究，具备部署、实施、维护hadoop 及相关组件的能力；3.熟悉nagios、cacti、ganglia、zabbix、zenoss优先；熟悉服务器监控、日志分析，熟悉运维自动化，熟悉集群和高可用技术并具备生产环境实施和维护管理的经验；4.具有良好的学习能力、沟通能力、客户服务意识和团队合作精神；具有强烈的进取精神和乐观的工作态度。", "TCL移动通信有限公司", "2000人以上", "上市公司", "移动互联网 ,硬件", "4.2"
"拉勾", "Hadoop", "Hadoop", "20000-25000", "本科", "北京", "3-5年", "职位描述岗位名称：Hadoop高级工程师（数据处理）岗位职责:1.负责大数据平台的开发、维护工作；2.负责各业务线日志采集、清洗、整合等工作；3.负责大数据平台数据分析、用户行为分析等相关工作。任职资格:1.本科及以上学历，计算机相关专业；2.有1－3年大数据或数据仓库项目经验，了解数据仓库相关理论知识；3.熟练掌握Hadoop及Map-Reduce应用开发，精通HBase、Hive、Spark等大数据开发工具者优先；4.精通SQL开发，精通Mysql、Oracle等关系型数据库中的一种；5.精通java开发；6.拥有memcache、redis、ehcache等cache开发经验，理解其原理和工作模式；7.熟悉Linux系统，具备shell、perl等脚本开发能力；8.熟悉nginx、resin者优先；9.学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力。", "深圳市普兰软件有限公司", "50-150人", "成长型(A轮)", "数据服务", "1.0"
"拉勾", "Hadoop", "Hadoop", "6000-12000", "本科", "成都", "1-3年", "职位描述岗位职责： 1、与企业客户沟通需求，针对客户需求，给出解决方案和设计文档；2、参与数据采集、清洗、传输、存储和计算等全方面设计与开发；3、利用开源的大数据处理组件，对海量数据进行分析来解决企业客户的实际问题；4、研究跟进大数据领域新技术并分享；任职要求：1、统招本科毕业、计算机或相关专业；2、熟练使用Java/Scala/Python等至少一门开发语言，2年以上开发经验；3、熟练使用大数据处理组件Hadoop/Spark/HBase/Kafka/Flume/Elastic Search/Solr等2种以上；4、熟悉Linux环境下的后台开发；5、有大数据集群部署及运维经验者优先；6、具备优秀的团队意识和沟通能力，学习能力和主动性强，有强烈的求知欲和进取心。", "成都华清佳信科技有限公司", "15-50人", "成长型(A轮)", "硬件,其他", "-"
"拉勾", "Hadoop", "Hadoop", "20000-35000", "本科", "北京", "5-10年", "职位描述负责数据仓库和大数据处理模块的架构设计和开发；负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；基于Spark框架的数据仓库的设计，开发，维护；根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作；应对PB以上级别数据的交互式查询、计算、存储；解决大数据平台在多租户模式下数据的安全、资源的隔离以及交互式数据探索等问题。", "海福云聚（北京）科技有限公司", "50-150人", "初创型(天使轮)", "数据服务", "4.0"
"拉勾", "Hadoop", "hadoop开发工程师", "10000-15000", "本科", "北京", "3-5年", "职位描述岗位技能要求1 有一定的java开发基础.熟悉网络通讯,文件操作等技术原理.2 熟悉Linux命令.能在Linux下进行软件部署,熟悉日志查询,进程跟踪,网络检查等相关命名3 熟悉大数据相关的技术，Hadoop/hbase作为内容存储,Nosql技术作为元数据存储.数据采集用到flume,logstash. 数据交换使用kafka.4 具备工作责任感和事业心，具备良好的团队精神和沟通能力。", "翰竺科技（北京）有限公司", "500-2000人", "成熟型(不需要融资)", "硬件,信息安全", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "8000-10000", "大专", "北京", "1-3年", "职位描述职位描述：1，参与Hadoop大数据平台产品的设计和优化；2，负责Hadoop大数据平台各个产品模块的开发、测试和维护；参与Haddop大数据平台产品的现场部署、调优和运维；岗位要求：1，3年及以上Java软件项目开发经验；2，1年及以上Hadoop平台开发经验，至少熟悉Hadoop/HBase/Hive/Storm/Flume/Kafka中的两种产品，具有Hadoop集群的线上运维经验者优先；3，熟悉Linux系统环境，熟练使用脚本编程，至少熟悉Shell/Python/Perl中的一种；4，责任心强，热爱技术，有较强的逻辑思维和清晰的表达能力，具备团队协作意识；5，具有海量数据处理、数据挖掘、数据分析相关项目经验者优先。", "中创立方慧谷科技（北京）有限公司", "15-50人", "初创型(未融资)", "其他", "-"
"拉勾", "Hadoop", "Hadoop集群运维工程师", "8000-16000", "本科", "广州", "1-3年", "职位描述岗位职责：1.负责维护大数据平台，能根据实际需求对平台进行优化配置2.负责集群容量规划、扩容及性能优化。3.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。任职资格：1.有Hadoop生态系统的运维经验，了解Hadoop、Storm、Spark、Flume、Kafka这些组件的原理。熟练的进行运维操作2.具备Java开发能力，对Hadoop源码有研究，具备部署、实施、维护hadoop 及相关组件的能力；3.熟悉服务器监控、日志分析，熟悉运维自动化，熟悉集群和高可用技术并具备生产环境实施和维护管理的经验；4.有团队合作精神，工作主动、责任心强，善于沟通。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop（上海）", "8000-12000", "本科", "上海", "1-3年", "职位描述大数据研发工程师（senior）： 一名工作职责：1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；3、完成各种面向业务目标的数据分析模型的定义和应用开发；4、开发具有数据分析、数据挖掘能力的创新型产品；岗位要求：1、计算机相关专业，本科及以上学历，2~3年以上Hadoop相关开发经验；2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；4、熟悉Linux/Unix平台上的开发环境；5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop研发-Java开发高级工程师", "25000-50000", "本科", "北京", "3-5年", "职位描述1，有深厚的开发功底，至少精通 JAVA， Scala， Python，Go等语言中的2种及以上2，熟读Hadoop源码，熟练使用Hadoop生态的各种工具和框架，有二次开发经验者优先3，当你满足1，2，和我联系吧", "京东－大数据部", "2000人以上", "上市公司", "电子商务,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop/Spark大数据平台高级运维工程师", "15000-30000", "本科", "北京", "不限", "职位描述360公司 大数据平台高级运维工程师职责：1. 负责几万台服务器规模的大数据平台Hadoop/HBase/Spark/Storm等运维及优化工作2. 研究业界最新的大数据技术，负责大数据运维工具、系统的设计与开发3. 支撑360安全、搜索、广告、推荐、智能硬件等大数据业务要求：1. 熟悉Linux操作系统，熟练使用各种常用命令2. 良好的Shell/Perl/Python/PHP至少一种脚本编程能力3. 有Hadoop/HBase/Spark/Storm等大数据平台运维经验优先4. 良好的团队合作及沟通能力，较强的责任心", "奇虎360科技有限公司", "50-150人", "上市公司", "移动互联网,游戏", "4.3"
"拉勾", "Hadoop", "Hadoop高级开发工程师", "15000-20000", "本科", "北京", "5-10年", "职位描述职位描述：1、参与Hadoop大数据平台产品的规划、分析和设计，完成系统整体架构；2、负责Hadoop大数据平台各个产品模块的开发、测试和优化；3、参与Haddop大数据平台产品的现场部署和调优；任职要求：1、5年及以上Java软件项目开发经验；2、2年及以上Hadoop平台开发经验，熟悉Hadoop/HBase/Hive/Storm/Flume/Kafka中的多种产品，具有Hadoop集群的线上运维经验；3、熟悉Linux系统环境，熟练使用脚本编程，至少熟悉Shell/Python/Perl中的一种；4、责任心强，热爱技术，有较强的逻辑思维和清晰的表达能力，具备团队协作意识；5、具有海量数据处理、数据挖掘、数据分析相关项目经验者优先。", "中创立方慧谷科技（北京）有限公司", "15-50人", "初创型(未融资)", "其他", "-"
"拉勾", "Hadoop", "Hadoop", "12000-18000", "本科", "合肥", "1-3年", "职位描述目前招聘大数据方向相关岗位：1、大数据分析师/挖掘师/大数据平台开发工程师/大数据爬取；2、大数据分析师/挖掘师：至少精通一门编程语言（C/C++，Java，Python，Scala等），熟悉网络编程、多线程、Hadoop/Spark分布式编程技术，对数据结构和算法设计有较为深刻的理解；3、大数据平台开发工程师：具备企业级Hadoop/Spark系统建设和运维经验，精通Hadoop以及HBase、Hive、Spark等大数据平台的二次开发和调优；有大规模集群开发运维经验或分布式OLAP开发应用经验者优先。", "科大讯飞股份有限公司", "2000人以上", "上市公司", "移动互联网,数据服务", "3.9"
"拉勾", "Hadoop", "资深Hadoop架构师", "10000-20000", "本科", "上海", "不限", "职位描述1、5年以上数据仓库开发和架构设计经验2. 精通Hadoop，Mapreduce，Hbase，Hive，Spark等大数据技术，了解源码或修改过源码优先3.精通Java，C等开发语言，熟悉Shell，Python，Perl至少一种脚本语言4. 精通ORACLE及MYSQL数据库，有扎实的数据库基础5. 有数据仓库建模和架构设计经验，对数据处理细节有深刻的见解6. 有强烈的学习能力和问题解决能力以及对新技术的钻研能力7. 有极强的团队协作精神，良好的沟通能力，工作积极主动，认真负责。", "上海陆家嘴国际金融资产交易市场股份有限公司", "2000人以上", "成长型(B轮)", "金融", "3.1"
"拉勾", "Hadoop", "Java开发工程师-Hadoop数据平台方向", "15000-30000", "本科", "北京", "3-5年", "职位描述岗位职责：1、负责数据平台的后台系统的研发；2、参与项目架构与方案设计；3、深入发掘和分析业务需求，撰写技术方案和系统设计；4、参与关键技术问题的攻关。职位要求：1、计算机及相关专业本科及其以上学历，2年以上Java开发经验，具有扎实的Java基础；2、熟悉常用设计模式、算法；3、至少熟练掌握Struts2、Spring3等一种主流开发框架，熟悉MVC开发模式；4、熟悉SQL语句的编写，熟练使用Mysql数据库，有MyBatis/Hibernate的使用经验；5、精通HTML/CSS/JS，熟悉Web标准；6. 优秀的编程效率，良好的编码习惯；能够独自完成项目中的模块开发和单元测试，具有软件设计及文档编写能力，富有责任感，具有较强的学习和沟通能力,有一定 的抗压能力；7、了解Hadoop生态系统开发和使用基础的优先；8、有数据仓库、BI系统建设经验的优先；9、了解分布式，高并发，高负载，高可用性系统的优先；", "艺龙网信息技术（北京）有限公司", "2000人以上", "上市公司", "移动互联网,旅游", "4.1"
"拉勾", "Hadoop", "Hadoop大数据培训工程师", "13000-25000", "本科", "杭州", "1-3年", "职位描述岗位职责：承担大数据产品、技术方向授课，教材开发，项目支持等工作。任职要求：1、具备数据挖掘和数据分析相关岗位经验；2、具有大数据方案实施经验者优先；3、熟悉Hadoop架构和工作原理者优先；4、具备服务器、云平台开发或使用经验者优先；5、本科学历，3年以上相关工作经验，通信、计算机、电子类相关专业毕业；6、CET-4以上，读、说、听、写熟练，口语表达流利，能以英语作为工作语言；7、适应短期的国内外出差。", "浙江华为通信技术有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,教育", "-"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "本科", "北京", "1-3年", "职位描述岗位职责：1. 从大数据中挖掘用户本质属性，并分析用户行为和个性化需求；2. 不断挖掘新的用户属性数据并据此产生创新的应用；3. 应用先进的统计建模、数据挖掘、机器学习法建立数据模型解决实际问题，并研发创新方法以解决常规算法不能解决的问题；4. 与业务部门沟通合作，将数据模型应用于实际业务；任职要求：1. 本科以上学历，硕士优先。统计学、计算机科学、数学等相关专业。扎实的统计学、数据挖掘、机器学习理论基础；2. 具有丰富的数据建模实践经验，1年以上相关工作经验；3. 扎实的编程基础，精通至少一门编程语言。熟悉R语言优先；4. 熟练掌握Hive\\SQL；5. 拥有海量数据处理经验者优先，熟悉Hadoop优先。", "北京中传瑞智市场调查有限公司", "50-150人", "初创型(未融资)", "数据服务", "4.5"
"拉勾", "Hadoop", "Hadoop/数据工程师实习生", "4000-7000", "本科", "深圳", "不限", "职位描述工作职责：1、参与百度国际化数据中心的研发工作，对国际化海量产品数据进行采集、处理、分析等，对内提供数据平台。岗位要求：1、熟悉Hadoop、Hive等开源项目者优先；2、熟悉算法设计/数据结构，熟悉Linux/Unix平台上的Python、Java、C/C++语言编程，熟悉常用脚本语言；3、善于学习新知识，有强烈的创新意识，对解决具有挑战性问题充满激情；4、良好的团队协作精神，较强的沟通表达能力，思路敏捷清晰。5、2017年/2018年毕业，为佳。工作地点：深圳!工作地点：深圳!工作地点：深圳!", "百度在线网络技术（北京）有限公司", "2000人以上", "上市公司", "移动互联网,数据服务", "3.9"
"拉勾", "Hadoop", "IDD-资深多媒体开发(Hadoop)", "25000-40000", "本科", "北京", "5-10年", "职位描述职责描述：1.负责多媒体技术相关调研；2.负责多媒体播放框架设计；3.负责需求开发和迭代；4.撰写和维护相关技术文档。职位要求1.精通C/C++；2.有多媒体播放开发经验（基于系统多媒体播放器开发或开发多媒体播放器均可，IOS/Windows/Android平台均可）；3.有良好代码规范，理解设计模式；4.能独立完成模块设计和编码；5.工作责任心强，积极主动认真细致并且能和团队融洽相处；6.本科及以上学历，5年以上工作经验。", "北京爱奇艺科技有限公司", "2000人以上", "成熟型(D轮及以上)", "广告营销,文化娱乐", "4.2"
"拉勾", "Hadoop", "Hadoop工程师", "15000-22000", "本科", "上海", "1-3年", "职位描述作为一名我们需要的Hadoop工程师，希望你具备：1. 计算机相关本科及以上学历2. 1年以上Hadoop编程经验，熟悉Mapreduce，熟悉JAVA编程3. 熟悉SQL/NoSQL/JSON/XML，以及相关的数据操作4. 熟悉Python/Shell编程5. 熟悉数据结构，算法的时间空间复杂度 O(?)Hadoop工程师：必备技能：Mapreduce开发经验，Linux（一般来说都有）优先几种竞赛得奖（计算机，数学，建模），优先计算机相关专业（其他专业扣分）", "上海巨灵信息技术股份有限公司", "50-150人", "上市公司", "企业服务,其他", "4.4"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "不限", "杭州", "不限", "职位描述岗位职责:1. 负责日志数据的清洗、分析工作以及入库工作;2. 负责Hadoop集群日常维护；3. 负责MapReduce程序的开发，Hive脚本的编写；任职资格:1、计算机相关专业本科学历；2、熟练掌握HADOOP平台hive、HBASE开发技能3、熟悉任何一种开发语言(java、python、c++等均可)4、有大数据开发处理经验者优先。", "杭州米络科技有限公司", "150-500人", "成长型(B轮)", "移动互联网", "4.3"
"拉勾", "Hadoop", "Hadoop", "20000-40000", "本科", "北京", "3-5年", "职位描述职责：1）大数据平台基础研发2）Hadoop 及其相关开源项目的二次开发职位要求：1）计算机或相关专业本科以上学历，三年以上研发经验2）熟悉 Linux 平台和计算机网络3）熟悉 JAVA 或者 C/C++， 常用脚本语言4）熟悉大数据开源项目源码，如 Hadoop, Hive, HBase, Presto, Storm, Kafka 等5）良好的团队合作精神，较强的沟通能力", "北京京东尚科信息技术有限公司", "2000人以上", "上市公司", "电子商务", "4.1"
"拉勾", "Hadoop", "Hadoop工程师", "8000-15000", "本科", "南宁", "不限", "职位描述岗位职责：1、根据数据需求，负责hadoop/hbase/hive/MapReduce定制开发；2、负责hadoop/hbase/hive/MapReduce数据流程维护及性能优化工作；3、负责基于hadoop进行挖掘模型开发实现及数据分析数据开发工作；4、编写项目hadoop数据开发流程文档，职位要求：1、本科以上学历，掌握java编程语言，熟悉java核心技术；2、1年以上hadoop/hbase/hive/MapReduce实际项目开发经验;3、熟悉分布式计算模型，能快速解决实际数据开发中遇到的各种问题；4、个性开朗，对技术钻研好学、逻辑思维能力强，有团队合作精神", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop研发工程师", "7000-12000", "本科", "杭州", "不限", "职位描述岗位职责：（1）负责大数据架构技术验证、性能优化、平台维护、平台演进等工作（2）设计及开发大数据系统，应用及修改部分开源大数据源码；（3）对大数据系统进行测试，应用修改大数据监控、资源管理等自动化运维系统；（4）研究大数据前沿技术，改进现有运维系统，提升系统的可靠性；任职要求：（1）计算机或相关专业，本科及以上学历；（2）具有Hadoop,Hbase，flume，kafka，storm，spark等大数据平台开发运维经验者优先；（3）熟悉linux系统，网络等计算机基础知识；；（4）熟练掌握并使用java,scala至少一种编程语言；（5）熟练掌握并使用shell,python至少一种脚本语言；（6）踏实认真，对技术钻研好学，逻辑能力强，有团队合作精神。", "银江研究院大数据研究所", "500-2000人", "上市公司", "移动互联网,数据服务", "-"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-30000", "本科", "深圳", "1-3年", "职位描述岗位职责：1、负责公司大数据平台产品的设计、开发及部署、实施；2、大数据平台运行性能、可用性、扩展性等监控与优化调控；3、负责基于Hadoop/Spark生态系统的研发；4、负责基于spark的计算和挖掘研发岗位要求：1、计算机相关专业，三年以上Java工作经验；2、Java基础良好，至少有一年Hadoop开发经验；3、深入了解HDFS/MapReduce/HBase架构及运行原理；4、深入了解Spark/Hive/Storm，有实际开发者优先；5、具有公共平台、大型架构设计开发者优先；6、熟练掌握Linux基本操作和Shell编程；7、能吃苦耐劳，有强烈的责任感和良好的沟通能力。", "厦门瑞为信息技术有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "2.3"
"拉勾", "Hadoop", "Hadoop", "10000-20000", "大专", "北京", "3-5年", "职位描述（１） 精通JAVA语言开发,熟悉Linux环境下的JAVA程序设计（２） 熟悉Hadoop分布式环境搭建和运行原理,对Hdfs/Mapreduce/Hbase等有一定研究，能解决Hadoop的复杂问题（３） 数据Hadoop/Hbase生态环境体系和管理掌握Hadoop，Hbase，MapReduce，HDFS，Hive，Pig，Sqoop，Oozie，Flume，Zookeeper，Storm，Spak Streaming等开源项目的原理和使用方法，有2年以上Hadoop项目实践经验，承担项目技术经理者优先（4）具有良好的沟通能力", "北京华正方圆科技发展有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,企业服务", "3.7"
"拉勾", "Hadoop", "Hadoop研发工程师", "15000-25000", "大专", "深圳", "3-5年", "职位描述岗位职责：1、从事Hadoop、Storm、Spark、Impala等分布式大数据系统产品的设计和开发；2、针对公司大数据业务进行大数据平台、数据分析、挖掘软件的框架设计和开发 ；3、参与公司内外部大数据项目的需求分析及数据建模、方案评估；4、对已有运营统计分析平台进行优化改进。任职要求：1、JAVA基础扎实，精通Spring、Hibernate、Struct、Junit等框架和技术；2、熟悉linux环境，能够熟练使用shell、python等脚本；3、熟悉开源框架(Hadoop、hbase、hdfs、storm、spark等，但不限于它们)，有一定的开源项目研究、应用、维护的经验者优先；4、熟悉数据结构、设计模式，有一定的软件架构和优化能力；5、熟悉正规的软件开发流程，能按照要求给出高质量的文档、代码；6、对大数据技术有强烈兴趣，工作认真踏实，动手和学习新技术能力强。", "深圳奇迹智慧网络有限公司", "50-150人", "初创型(天使轮)", "移动互联网,数据服务", "2.9"
"拉勾", "Hadoop", "Hadoop运维", "12000-22000", "本科", "上海", "1-3年", "职位描述职位描述：1、负责Hadoop&HBase平台运维，保障各核心服务运行的稳定、通过技术优化提升数据产品的质量和响应速度；2、开发各种Hadoop&HBase大数据自动化运维与监控工具。3、建设基于大数据的运维监控体系。岗位要求：1、计算机科学、计算机工程及相关专业的本科、研究生学历2、三年以上系统运维或大数据运维工作经验，有大型互联网公司工作经验者优先；3、熟悉Hadoop、HBase、Hive、Hue、Spark、impala、zookeeper、oozie、yarn、Scribe、Flume、Storm等开源项目的部署、性能调优；4、熟悉nagios、cacti、ganglia、zabbix、zenoss优先；6、具有良好的学习能力、沟通能力、客户服务意识和团队合作精神；具有强烈的进取精神和乐观的工作态度。", "上海游族信息技术有限公司", "500-2000人", "上市公司", "移动互联网,游戏", "4.5"
"拉勾", "Hadoop", "Hadoop高级工程师", "15000-20000", "不限", "北京", "3-5年", "职位描述岗位职责：1、负责大数据平台核心功能模块的开发工作。2、负责平台底层搭建和。3、负责协同大数据平台架构师完成架构搭建工作。4、负责负责明星分析类应用产品核心功能开发工作。任职资格：1、您应该具备2年以上的Hadoop、Hive、MR项目开发经验，热爱编程。2、您应该熟悉Hadoop生态圈的各种组件HBase、Sqoop等、能熟练上手，并指导初级Hadoop工程师完成开发工作。3、您应该是一个执行力强的人，能在规定时间高质量完成工作。4、你应该愿意与团队一起成长，能接受从0到1的过程中带来的任何压力，所以你需要抗压性很强。5、你应该是计算机相关专业，专科以上学历。6、如果你有影视、娱乐数据平台及产品开发经验，将会优先选择。", "艺恩世纪国际信息咨询（北京）有限公司", "50-150人", "初创型(未融资)", "移动互联网,金融", "-"
"拉勾", "Hadoop", "Hadoop", "5000-10000", "大专", "重庆", "1年以下", "职位描述JobRequirements&SkillsRequired1. TypicallyatechnicalBachelor'sdegreeorabove2. GoodverbalandwrittencommunicationskillsinEnglishandcommunicationskills.3. HavesolidJavadevelopmentexperiencesinamust4. ExperiencedinHadoopdevelopment,atleast1yearsexperiencesinHadoop:HDFS,MapReduce,pig,hive,sqoop,YARN5. Experiencesinotherbigdatadevelopmentisaplus,e.g,Cassandra,MongoDB,GreenPlum,in-memoryDB,Storm,Kafka,etc6. Skillsontroubleshootingandproblemsolving.7. Abletoworkindependentlywithpartnersaroundtheworld8. Abletomanagemultitasksinparallelefficiently.9. Quicklearnerandstrongwillingnessinlearningdifferenttechnologies,andshiftassignmentareawhenrequested.", "上海亚创博彦信息技术有限公司", "500-2000人", "上市公司", "企业服务", "-"
"拉勾", "Hadoop", "Hadoop", "8000-15000", "大专", "广州", "1-3年", "职位描述大数据产品工程师岗位职责：1、负责大数据技术领域的产品开发工作；2、大数据采集、整合、存储、分析建模等技术研究和开发；3、MPP数据库技术研究和功能开发；4、大数据应用服务开发平台设计与开发；5、大数据相关项目实施支持工作。任职要求：1、大学本科以上学历，计算机、软件工程相关专业，具有一年以上大数据平台开发，有志于从事政务大数据云计算开发工作；2、熟悉Hadoop、Spark、Docker容器等技术；3、熟悉SOA体系架构、精通SSH开发和J2EE开发平台；4、熟悉Oracle、MySQL等主流关系型数据库；5、熟悉政府数据架构，有相关数据整合、分析工作经验优先；6、有阿里、华为、浪潮大数据平台开发经验优先。", "广州金越软件技术有限公司", "50-150人", "初创型(未融资)", "信息安全,数据服务", "-"
"拉勾", "Hadoop", "Hadoop", "20000-30000", "本科", "上海", "不限", "职位描述岗位职责：1、 负责基于Hadoop/Spark平台架构的开发、设计和布局2、 完成系统框架的设计和核心代码的编写；3、 针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率。4、 负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑，5、 负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案6、 大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。任职资格：1、 2年互联网行业开发经验，计算机或相关专业本科以上学历。2、 精通Hadoop大数据平台架构，具有扎实的Java/Python等开发语言；并可以开发高效可靠的代码3、 具有较强的数据分析、数据挖掘的能力。4、 熟悉spark、Hive、storm等计算框架者优先，对分布式存储和计算原理有较深的理解。5、 严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能；6、 个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。", "上海厚福金融信息服务有限公司", "50-150人", "初创型(未融资)", "金融", "-"
"拉勾", "Hadoop", "Hadoop架构师", "18000-30000", "本科", "北京", "5-10年", "职位描述岗位职责：1、研究和设计公司的大数据仓库平台，负责数据仓库中的数据计算ETLpipeline的设计和开发，管理和维护；2、开发基于大数据技术的数据统计分析平台及大数据报表系统；3、web日志分析、微信、微博等非结构化数据抓取、分析；用户标签分析体系；4.理解系统的业务需求，制定系统的整体技术框架、业务框架和系统架构；5.负责给产品开发、实施、运维团队提供技术保障；6.负责对系统的重用、扩展、安全、性能、伸缩性、简洁等做系统级的把握；7.对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题。岗位要求：1.对各种架构模型有深入理解，了解模型的优缺点；2.熟悉Java、Scala或C++中的至少一门语言，有优良的TroubleShooting能力；3.对技术由衷热爱，对新技术、新方向有敏感的前瞻性；4.有扎实的表达能力，对业务模型、技术模型进行分析、评估；5.对大数据技术有钻研热情，乐于分享；6.在开源社群活跃并有积极贡献者优先；7.有百度、阿里、腾讯、Google等互联网公司同类数据产品架构经验者优先。", "信码互通（北京）科技有限公司", "150-500人", "初创型(未融资)", "O2O,数据服务", "4.0"
"拉勾", "Hadoop", "Hadoop", "15000-25000", "大专", "深圳", "3-5年", "职位描述岗位要求：1、大数据相关工作1年以上；2、JAVA，Python,其中至少一种语言三年以上；3、熟悉运用Mapreduce、HDFS、Hive、Hbase、Sqoop、Strom、Kafha、mongoDB、redis、elasticsearch中至少4中组件，并基于4种以上组件的开发经验；4、熟悉使用关系型数据库；5、熟悉Linux shell；", "印孚瑟斯技术（中国）有限公司", "2000人以上", "上市公司", "移动互联网", "3.0"
"拉勾", "Hadoop", "Hadoop开发高级工程师", "15000-30000", "本科", "上海", "5-10年", "职位描述岗位职责：1、开发实时/准实时大数据产品2、基于主流的流计算方案，如spark streaming ,storm3、提供有价值的商业数据、模型、算法支持4、参与公司平台化产品的开发任职要求：1、4年及以上的Java开发经验2、熟悉分布式缓存、消息队列、对基于java的高并发大流量系统性能优化有一定的经验3、熟悉Hadoop大数据平台架构，有Map/Reduce开发运维经验4、具有使用java在Storm、Spark、Hbase等大数据平台上开发真实项目的经验；4、熟悉Linux的基本操作及应用部署，了解Shell命令5、良好的沟通与团队合作能力，以及积极的学习成长心态", "上海优猎企业咨询管理有限公司", "50-150人", "成长型(不需要融资)", "招聘", "-"
"拉勾", "Hadoop", "Hadoop工程师", "15000-25000", "大专", "北京", "3-5年", "职位描述职位描述： 1、 HBase日志框架的搭建、优化及维护。Hadoop 集群维护及开发； 2、根据业务需要为HBase数据仓库的实现提供支持； 3、 参与基于Hadoop Map/Reduce 的项目开发。 岗位要求： 1、 2年以上相关工作经验，计算机相关专业。 2、熟悉Hadoop、HBase、Zookeeper 、Storm 、Spark等分布式框架； 3、熟悉RabbitMQ、Kafka等分布式消息队列； 4、具备两个以上的分布式系统的设计、开发、调优及运维/运营经验，相关系统在线上至少稳定运行1年以上； 5、有分布式项目开发经验者优先，有生产系统调优经验者优先。", "国美在线电子商务有限公司", "2000人以上", "上市公司", "电子商务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "15000-20000", "本科", "广州", "1-3年", "职位描述一、岗位工作范围和职责：1、负责公司大数据平台相关产品的设计，开发、文档撰写和项目改进 ；2、参与公司大数据平台上业务应用的功能设计及架构规划；3、负责优化平台软件的模块结构和流程逻辑。二、专业知识和技能要求：1、两年及以上Java开发经验；2、熟悉Java语言，熟悉虚拟机原理，数据结构和算法等基础扎实，熟练掌握并应用面向对象的编程思想；3、熟悉Hadoop以及相关开源大数据技术，如Hive、HBase、Storm、 机器学习等框架；4、有较强的责任心、上进心以及良好的表达和沟通能力。三、公司福利：1、全年年收入约14.5个月工资，另外约有1.2万左右的现金福利；2、六险一金，员工年度健康福利体检；其中住房公积金按照月度工资总额的12%购买；3、五天7小时工作制。带薪年假、各类法定节假日、有薪假及出差探亲假等；4、各类过节福利、节日礼品、生日礼品、慰问品等；5、差旅费、差旅津贴、业务招待费、通讯补助、用餐补助、保密补贴、活动经费等；6、每周免费部门水果，部门不定期旅游、聚餐；7、量身定制职业装、运动装；8、公司设有健身房、篮球场、乒乓球室、壁球室等休闲设施，并定期组织各类业余活动；9、良好的学习平台，公司全额资助优秀员工参加上海交大、同济大学在职研究生学习；10、提供部分集体宿舍，解决广州户口。", "广州汇智通信技术有限公司", "500-2000人", "成熟型(不需要融资)", "移动互联网,信息安全", "3.3"
"拉勾", "Hadoop", "Hadoop工程师", "8000-15000", "本科", "北京", "不限", "职位描述职位描述：1、使用Hadoop、Hbase、Hive、MapReduce、Spark等进行大数据存储、处理和分析；2、负责数据处理维护和优化工作；2、维护开发文档，担任部分技术研究工作；岗位要求：1、计算机相关专业统招本科及以上学历，至少1年以上Hadoop相关开发经验；2、熟悉java开发，熟练掌握java集合类、io、并发编程和熟悉jvm原理及内存管理,对数据结构、算法有较深理解；3、熟悉Linux操作系统，熟悉Shell脚本编程；4、熟悉Hadoop、Hive、Hbase、Sqoop、Zookeeper中至少两种组件的部署、配置、维护；5、熟悉关系型数据库和NoSQL数据库；6、熟悉Spark等流式处理或有相关经验者优先。      ", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop", "7000-14000", "本科", "北京", "不限", "职位描述工作描述：1、参与大数据相关系统的需求调研和需求分析，撰写相关技术文档；2、项目概要设计、详细设计、开发计划等的编制并实施；3、具有良好沟通能力，能与客户进行需求方面的交流；4、搭建大数据相关系统开发环境，完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具程序代码的实现；5、完成Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维工作，完成上述工具的故障排除、修复工作；岗位要求:1、全国统招全日制高校计算机软件及相关专业一本学历及以上211/985院校优先；2、具备软件设计、编码开发测试、文档编写的能力；3、熟悉主流Linux操作系统，精通shell;4、了解Hadoop、Hive、Hbase、Storm、Spark等技术中的两种以上进行大数据应用开发；5、了解Linux系统运维，了解Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维；6、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；7、责任心强，工作踏实，团队协作精神，能适应严格项目管理；8、具备良好的沟通能力；9、具备电信行业、互联网行业工作经验者优先考虑；10、能够接受长期在外出差。", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "5000-10000", "本科", "上海", "不限", "职位描述 岗位职责 1、参与软件设计、编码开发、测试、文档编写等工作； 2、具备软件设计、编码开发测试、文档编写的能力； 3、具有一定沟通能力，能与客户进行需求方面的交流； 4、熟悉Oracle数据库，良好的SQL开发能力，熟练使用PL/SQL进行存储过程、函数等开发； 5、熟悉Hadoop、Hive、Hbase、Storm、Spark等大数据工具，完成上述工具的常见故障排除和修复工作； 岗位要求 1.全国统招全日制高校计算机软件及相关专业本科学历（非地方学院类院校）及以上，一本、211、985院校毕业生、硕士研究生优先； 2、具备大数据应用系统开发能力； 3、具备软件设计、编码开发测试、文档编写的能力； 4、熟悉Oracle或Hadoop、Hive、Hbase、Storm、Spark等技术框架中的两种以上;熟悉java、scala、sql等相关技术中的一种以上； 5、熟练使用Oracle或Hadoop、Hive、Hbase、Storm、Spark等技术中的两种以上进行大数据应用开发； 6、了解主流应用服务器，熟悉主流Linux操作系统，精通shell； 7、了解Linux系统运维，了解Hadoop、Hive、Hbase、Storm、Spark等大数据工具的运维； 8、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作； 9、责任心强，工作踏实，团队协作精神，能适应严格项目管理； 10、具备良好的沟通能力； 11、具备电信行业、互联网行业工作经验者优先考虑；", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "本科", "广州", "不限", "职位描述工作内容描述:1.负责hadoop平台上大数据处理程序开发； 2.负责大数据规则库加密、解密JAVA程序开发； 3.负责编写相关开发文档。 岗位要求:1.计算机或相关专业本科及以上学历,2年以上JAVA开发经验； 2.熟悉hadoop框架及原理，有应用hadoop的开发经验（MR编程、hbase、hive等）； 3.熟悉Linux/Unix操作系统； 4.熟悉shell、python脚本语言者优先；", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "JAVA高级工程师/技术专家-hadoop数据平台方向", "30000-50000", "不限", "北京", "3-5年", "职位描述岗位职责：1、负责数据平台的后台系统的研发；2、参与项目架构与方案设计；3、深入发掘和分析业务需求，撰写技术方案和系统设计；4、参与关键技术问题的攻关。职位要求：1、计算机及相关专业本科及其以上学历，2年以上Java开发经验，具有扎实的Java基础；2、熟悉常用设计模式、算法；3、至少熟练掌握Struts2、Spring3等一种主流开发框架，熟悉MVC开发模式；4、熟悉SQL语句的编写，熟练使用Mysql数据库，有MyBatis/Hibernate的使用经验；5、精通HTML/CSS/JS，熟悉Web标准；6.优秀的编程效率，良好的编码习惯；能够独自完成项目中的模块开发和单元测试，具有软件设计及文档编写能力，富有责任感，具有较强的学习和沟通能力,有一定的抗压能力；7、了解Hadoop生态系统开发和使用基础的优先；8、有数据仓库、BI系统建设经验的优先；9、了解分布式，高并发，高负载，高可用性系统的优先；", "北京华正方圆科技发展有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,企业服务", "3.7"
"拉勾", "Hadoop", "JAVA高级工程师/技术专家-hadoop方向", "30000-50000", "不限", "北京", "3-5年", "职位描述岗位职责：1、负责数据平台的后台系统的研发；2、参与项目架构与方案设计；3、深入发掘和分析业务需求，撰写技术方案和系统设计；4、参与关键技术问题的攻关。职位要求：1、计算机及相关专业本科及其以上学历，2年以上Java开发经验，具有扎实的Java基础；2、熟悉常用设计模式、算法；3、至少熟练掌握Struts2、Spring3等一种主流开发框架，熟悉MVC开发模式；4、熟悉SQL语句的编写，熟练使用Mysql数据库，有MyBatis/Hibernate的使用经验；5、精通HTML/CSS/JS，熟悉Web标准；6.优秀的编程效率，良好的编码习惯；能够独自完成项目中的模块开发和单元测试，具有软件设计及文档编写能力，富有责任感，具有较强的学习和沟通能力,有一定的抗压能力；7、了解Hadoop生态系统开发和使用基础的优先；8、有数据仓库、BI系统建设经验的优先；9、了解分布式，高并发，高负载，高可用性系统的优先；", "北京华正方圆科技发展有限公司", "150-500人", "成长型(不需要融资)", "移动互联网,企业服务", "3.7"
"拉勾", "Hadoop", "Hadoop开发工程师", "8000-16000", "本科", "北京", "1-3年", "职位描述岗位职责：1、负责基于Hadoop平台的数据开发工作2、负责电信行业业务统计分析，解决并实现业务需求3、大规模数据处理性能调优和存储调优4、大数据处理技术的跟踪和研究任职要求：1、本科以上学历，计算机及通信相关专业；2、1年以上Java开发工作经验，有Hadoop开发经验优先；3、熟悉大数据生态体系，掌握Hadoop技术架构和基本原理4、有电信行业开发经验者优先", "北京东方国信科技股份有限公司", "2000人以上", "上市公司", "数据服务", "3.9"
"拉勾", "Hadoop", "Hadoop/MySQL开发维护工程师", "9000-18000", "本科", "上海", "1-3年", "职位描述岗位职责：1.负责搭建hadoop集群，并维护与管理；2.负责hadoop平台上的数据存储，数据维护和优化；3.编写hive-ql脚本做相关的统计计算；4.编写map-reduce程序做相关的分析建模；5.使用kettle工具把分析结果导入到mysql数据库中；职位要求：1.本科以上学历，1年以上相关工作经验；2.对数据结构、算法有深刻理解；3.熟悉linux开发环境；4.有hadoop集群部署和开发经验；5.熟悉java和sql开发；6.工作积极主动认真负责，具有良好的沟通和学习能力；", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "Hadoop开发工程师", "10000-20000", "本科", "上海", "1-3年", "职位描述岗位职责：1.负责智子云数据基础架构平台的运维工作，保障服务的高可用行和稳定性。2.负责集群容量规划、扩容及集群性能优化3.集群作业的执行计划和日常运行状态监控4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。职位要求：1. 2年以上大数据集群相关运维经验，熟悉常用的监控及管理工具2.有良好的计算机和网络基础，熟悉linux文件系统、性能调优，TCP/IP、HTTP等协议3.熟悉大数据集群运行基本原理。具备相关大数据集群搭建优化经验者优先（Cloudera CDH/Apache Hadoop/Hbase/Kafka/Zookeeper）4.良好的学习能力、沟通能力、适应能力，责任心强。", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "高级Hadoop/hadoop开发工程师", "10000-20000", "本科", "上海", "1-3年", "职位描述岗位职责：1.负责hadoop平台上的数据存储，数据维护和优化；2.编写hive-ql脚本做相关的统计计算；3.编写spark程序进行相关报表计算；4.编写map-reduce程序做相关的分析建模；任职要求：5.本科以上学历，1年以上相关工作经验；6.对数据结构、算法有深刻理解；7.熟悉linux开发环境；8.有hadoop集群部署和开发经验；9.熟悉java和sql开发；10.工作积极主动认真负责，具有良好的沟通和学习能力.", "上海智子信息科技有限公司", "50-150人", "成长型(B轮)", "移动互联网,数据服务", "4.1"
"拉勾", "Hadoop", "HADOOP开发工程师", "12000-18000", "本科", "杭州", "3-5年", "职位描述研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等任职要求：1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳3、 熟悉mysql数据库，并具有一定的SQL功底；4、 熟悉python，scala等语言更佳。5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情", "浙江每日互动网络科技股份有限公司", "150-500人", "成熟型(C轮)", "移动互联网", "3.3"
"拉勾", "Hadoop", "Hadoop大数据高级工程师（北京）", "15000-25000", "本科", "北京", "不限", "职位描述工作职责1、基于Hadoop/Spark分布式集群的架构设计和开发。2、解答用户提出的需求以及碰到问题时的解答。任职资格1、数学、统计学、人工智能、计算机相关专业，本科或以上学历。2、至少熟练运用Java、Scala语言中的1种。3、需要有Hadoop / Spark平台相关运维经验2年以上，有3年以上基于hadoop/Spark的实际项目开发经验。4、熟练掌握linux常规命令与工具，至少熟练应用shell、Python脚本语言中的1种。5、敏锐的洞察系统性能瓶颈，并能对io、网络通讯、任务调度中一个或多个方面的性能调优。6、具有较强的学习能力、逻辑分析能力、问题排查能力、沟通能力、自我驱动动力、自我管理能力。", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop开发--平台组（北京）", "15000-20000", "本科", "北京", "不限", "职位描述职位描述：1. 参与大数据基础平台管理组件的设计与研发、测试等工作；2. 负责相关模块的研发，保证系统性能、稳定和安全；3. 参与Hadoop生态系统相关开源技术的使用、封装和增强等研发工作；任职要求：1.熟悉JAVA开发语言等相关技术和网络应用开发；2.参与Hadoop生态中的zookeeper、hdfs、yarn、hbase、hive、impala、sqoop、spark、oozie、flume、kafka等开源组件的使用、封装和增强；4.熟悉MySql、Postgresql至少一种数据库；5.熟悉使用Linux；6.熟悉Hadoop生态系统的优先考虑。", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop--平台组（北京）", "16000-25000", "本科", "北京", "1-3年", "职位描述职位描述： 1. 参与大数据基础平台管理组件的设计与研发、测试等工作 2. 负责相关模块的研发，保证系统性能、稳定和安全 3. 参与Hadoop生态系统相关开源技术的使用、封装和增强等研发工作任职要求：1.熟悉JAVA开发语言等相关技术和网络应用开发。2.参与Hadoop生态中的zookeeper、hdfs、yarn、hbase、hive、impala、sqoop、spark、oozie、flume、kafka等开源组件的使用、封装和增强 4.熟悉MySql、Postgresql至少一种数据库；5.熟悉使用Linux6.熟悉Hadoop生态系统的优先考虑", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
"拉勾", "Hadoop", "Hadoop", "3000-4000", "本科", "上海", "不限", "职位描述1、负责大数据应用现场定制方案的设计与实施；2、负责基于HIVE平台的数据治理和报表加工岗位要求：1、计算机相关专业，本科及以上学历；2、熟悉Linux/Unix平台上的开发环境；3.、踏实努力，认真负责，做事仔细。4.2017年以及以后毕业，每周实习4天以", "北京明略软件系统有限公司", "150-500人", "成长型(B轮)", "数据服务", "-"
